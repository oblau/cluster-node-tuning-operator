2025-11-17T09:26:14.511236537Z + [[ -f /env/_XXXXXX ]]
2025-11-17T09:26:14.511555051Z ++ date '+%m%d %H:%M:%S.%N'
2025-11-17T09:26:14.513022010Z I1117 09:26:14.512781503 - network-node-identity - start approver
2025-11-17T09:26:14.513028352Z + echo 'I1117 09:26:14.512781503 - network-node-identity - start approver'
2025-11-17T09:26:14.513064747Z + exec /usr/bin/ovnkube-identity --k8s-apiserver=https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443 --disable-webhook --csr-acceptance-conditions=/var/run/ovnkube-identity-config/additional-cert-acceptance-cond.json --loglevel=4
2025-11-17T09:26:14.534402946Z I1117 09:26:14.534304       1 ovnkubeidentity.go:131] Config: {kubeconfig: apiServer:https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443 logLevel:4 port:9443 host:localhost certDir: metricsAddress:0 leaseNamespace: enableInterconnect:false enableHybridOverlay:false disableWebhook:true disableApprover:false waitForKAPIDuration:0 localKAPIPort:6443 extraAllowedUsers:{slice:[] hasBeenSet:false} csrAcceptanceConditionFile:/var/run/ovnkube-identity-config/additional-cert-acceptance-cond.json csrAcceptanceConditions:[] podAdmissionConditionFile: podAdmissionConditions:[]}
2025-11-17T09:26:14.534402946Z W1117 09:26:14.534397       1 client_config.go:618] Neither --kubeconfig nor --XXXXXX was specified.  Using the inClusterConfig.  This might not work.
2025-11-17T09:26:14.535414674Z I1117 09:26:14.535398       1 ovnkubeidentity.go:468] Starting certificate signing request approver
2025-11-17T09:26:14.535579261Z I1117 09:26:14.535559       1 shared_informer.go:341] caches populated
2025-11-17T09:26:14.535630261Z I1117 09:26:14.535621       1 leaderelection.go:245] attempting to acquire leader lease openshift-network-node-identity/ovnkube-identity...
2025-11-17T09:26:19.546911230Z I1117 09:26:19.546764       1 with_retry.go:234] Got a Retry-After 5s response for attempt 1 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:24.556389552Z I1117 09:26:24.556228       1 with_retry.go:234] Got a Retry-After 5s response for attempt 2 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:29.567178968Z I1117 09:26:29.567104       1 with_retry.go:234] Got a Retry-After 5s response for attempt 3 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:34.577674633Z I1117 09:26:34.577609       1 with_retry.go:234] Got a Retry-After 5s response for attempt 4 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:39.587978577Z I1117 09:26:39.587823       1 with_retry.go:234] Got a Retry-After 5s response for attempt 5 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:44.594742888Z I1117 09:26:44.594534       1 with_retry.go:234] Got a Retry-After 5s response for attempt 6 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:49.600486228Z I1117 09:26:49.600435       1 with_retry.go:234] Got a Retry-After 5s response for attempt 7 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:54.607377301Z I1117 09:26:54.607333       1 with_retry.go:234] Got a Retry-After 5s response for attempt 8 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:26:59.613729004Z I1117 09:26:59.613567       1 with_retry.go:234] Got a Retry-After 5s response for attempt 9 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:27:04.621705846Z I1117 09:27:04.621650       1 with_retry.go:234] Got a Retry-After 5s response for attempt 10 to https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity
2025-11-17T09:27:04.624327041Z E1117 09:27:04.623930       1 leaderelection.go:327] error retrieving resource lock openshift-network-node-identity/ovnkube-identity: Get "https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity": dial tcp [2620:52:0:2e1a::10]:6443: connect: connection refused
2025-11-17T09:27:04.624327041Z I1117 09:27:04.623994       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:27:29.788420406Z I1117 09:27:29.788355       1 leaderelection.go:349] lock is held by XXXXXX2_68b7dbf0-b309-405d-9f97-be8870900e1b and has not yet expired
2025-11-17T09:27:29.788420406Z I1117 09:27:29.788379       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:27:58.253513091Z I1117 09:27:58.253450       1 leaderelection.go:349] lock is held by XXXXXX2_68b7dbf0-b309-405d-9f97-be8870900e1b and has not yet expired
2025-11-17T09:27:58.253513091Z I1117 09:27:58.253471       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:28:26.710824603Z I1117 09:28:26.710766       1 leaderelection.go:349] lock is held by XXXXXX2_68b7dbf0-b309-405d-9f97-be8870900e1b and has not yet expired
2025-11-17T09:28:26.710824603Z I1117 09:28:26.710783       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:29:09.700105489Z I1117 09:29:09.700014       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:29:09.700105489Z I1117 09:29:09.700033       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:29:53.643500487Z I1117 09:29:53.643429       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:29:53.643500487Z I1117 09:29:53.643450       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:30:17.533252602Z I1117 09:30:17.533198       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:30:17.533252602Z I1117 09:30:17.533217       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:30:40.006062999Z I1117 09:30:40.005663       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:30:40.006062999Z I1117 09:30:40.005685       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:32:00.136273049Z E1117 09:32:00.136204       1 leaderelection.go:327] error retrieving resource lock openshift-network-node-identity/ovnkube-identity: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io ovnkube-identity)
2025-11-17T09:32:00.136273049Z I1117 09:32:00.136233       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:32:49.487173736Z I1117 09:32:49.487079       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:32:49.487251090Z I1117 09:32:49.487229       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:33:24.167241524Z I1117 09:33:24.167169       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:33:24.167241524Z I1117 09:33:24.167193       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:33:47.332306185Z I1117 09:33:47.332146       1 leaderelection.go:349] lock is held by XXXXXX1_35b72ff6-6f1e-4bdc-9b47-0a46be3b2c1b and has not yet expired
2025-11-17T09:33:47.332306185Z I1117 09:33:47.332169       1 leaderelection.go:250] failed to acquire lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:34:10.184247982Z I1117 09:34:10.184007       1 leaderelection.go:255] successfully acquired lease openshift-network-node-identity/ovnkube-identity
2025-11-17T09:34:10.184247982Z I1117 09:34:10.184158       1 recorder.go:104] "events: XXXXXX2_e18b296c-e194-4404-856d-9c31178857df became leader" type="Normal" object={"kind":"Lease","namespace":"openshift-network-node-identity","name":"ovnkube-identity","uid":"4659b2c6-ade4-4d67-b4a9-67def0d42dec","apiVersion":"coordination.k8s.io/v1","resourceVersion":"20652"} reason="LeaderElection"
2025-11-17T09:34:10.184451445Z I1117 09:34:10.184415       1 controller.go:177] "Starting EventSource" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest" source="kind source: *v1.CertificateSigningRequest"
2025-11-17T09:34:10.184462517Z I1117 09:34:10.184448       1 controller.go:185] "Starting Controller" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest"
2025-11-17T09:34:10.185704509Z I1117 09:34:10.185678       1 reflector.go:287] Starting reflector *v1.CertificateSigningRequest (9h9m15.829886219s) from sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:233
2025-11-17T09:34:10.185704509Z I1117 09:34:10.185690       1 reflector.go:323] Listing and watching *v1.CertificateSigningRequest from sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:233
2025-11-17T09:34:10.286123542Z I1117 09:34:10.286076       1 shared_informer.go:341] caches populated
2025-11-17T09:34:10.286178142Z I1117 09:34:10.286167       1 shared_informer.go:341] caches populated
2025-11-17T09:34:10.286217485Z I1117 09:34:10.286205       1 controller.go:219] "Starting XXXXXXs" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest" XXXXXX count=1
2025-11-17T09:34:10.286520642Z I1117 09:34:10.286505       1 approver.go:230] Finished syncing CSR csr-lpstt for unknown node in 236.076µs
2025-11-17T09:34:10.286713286Z I1117 09:34:10.286703       1 approver.go:230] Finished syncing CSR csr-wmwzn for unknown node in 17.945µs
2025-11-17T09:34:10.286740078Z I1117 09:34:10.286729       1 approver.go:230] Finished syncing CSR csr-wlsld for unknown node in 15.368µs
2025-11-17T09:34:10.286871652Z I1117 09:34:10.286856       1 approver.go:230] Finished syncing CSR csr-947tr for unknown node in 24.62µs
2025-11-17T09:35:32.431939507Z I1117 09:35:32.430477       1 reflector.go:788] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:233: Watch close - *v1.CertificateSigningRequest total 1 items received
2025-11-17T09:35:40.205771448Z E1117 09:35:40.205711       1 leaderelection.go:327] error retrieving resource lock openshift-network-node-identity/ovnkube-identity: Get "https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity": context deadline exceeded
2025-11-17T09:35:40.205771448Z I1117 09:35:40.205750       1 leaderelection.go:280] failed to renew lease openshift-network-node-identity/ovnkube-identity: timed out waiting for the condition
2025-11-17T09:35:47.210139910Z E1117 09:35:47.210080       1 leaderelection.go:303] Failed to release lock: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:47.210178033Z error running approver: leader election lost
