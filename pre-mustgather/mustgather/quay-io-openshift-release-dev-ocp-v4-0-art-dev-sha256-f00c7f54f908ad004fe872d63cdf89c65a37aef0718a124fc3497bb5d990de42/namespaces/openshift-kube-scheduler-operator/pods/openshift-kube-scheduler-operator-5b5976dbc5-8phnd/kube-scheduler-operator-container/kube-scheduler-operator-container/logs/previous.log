2025-11-17T09:27:19.655715653Z I1117 09:27:19.655595       1 cmd.go:233] Using service-serving-cert provided certificates
2025-11-17T09:27:19.655715653Z I1117 09:27:19.655682       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-11-17T09:27:19.656536581Z I1117 09:27:19.656493       1 observer_polling.go:159] Starting file observer
2025-11-17T09:27:19.680832330Z I1117 09:27:19.680774       1 builder.go:271] openshift-cluster-kube-scheduler-operator version 4.14.0-202511060117.p2.g33f630d.assembly.stream.el8-33f630d-33f630dc1f890ca59c5e57fb5b6cc24a3f22a1d4
2025-11-17T09:27:20.426589341Z I1117 09:27:20.426533       1 secure_serving.go:57] Forcing use of http/1.1 only
2025-11-17T09:27:20.426589341Z W1117 09:27:20.426583       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:20.426628562Z W1117 09:27:20.426592       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430262       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430323       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430339       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430368       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430337       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2025-11-17T09:27:20.432755476Z I1117 09:27:20.430368       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:20.432755476Z I1117 09:27:20.432158       1 secure_serving.go:213] Serving securely on [::]:8443
2025-11-17T09:27:20.432755476Z I1117 09:27:20.432217       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2025-11-17T09:27:20.432755476Z I1117 09:27:20.432655       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2025-11-17T09:27:20.437566256Z I1117 09:27:20.437513       1 leaderelection.go:245] attempting to acquire leader lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock...
2025-11-17T09:27:20.530992347Z I1117 09:27:20.530812       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:20.531134686Z I1117 09:27:20.531112       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:20.531193639Z I1117 09:27:20.531179       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2025-11-17T09:30:26.901342574Z I1117 09:30:26.900904       1 leaderelection.go:255] successfully acquired lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock
2025-11-17T09:30:26.901342574Z I1117 09:30:26.901315       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-cluster-kube-scheduler-operator-lock", UID:"69cb67e8-e60a-47cc-9554-63ec3c014b72", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"16058", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' openshift-kube-scheduler-operator-5b5976dbc5-8phnd_ea04a169-1633-4cb5-80f4-f035a24e18c9 became leader
2025-11-17T09:30:26.905320420Z I1117 09:30:26.902601       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2025-11-17T09:30:26.909314196Z I1117 09:30:26.908847       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform", "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource", "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration", "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass", "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
2025-11-17T09:30:26.909314196Z I1117 09:30:26.908817       1 starter.go:77] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AdmissionWebhookMatchConditions AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BuildCSIVolumes CSIDriverSharedResource CloudDualStackNodeIPs DynamicResourceAllocation EventedPLEG ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP GCPLabelsTags GatewayAPI InsightsConfigAPI MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MaxUnavailableStatefulSet NetworkLiveMigration NodeSwap OpenShiftPodSecurityAdmission PrivateHostedZoneAWS RetroactiveDefaultStorageClass RouteExternalCertificate SigstoreImageVerification VSphereStaticIPs ValidatingAdmissionPolicy]
2025-11-17T09:30:26.916006627Z I1117 09:30:26.915958       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2025-11-17T09:30:26.922035453Z I1117 09:30:26.919849       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-scheduler
2025-11-17T09:30:26.922035453Z I1117 09:30:26.920642       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923890       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923919       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923935       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923944       1 base_controller.go:67] Waiting for caches to sync for PruneController
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923958       1 base_controller.go:67] Waiting for caches to sync for NodeController
2025-11-17T09:30:26.924052627Z I1117 09:30:26.923961       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2025-11-17T09:30:26.924121965Z I1117 09:30:26.924108       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2025-11-17T09:30:26.924151341Z I1117 09:30:26.924141       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2025-11-17T09:30:26.924178652Z I1117 09:30:26.924167       1 base_controller.go:67] Waiting for caches to sync for GuardController
2025-11-17T09:30:26.924193156Z I1117 09:30:26.924184       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2025-11-17T09:30:26.924193156Z I1117 09:30:26.924185       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:30:26.924210426Z I1117 09:30:26.924204       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2025-11-17T09:30:26.924226093Z I1117 09:30:26.924205       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2025-11-17T09:30:26.924335266Z I1117 09:30:26.924319       1 base_controller.go:67] Waiting for caches to sync for KubeControllerManagerStaticResources
2025-11-17T09:30:27.016189676Z I1117 09:30:27.016123       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2025-11-17T09:30:27.016189676Z I1117 09:30:27.016155       1 base_controller.go:110] Starting #1 XXXXXX of RemoveStaleConditionsController controller ...
2025-11-17T09:30:27.020471801Z I1117 09:30:27.020353       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-scheduler 
2025-11-17T09:30:27.020471801Z I1117 09:30:27.020368       1 base_controller.go:110] Starting #1 XXXXXX of StatusSyncer_kube-scheduler controller ...
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024641       1 base_controller.go:73] Caches are synced for GuardController 
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024656       1 base_controller.go:110] Starting #1 XXXXXX of GuardController controller ...
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024661       1 base_controller.go:73] Caches are synced for InstallerStateController 
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024672       1 base_controller.go:110] Starting #1 XXXXXX of InstallerStateController controller ...
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024676       1 base_controller.go:73] Caches are synced for NodeController 
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024685       1 base_controller.go:110] Starting #1 XXXXXX of NodeController controller ...
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024705       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024719       1 base_controller.go:110] Starting #1 XXXXXX of MissingStaticPodController controller ...
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024724       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:30:27.024787650Z I1117 09:30:27.024734       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:30:27.024808138Z I1117 09:30:27.024791       1 base_controller.go:73] Caches are synced for InstallerController 
2025-11-17T09:30:27.024808138Z I1117 09:30:27.024797       1 base_controller.go:110] Starting #1 XXXXXX of InstallerController controller ...
2025-11-17T09:30:27.024966651Z I1117 09:30:27.024946       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2025-11-17T09:30:27.024966651Z I1117 09:30:27.024955       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateController controller ...
2025-11-17T09:30:27.024972450Z I1117 09:30:27.024966       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2025-11-17T09:30:27.024972450Z I1117 09:30:27.024969       1 base_controller.go:110] Starting #1 XXXXXX of LoggingSyncer controller ...
2025-11-17T09:30:27.025042899Z I1117 09:30:27.025024       1 base_controller.go:73] Caches are synced for BackingResourceController 
2025-11-17T09:30:27.025042899Z I1117 09:30:27.025038       1 base_controller.go:110] Starting #1 XXXXXX of BackingResourceController controller ...
2025-11-17T09:30:27.025277542Z I1117 09:30:27.025226       1 base_controller.go:73] Caches are synced for PruneController 
2025-11-17T09:30:27.025512254Z I1117 09:30:27.025475       1 base_controller.go:110] Starting #1 XXXXXX of PruneController controller ...
2025-11-17T09:30:27.025716377Z I1117 09:30:27.025680       1 base_controller.go:73] Caches are synced for RevisionController 
2025-11-17T09:30:27.025716377Z I1117 09:30:27.025711       1 base_controller.go:110] Starting #1 XXXXXX of RevisionController controller ...
2025-11-17T09:30:27.027394827Z I1117 09:30:27.027331       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2025-11-17T09:30:27.724541730Z I1117 09:30:27.724471       1 base_controller.go:73] Caches are synced for KubeControllerManagerStaticResources 
2025-11-17T09:30:27.724541730Z I1117 09:30:27.724497       1 base_controller.go:110] Starting #1 XXXXXX of KubeControllerManagerStaticResources controller ...
2025-11-17T09:30:27.920900913Z I1117 09:30:27.920847       1 base_controller.go:73] Caches are synced for ConfigObserver 
2025-11-17T09:30:27.920900913Z I1117 09:30:27.920866       1 base_controller.go:110] Starting #1 XXXXXX of ConfigObserver controller ...
2025-11-17T09:30:27.924231947Z I1117 09:30:27.924194       1 base_controller.go:73] Caches are synced for TargetConfigController 
2025-11-17T09:30:27.924231947Z I1117 09:30:27.924212       1 base_controller.go:110] Starting #1 XXXXXX of TargetConfigController controller ...
2025-11-17T09:30:27.924231947Z I1117 09:30:27.924199       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-11-17T09:30:27.924231947Z I1117 09:30:27.924225       1 base_controller.go:110] Starting #1 XXXXXX of ResourceSyncController controller ...
2025-11-17T09:30:28.116644938Z I1117 09:30:28.116591       1 request.go:696] Waited for 1.091780264s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:28.924409414Z I1117 09:30:28.924360       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:29.118165796Z I1117 09:30:29.117375       1 request.go:696] Waited for 2.087906121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-XXXXXX1
2025-11-17T09:30:30.317306738Z I1117 09:30:30.317242       1 request.go:696] Waited for 1.393068777s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2025-11-17T09:30:30.327934598Z I1117 09:30:30.327216       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:31.517146385Z I1117 09:30:31.517085       1 request.go:696] Waited for 1.381024858s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-XXXXXX2
2025-11-17T09:30:31.519415433Z I1117 09:30:31.519375       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:30:31.519415433Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:30:31.519415433Z  CurrentRevision: (int32) 7,
2025-11-17T09:30:31.519415433Z  TargetRevision: (int32) 0,
2025-11-17T09:30:31.519415433Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:31.519415433Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:31.519415433Z  LastFailedReason: (string) "",
2025-11-17T09:30:31.519415433Z  LastFailedCount: (int) 0,
2025-11-17T09:30:31.519415433Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:31.519415433Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:31.519415433Z }
2025-11-17T09:30:31.519415433Z  because static pod is ready
2025-11-17T09:30:31.529252569Z I1117 09:30:31.529215       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 0 to 7 because static pod is ready
2025-11-17T09:30:31.530382765Z I1117 09:30:31.530314       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:22:21Z","message":"GuardControllerDegraded: Missing operand on node XXXXXX2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:31Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:31.541013075Z I1117 09:30:31.539547       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing changed from True to False ("NodeInstallerProgressing: 2 nodes are at revision 7"),Available message changed from "StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 7" to "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7"
2025-11-17T09:30:31.725081169Z I1117 09:30:31.725021       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:32.518863648Z I1117 09:30:32.517093       1 request.go:696] Waited for 1.193482932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2025-11-17T09:30:33.326214703Z I1117 09:30:33.326152       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:33.517523462Z I1117 09:30:33.517467       1 request.go:696] Waited for 1.597836972s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-XXXXXX2
2025-11-17T09:30:34.716716823Z I1117 09:30:34.716650       1 request.go:696] Waited for 1.597246031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-XXXXXX2
2025-11-17T09:30:34.921491749Z I1117 09:30:34.921436       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:35.130942119Z I1117 09:30:35.130874       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/openshift-kube-scheduler-guard-XXXXXX2 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:35.147037703Z I1117 09:30:35.146980       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:31Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:35.161564511Z I1117 09:30:35.161505       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded changed from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready")
2025-11-17T09:30:35.716735768Z I1117 09:30:35.716696       1 request.go:696] Waited for 1.589928878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2025-11-17T09:30:36.121840947Z I1117 09:30:36.121779       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:36.917780108Z I1117 09:30:36.916675       1 request.go:696] Waited for 1.764375285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-XXXXXX1
2025-11-17T09:30:37.917081028Z I1117 09:30:37.917032       1 request.go:696] Waited for 1.795325229s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets
2025-11-17T09:30:37.922171699Z I1117 09:30:37.922112       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:39.116970075Z I1117 09:30:39.116911       1 request.go:696] Waited for 1.794371623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler-pod
2025-11-17T09:30:39.522313737Z I1117 09:30:39.522248       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-8 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:39.529807202Z I1117 09:30:39.529729       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 7 created because required secret/localhost-recovery-client-token has changed
2025-11-17T09:30:39.529807202Z I1117 09:30:39.529782       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2025-11-17T09:30:39.531833386Z W1117 09:30:39.531807       1 staticpod.go:38] revision 8 is unexpectedly already the XXXXXX available revision. This is a possible race!
2025-11-17T09:30:39.541914057Z E1117 09:30:39.541853       1 base_controller.go:268] RevisionController reconciliation failed: conflicting XXXXXXAvailableRevision 8
2025-11-17T09:30:39.542630399Z I1117 09:30:39.542594       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 8\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:31Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:39.550376810Z I1117 09:30:39.550335       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 8\nNodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:30:39.557026533Z I1117 09:30:39.556910       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:31Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:39.564848435Z I1117 09:30:39.563951       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 8\nNodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:30:40.117372856Z I1117 09:30:40.117321       1 request.go:696] Waited for 1.398302095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-XXXXXX2
2025-11-17T09:30:41.316866830Z I1117 09:30:41.316809       1 request.go:696] Waited for 1.596623511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:42.517124808Z I1117 09:30:42.517063       1 request.go:696] Waited for 1.594221096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2025-11-17T09:30:42.723045195Z I1117 09:30:42.722967       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-XXXXXX1 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:43.124269118Z I1117 09:30:43.124213       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/openshift-kube-scheduler-guard-XXXXXX2 -n openshift-kube-scheduler because it changed
2025-11-17T09:30:43.716715984Z I1117 09:30:43.716660       1 request.go:696] Waited for 1.397545926s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-XXXXXX2
2025-11-17T09:30:43.729303520Z I1117 09:30:43.729243       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:43.738759485Z I1117 09:30:43.737656       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing changed from False to True ("NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8"),Available message changed from "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7" to "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8"
2025-11-17T09:30:44.916312742Z I1117 09:30:44.916269       1 request.go:696] Waited for 1.396922573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/localhost-recovery-client-token
2025-11-17T09:30:45.722561679Z I1117 09:30:45.722320       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-XXXXXX2 -n openshift-kube-scheduler because it was missing
2025-11-17T09:30:45.916954268Z I1117 09:30:45.916906       1 request.go:696] Waited for 1.596778846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-XXXXXX1
2025-11-17T09:30:47.116771245Z I1117 09:30:47.116721       1 request.go:696] Waited for 1.3933162s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-8-XXXXXX1
2025-11-17T09:30:48.116881177Z I1117 09:30:48.116818       1 request.go:696] Waited for 1.396549183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-XXXXXX1
2025-11-17T09:30:49.117331786Z I1117 09:30:49.117254       1 request.go:696] Waited for 1.387558589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2025-11-17T09:30:49.527112499Z I1117 09:30:49.527060       1 installer_controller.go:524] node XXXXXX1 with revision 7 is the oldest and needs new revision 8
2025-11-17T09:30:49.527149608Z I1117 09:30:49.527114       1 installer_controller.go:532] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:30:49.527149608Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:30:49.527149608Z  CurrentRevision: (int32) 7,
2025-11-17T09:30:49.527149608Z  TargetRevision: (int32) 8,
2025-11-17T09:30:49.527149608Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:49.527149608Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:49.527149608Z  LastFailedReason: (string) "",
2025-11-17T09:30:49.527149608Z  LastFailedCount: (int) 0,
2025-11-17T09:30:49.527149608Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:49.527149608Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:49.527149608Z }
2025-11-17T09:30:49.539789066Z I1117 09:30:49.539726       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX1" from revision 7 to 8 because node XXXXXX1 with revision 7 is the oldest
2025-11-17T09:30:50.316762827Z I1117 09:30:50.316683       1 request.go:696] Waited for 1.191289746s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2025-11-17T09:30:51.317023587Z I1117 09:30:51.316932       1 request.go:696] Waited for 1.594002786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:52.317492036Z I1117 09:30:52.316983       1 request.go:696] Waited for 1.595653236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2025-11-17T09:30:53.317593968Z I1117 09:30:53.317151       1 request.go:696] Waited for 1.597531343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-XXXXXX2
2025-11-17T09:32:00.327169262Z W1117 09:32:00.327108       1 base_controller.go:232] Updating status of "GuardController" failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:32:00.327169262Z E1117 09:32:00.327148       1 base_controller.go:268] GuardController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods openshift-kube-scheduler-guard-XXXXXX2)
2025-11-17T09:32:00.924561804Z E1117 09:32:00.924513       1 base_controller.go:268] InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods openshift-kube-scheduler-XXXXXX1)
2025-11-17T09:32:18.921696711Z E1117 09:32:18.921643       1 leaderelection.go:327] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io openshift-cluster-kube-scheduler-operator-lock)
2025-11-17T09:32:27.029412841Z E1117 09:32:27.029362       1 base_controller.go:268] InstallerStateController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)
2025-11-17T09:32:52.196775407Z W1117 09:32:52.196516       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.196775407Z E1117 09:32:52.196563       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.396700114Z W1117 09:32:52.396652       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.396700114Z E1117 09:32:52.396688       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.596449761Z W1117 09:32:52.596398       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.596449761Z E1117 09:32:52.596439       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps?resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:54.500641724Z E1117 09:32:54.500584       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:54.553868950Z E1117 09:32:54.553817       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:55.397479366Z E1117 09:32:55.397423       1 leaderelection.go:327] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: leases.coordination.k8s.io "openshift-cluster-kube-scheduler-operator-lock" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "openshift-kube-scheduler-operator"
2025-11-17T09:32:55.397774494Z W1117 09:32:55.397747       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
2025-11-17T09:32:55.397803642Z E1117 09:32:55.397788       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
2025-11-17T09:32:55.399237535Z E1117 09:32:55.399189       1 base_controller.go:268] InstallerStateController reconciliation failed: pods is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "pods" in API group "" in the namespace "openshift-kube-scheduler"
2025-11-17T09:32:55.399270394Z W1117 09:32:55.399257       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "openshift-config"
2025-11-17T09:32:55.399277007Z E1117 09:32:55.399270       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "openshift-config"
2025-11-17T09:32:55.399670120Z E1117 09:32:55.399501       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get serviceaccounts installer-sa), kubeschedulers.operator.openshift.io "cluster" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot update resource "kubeschedulers/status" in API group "operator.openshift.io" at the cluster scope]
2025-11-17T09:32:55.400146777Z W1117 09:32:55.400132       1 reflector.go:533] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "openshift-kube-scheduler"
2025-11-17T09:32:55.400156427Z E1117 09:32:55.400150       1 reflector.go:148] k8s.io/client-go@v0.27.7/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot list resource "configmaps" in API group "" in the namespace "openshift-kube-scheduler"
2025-11-17T09:32:55.401080271Z E1117 09:32:55.401060       1 base_controller.go:268] StaticPodStateController reconciliation failed: kubeschedulers.operator.openshift.io "cluster" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot update resource "kubeschedulers/status" in API group "operator.openshift.io" at the cluster scope
2025-11-17T09:32:55.409120258Z E1117 09:32:55.408933       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): serviceaccounts "installer-sa" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-kube-scheduler", "manifests/installer-cluster-rolebinding.yaml" (string): clusterrolebindings.rbac.authorization.k8s.io "system:openshift:operator:openshift-kube-scheduler-installer" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "clusterrolebindings" in API group "rbac.authorization.k8s.io" at the cluster scope, kubeschedulers.operator.openshift.io "cluster" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot update resource "kubeschedulers/status" in API group "operator.openshift.io" at the cluster scope]
2025-11-17T09:32:56.008013480Z E1117 09:32:56.007973       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-scheduler/ns.yaml" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler), "assets/kube-scheduler/scheduler-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-scheduler/policyconfigmap-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-scheduler/policyconfigmap-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-scheduler/svc.yaml" (string): services "scheduler" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "services" in API group "" in the namespace "openshift-kube-scheduler", "assets/kube-scheduler/sa.yaml" (string): serviceaccounts "openshift-kube-scheduler-sa" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-kube-scheduler", "assets/kube-scheduler/localhost-recovery-client-crb.yaml" (string): clusterrolebindings.rbac.authorization.k8s.io "system:openshift:operator:kube-scheduler-recovery" is forbidden: User "system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator" cannot get resource "clusterrolebindings" in API group "rbac.authorization.k8s.io" at the cluster scope]
2025-11-17T09:32:56.414045628Z I1117 09:32:56.412953       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:56.431110282Z I1117 09:32:56.431067       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:32:56.597442954Z I1117 09:32:56.597395       1 request.go:696] Waited for 1.032348769s, retries: 1, retry-after: 5s - retry-reason: due to server-side throttling, FlowSchema UID: "" - request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=18963
2025-11-17T09:32:56.813549012Z I1117 09:32:56.813491       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:56.832069254Z E1117 09:32:56.832022       1 base_controller.go:268] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:32:56.832619415Z I1117 09:32:56.832601       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:56.872392312Z E1117 09:32:56.869424       1 base_controller.go:268] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:32:56.872392312Z I1117 09:32:56.869974       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:56.895416337Z E1117 09:32:56.893531       1 base_controller.go:268] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:32:56.895416337Z I1117 09:32:56.894185       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:56.999139237Z E1117 09:32:56.998528       1 base_controller.go:268] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:32:56.999139237Z I1117 09:32:56.999099       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:57.092827797Z E1117 09:32:57.091367       1 base_controller.go:268] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:32:57.106387387Z E1117 09:32:57.105760       1 base_controller.go:268] TargetConfigController reconciliation failed: synthetic requeue request
2025-11-17T09:32:57.132495774Z I1117 09:32:57.132429       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": configmaps \"serviceaccount-ca\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": configmaps \"scheduler-kubeconfig\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:32:57.157430842Z I1117 09:32:57.155237       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nNodeControllerDegraded: All XXXXXX nodes are ready" to "KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": configmaps \"serviceaccount-ca\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": configmaps \"scheduler-kubeconfig\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nNodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:32:57.795685737Z I1117 09:32:57.795640       1 request.go:696] Waited for 1.382840221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-8-XXXXXX1
2025-11-17T09:32:58.797637464Z I1117 09:32:58.797588       1 request.go:696] Waited for 2.197286147s, retries: 1, retry-after: 5s - retry-reason: due to server-side throttling, FlowSchema UID: "" - request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?resourceVersion=18961
2025-11-17T09:32:59.810615966Z I1117 09:32:59.810555       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-XXXXXX1 -n openshift-kube-scheduler because it was missing
2025-11-17T09:32:59.995305134Z I1117 09:32:59.995242       1 request.go:696] Waited for 3.06344774s, retries: 1, retry-after: 5s - retry-reason: due to server-side throttling, FlowSchema UID: "" - request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-XXXXXX1
2025-11-17T09:33:00.995680571Z I1117 09:33:00.995626       1 request.go:696] Waited for 3.595211925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2025-11-17T09:33:01.805457971Z I1117 09:33:01.805068       1 installer_controller.go:512] "XXXXXX1" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:33:02.195568857Z I1117 09:33:02.195507       1 request.go:696] Waited for 1.595668778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca
2025-11-17T09:33:03.196172528Z I1117 09:33:03.196119       1 request.go:696] Waited for 2.017028674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=18961
2025-11-17T09:33:04.395847373Z I1117 09:33:04.395796       1 request.go:696] Waited for 2.195352724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
2025-11-17T09:33:04.627615520Z I1117 09:33:04.627531       1 status_controller.go:215] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:35Z","message":"TargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": configmaps \"serviceaccount-ca\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": configmaps \"scheduler-kubeconfig\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:30:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:45Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:21Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:21Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:04.637245413Z I1117 09:33:04.637181       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"b27def28-8790-4113-bdf7-9bed9e00dbca", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "KubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/svc.yaml\" (string): services \"scheduler\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"services\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/sa.yaml\" (string): serviceaccounts \"openshift-kube-scheduler-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:kube-scheduler-recovery\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": configmaps \"serviceaccount-ca\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": configmaps \"scheduler-kubeconfig\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nNodeControllerDegraded: All XXXXXX nodes are ready" to "TargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": configmaps \"serviceaccount-ca\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": configmaps \"scheduler-kubeconfig\" is forbidden: User \"system:serviceaccount:openshift-kube-scheduler-operator:openshift-kube-scheduler-operator\" cannot get resource \"configmaps\" in API group \"\" in the namespace \"openshift-kube-scheduler\"\nNodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:33:05.398455717Z I1117 09:33:05.398390       1 request.go:696] Waited for 1.397299344s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-8-XXXXXX1
2025-11-17T09:33:05.409504401Z I1117 09:33:05.409455       1 installer_controller.go:512] "XXXXXX1" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:33:05.919088388Z I1117 09:33:05.919028       1 leaderelection.go:280] failed to renew lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: timed out waiting for the condition
2025-11-17T09:33:05.924719894Z W1117 09:33:05.924687       1 leaderelection.go:85] leader election lost
