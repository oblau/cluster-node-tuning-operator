---
apiVersion: v1
items:
- action: Scheduling
  apiVersion: v1
  eventTime: "2025-11-17T09:11:05.438671Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "3393"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: null
  message: '0/2 nodes are available: 2 node(s) had untolerated taint {node.kubernetes.io/not-ready:
    }. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling..'
  metadata:
    creationTimestamp: "2025-11-17T09:11:05Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-11-17T09:11:05Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c04708d1073a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "3396"
    uid: 45035069-fbcd-427e-b4f5-61edddd9b298
  reason: FailedScheduling
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-XXXXXX0
  source: {}
  type: Warning
- action: Scheduling
  apiVersion: v1
  eventTime: "2025-11-17T09:16:29.604912Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "3397"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: null
  message: '0/2 nodes are available: 2 node(s) had untolerated taint {node.kubernetes.io/not-ready:
    }. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling..'
  metadata:
    creationTimestamp: "2025-11-17T09:16:29Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-11-17T09:16:29Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c09282a14409
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "4405"
    uid: 1b515793-0c8f-49a1-90ab-28d1448a2d42
  reason: FailedScheduling
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-XXXXXX0
  source: {}
  type: Warning
- action: Binding
  apiVersion: v1
  eventTime: "2025-11-17T09:19:25.303766Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "3397"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: null
  message: Successfully assigned openshift-kube-controller-manager-operator/kube-controller-manager-operator-854f667594-xdqdb
    to XXXXXX2
  metadata:
    creationTimestamp: "2025-11-17T09:19:25Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-11-17T09:19:25Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0bb6b190440
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5550"
    uid: c3f8e291-08db-4f4b-aeaf-b29b80bcf2b5
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-XXXXXX0
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:19:25Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:19:25Z"
  message: 'Failed to create pod sandbox: rpc error: code = Unknown desc = failed
    to create pod network sandbox k8s_kube-controller-manager-operator-854f667594-xdqdb_openshift-kube-controller-manager-operator_51a636b0-a962-48ca-8962-e2a3905552a2_0(a858634d593699a158c3f66c9b41ca217d8c79cd056e0a4ed335c60e68fa1f54):
    No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider
    started?'
  metadata:
    creationTimestamp: "2025-11-17T09:19:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:19:25Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0bb931c840d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5622"
    uid: 1a7b6286-c073-4cce-870f-54d8d67bc6e2
  reason: FailedCreatePodSandBox
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:19:38Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:19:38Z"
  message: 'Failed to create pod sandbox: rpc error: code = Unknown desc = failed
    to create pod network sandbox k8s_kube-controller-manager-operator-854f667594-xdqdb_openshift-kube-controller-manager-operator_51a636b0-a962-48ca-8962-e2a3905552a2_0(3f77100be07e458270e482dbf0816e11f1096f7fe0e2d36478a7d230e01fdc69):
    No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider
    started?'
  metadata:
    creationTimestamp: "2025-11-17T09:19:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:19:38Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0be67e22b30
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5799"
    uid: 9b44019b-d20e-4e8c-9238-feb3028f40cf
  reason: FailedCreatePodSandBox
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:19:50Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:19:50Z"
  message: 'Failed to create pod sandbox: rpc error: code = Unknown desc = failed
    to create pod network sandbox k8s_kube-controller-manager-operator-854f667594-xdqdb_openshift-kube-controller-manager-operator_51a636b0-a962-48ca-8962-e2a3905552a2_0(188f77c39fee17c0bb31255043bfeb578e455e9cdd19eb2dececa250fdcc01f9):
    No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider
    started?'
  metadata:
    creationTimestamp: "2025-11-17T09:19:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:19:50Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c13175b589
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5875"
    uid: 69f1d27e-f4e3-49c8-8187-e34ab6a543bd
  reason: FailedCreatePodSandBox
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:00Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:00Z"
  message: 'Failed to create pod sandbox: rpc error: code = Unknown desc = failed
    to create pod network sandbox k8s_kube-controller-manager-operator-854f667594-xdqdb_openshift-kube-controller-manager-operator_51a636b0-a962-48ca-8962-e2a3905552a2_0(37696a7b3899c7e835f1311f7801648405483918b1c2d6b1f30df1c71cf30185):
    No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider
    started?'
  metadata:
    creationTimestamp: "2025-11-17T09:20:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:20:00Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c38fd2232e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6041"
    uid: 11b12f7b-dc46-4655-939f-f54017707893
  reason: FailedCreatePodSandBox
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:14Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6028"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:14Z"
  message: Add eth0 [10.129.0.25/23 fd02:0:0:2::19/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:20:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:20:14Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c6c865ce7d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6121"
    uid: 7b68493d-24af-46fd-9515-81ce620c2915
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:14Z"
  message: Pulling image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd509e6bc6df891aaf6057a0c9d6228e5fd198fe3c00bfd66a30cb3fc21f60f"
  metadata:
    creationTimestamp: "2025-11-17T09:20:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:20:14Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c6ca03d580
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6123"
    uid: ddd44e14-9e93-4bf6-95a4-265992440711
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:21Z"
  message: Successfully pulled image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd509e6bc6df891aaf6057a0c9d6228e5fd198fe3c00bfd66a30cb3fc21f60f"
    in 7.55022371s (7.550243853s including waiting)
  metadata:
    creationTimestamp: "2025-11-17T09:20:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:20:21Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c88c0bc813
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6477"
    uid: 45ba737e-7072-42b4-895b-61e3f6e6c53d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:13Z"
  message: Created container kube-controller-manager-operator
  metadata:
    creationTimestamp: "2025-11-17T09:20:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:13Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c897179f5b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19572"
    uid: 95e02796-9408-42cf-a7c7-53fb92371064
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:13Z"
  message: Started container kube-controller-manager-operator
  metadata:
    creationTimestamp: "2025-11-17T09:20:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:13Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0c8985d6271
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19575"
    uid: f8834231-75cf-43c5-813e-99fce64b7285
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:48Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:13Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd509e6bc6df891aaf6057a0c9d6228e5fd198fe3c00bfd66a30cb3fc21f60f"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:21:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:13Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c0dca8ba352a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19566"
    uid: 778f4ed9-13ce-4204-8689-24825fc49f27
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:26:45Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-controller-manager-operator}
    kind: Pod
    name: kube-controller-manager-operator-854f667594-xdqdb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "5515"
    uid: 51a636b0-a962-48ca-8962-e2a3905552a2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:02Z"
  message: Back-off restarting failed container kube-controller-manager-operator in
    pod kube-controller-manager-operator-854f667594-xdqdb_openshift-kube-controller-manager-operator(51a636b0-a962-48ca-8962-e2a3905552a2)
  metadata:
    creationTimestamp: "2025-11-17T09:27:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-controller-manager-operator-854f667594-xdqdb.1878c121eb65598b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19289"
    uid: 7a236fba-b648-4e7e-97cd-24a613fbed63
  reason: BackOff
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 16
  eventTime: null
  firstTimestamp: "2025-11-17T09:05:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: kube-controller-manager-operator-854f667594
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "1349"
    uid: 18c76f8a-b69c-403b-be8d-c5f0862f3b71
  kind: Event
  lastTimestamp: "2025-11-17T09:08:21Z"
  message: 'Error creating: pods "kube-controller-manager-operator-854f667594-" is
    forbidden: autoscaling.openshift.io/ManagementCPUsOverride the cluster does not
    have any nodes'
  metadata:
    creationTimestamp: "2025-11-17T09:05:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-11-17T09:08:21Z"
    name: kube-controller-manager-operator-854f667594.1878bffabb1b1e95
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "2812"
    uid: 58d3b353-5f70-49d8-ab8a-5b0c94b78e22
  reason: FailedCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:11:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: kube-controller-manager-operator-854f667594
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "1353"
    uid: 18c76f8a-b69c-403b-be8d-c5f0862f3b71
  kind: Event
  lastTimestamp: "2025-11-17T09:11:05Z"
  message: 'Created pod: kube-controller-manager-operator-854f667594-xdqdb'
  metadata:
    creationTimestamp: "2025-11-17T09:11:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-11-17T09:11:05Z"
    name: kube-controller-manager-operator-854f667594.1878c04708c51443
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "3394"
    uid: 95c820a0-929b-4a8e-a4ae-3f1d9658bba2
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-controller-manager-operator-lock
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6551"
    uid: 35c308bc-048c-4f6a-821b-922780b1aecf
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: kube-controller-manager-operator-854f667594-xdqdb_411e6768-d3ca-4faa-9e1b-df2b4d6588f5
    became leader
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator-lock.1878c0c8c36ce5d6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6552"
    uid: 4334e2e7-cd5f-4984-b82f-c3f82b2332a4
  reason: LeaderElection
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:49Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-controller-manager-operator-lock
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10055"
    uid: 35c308bc-048c-4f6a-821b-922780b1aecf
  kind: Event
  lastTimestamp: "2025-11-17T09:21:49Z"
  message: kube-controller-manager-operator-854f667594-xdqdb_27ad96ce-f871-4a33-b2ee-75377ae3a60b
    became leader
  metadata:
    creationTimestamp: "2025-11-17T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:49Z"
    name: kube-controller-manager-operator-lock.1878c0dceaba887f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10056"
    uid: cab3deb1-5f57-4b0c-8135-ba1620263e0e
  reason: LeaderElection
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:36Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-controller-manager-operator-lock
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15372"
    uid: 35c308bc-048c-4f6a-821b-922780b1aecf
  kind: Event
  lastTimestamp: "2025-11-17T09:29:36Z"
  message: kube-controller-manager-operator-854f667594-xdqdb_a285a008-7dba-4235-88fb-8392e871cbbf
    became leader
  metadata:
    creationTimestamp: "2025-11-17T09:29:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:36Z"
    name: kube-controller-manager-operator-lock.1878c149b417ae0c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15373"
    uid: 9651df3d-2a2d-46a5-9dfb-49c16a5710dc
  reason: LeaderElection
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:13Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: kube-controller-manager-operator-lock
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19584"
    uid: 35c308bc-048c-4f6a-821b-922780b1aecf
  kind: Event
  lastTimestamp: "2025-11-17T09:33:13Z"
  message: kube-controller-manager-operator-854f667594-xdqdb_ccfd78ca-edf6-4b6e-a9fd-3ce89f61f677
    became leader
  metadata:
    creationTimestamp: "2025-11-17T09:33:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:13Z"
    name: kube-controller-manager-operator-lock.1878c17c57dcc0f2
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19587"
    uid: cf57d7c6-46fb-4370-b760-b761deec65fe
  reason: LeaderElection
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:05:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "1348"
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:05:37Z"
  message: Scaled up replica set kube-controller-manager-operator-854f667594 to 1
  metadata:
    creationTimestamp: "2025-11-17T09:05:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-11-17T09:05:37Z"
    name: kube-controller-manager-operator.1878bffabae3a060
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "1350"
    uid: da37e9d9-c536-47fb-9b16-5d3ddb263c69
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure",
    "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource",
    "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP",
    "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController",
    "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration",
    "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass",
    "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8c39efd22
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6554"
    uid: 085aa195-a1e7-4b12-ac86-4fdda04ef507
  reason: FeatureGatesInitialized
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: Observed new XXXXXX node XXXXXX1
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8ca5e225f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6567"
    uid: cfc194fc-31dd-4364-a61f-209b0e8da298
  reason: MasterNodeObserved
  reportingComponent: kube-controller-manager-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: Observed new XXXXXX node XXXXXX2
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8ca5e51d5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6569"
    uid: 304893b6-b1a9-42f7-b959-bb65986ef1f3
  reason: MasterNodeObserved
  reportingComponent: kube-controller-manager-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: clusteroperator/kube-controller-manager version "raw-internal" changed
    from "" to "4.14.59"
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8ca70e33d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6568"
    uid: 95323296-460b-4c13-8b4c-d802172e343f
  reason: OperatorVersionChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded set
    to Unknown (""),Progressing set to Unknown (""),Available set to Unknown (""),Upgradeable
    set to Unknown (""),EvaluationConditionsDetected set to Unknown (""),status.relatedObjects
    changed from [{"operator.openshift.io" "kubecontrollermanagers" "" "cluster"}
    {"" "namespaces" "" "openshift-config"} {"" "namespaces" "" "openshift-config-managed"}
    {"" "namespaces" "" "openshift-kube-controller-manager"} {"" "namespaces" "" "openshift-kube-controller-manager-operator"}
    {"" "namespaces" "" "kube-system"} {"" "nodes" "" ""} {"certificates.k8s.io" "certificatesigningrequests"
    "" ""}] to [{"operator.openshift.io" "kubecontrollermanagers" "" "cluster"} {""
    "namespaces" "" "openshift-config"} {"" "namespaces" "" "openshift-config-managed"}
    {"" "namespaces" "" "openshift-kube-controller-manager"} {"" "namespaces" "" "openshift-kube-controller-manager-operator"}
    {"" "namespaces" "" "kube-system"} {"certificates.k8s.io" "certificatesigningrequests"
    "" ""} {"" "nodes" "" ""} {"config.openshift.io" "nodes" "" "cluster"}],status.versions
    changed from [] to [{"raw-internal" "4.14.59"}]'
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8cabb3ec8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6572"
    uid: e9e85475-09d7-49e2-8a07-36a74c835800
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:22Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Upgradeable
    changed from Unknown to True ("All is well")'
  metadata:
    creationTimestamp: "2025-11-17T09:20:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:22Z"
    name: kube-controller-manager-operator.1878c0c8cfba04a1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6580"
    uid: 8fb2897d-d7e7-4ad6-bcad-c70f2b959d87
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from Unknown to False ("NodeControllerDegraded: All XXXXXX nodes are ready")'
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c8db9cc8f5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6593"
    uid: 89a54547-95d6-43c6-a0de-fbd45b7efb68
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: Updated featureGates to AdminNetworkPolicy=false,AdmissionWebhookMatchConditions=false,AlibabaPlatform=true,AutomatedEtcdBackup=false,AzureWorkloadIdentity=true,BuildCSIVolumes=true,CSIDriverSharedResource=false,CloudDualStackNodeIPs=true,DynamicResourceAllocation=false,EventedPLEG=false,ExternalCloudProvider=false,ExternalCloudProviderAzure=true,ExternalCloudProviderExternal=true,ExternalCloudProviderGCP=false,GCPLabelsTags=false,GatewayAPI=false,InsightsConfigAPI=false,MachineAPIOperatorDisableMachineHealthCheckController=false,MachineAPIProviderOpenStack=false,MaxUnavailableStatefulSet=false,NetworkLiveMigration=false,NodeSwap=false,OpenShiftPodSecurityAdmission=false,PrivateHostedZoneAWS=true,RetroactiveDefaultStorageClass=false,RouteExternalCertificate=false,SigstoreImageVerification=false,VSphereStaticIPs=false,ValidatingAdmissionPolicy=false
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c90010f12e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6621"
    uid: ef4fc4bc-a6cd-4a62-b4aa-5c42ceb1e34e
  reason: ObserveFeatureFlagsUpdated
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: Updated extendedArguments.feature-gates to AdminNetworkPolicy=false,AdmissionWebhookMatchConditions=false,AlibabaPlatform=true,AutomatedEtcdBackup=false,AzureWorkloadIdentity=true,BuildCSIVolumes=true,CSIDriverSharedResource=false,CloudDualStackNodeIPs=true,DynamicResourceAllocation=false,EventedPLEG=false,ExternalCloudProviderAzure=true,ExternalCloudProviderExternal=true,ExternalCloudProviderGCP=false,GCPLabelsTags=false,GatewayAPI=false,InsightsConfigAPI=false,MachineAPIOperatorDisableMachineHealthCheckController=false,MachineAPIProviderOpenStack=false,MaxUnavailableStatefulSet=false,NetworkLiveMigration=false,NodeSwap=false,OpenShiftPodSecurityAdmission=false,PrivateHostedZoneAWS=true,RetroactiveDefaultStorageClass=false,RouteExternalCertificate=false,SigstoreImageVerification=false,VSphereStaticIPs=false,ValidatingAdmissionPolicy=false
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c90011f255
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6623"
    uid: 7421ca6d-1293-4513-9ee9-0383e5b14ff2
  reason: ObserveFeatureFlagsUpdated
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: minTLSVersion changed to VersionTLS12
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c900126f7f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6624"
    uid: a6b28d6b-736c-475b-a524-70b86bdb54e9
  reason: ObserveTLSSecurityProfile
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"
    "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"
    "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c90012d47a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6626"
    uid: 5540d3e5-55c9-414d-bbdf-96d15ef9d571
  reason: ObserveTLSSecurityProfile
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: "Writing updated observed config:   map[string]any{\n+ \t\"extendedArguments\":
    map[string]any{\n+ \t\t\"cluster-cidr\": []any{string(\"10.128.0.0/14\"), string(\"fd02::/48\")},\n+ \t\t\"cluster-name\":
    []any{string(\"hlxcl51-5vf88\")},\n+ \t\t\"feature-gates\": []any{\n+ \t\t\tstring(\"AdminNetworkPolicy=false\"),\n+ \t\t\tstring(\"AdmissionWebhookMatchConditions=false\"),\n+ \t\t\tstring(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"),\n+ \t\t\tstring(\"AzureWorkloadIdentity=true\"),
    string(\"BuildCSIVolumes=true\"),\n+ \t\t\tstring(\"CSIDriverSharedResource=false\"),
    string(\"CloudDualStackNodeIPs=true\"),\n+ \t\t\t...,\n+ \t\t},\n+ \t\t\"service-cluster-ip-range\":
    []any{string(\"172.30.0.0/16,fd03::/112\")},\n+ \t},\n+ \t\"featureGates\": []any{\n+ \t\tstring(\"AdminNetworkPolicy=false\"),\n+ \t\tstring(\"AdmissionWebhookMatchConditions=false\"),\n+ \t\tstring(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"),\n+ \t\tstring(\"AzureWorkloadIdentity=true\"),
    string(\"BuildCSIVolumes=true\"),\n+ \t\tstring(\"CSIDriverSharedResource=false\"),
    string(\"CloudDualStackNodeIPs=true\"),\n+ \t\tstring(\"DynamicResourceAllocation=false\"),
    string(\"EventedPLEG=false\"),\n+ \t\tstring(\"ExternalCloudProvider=false\"),\n+ \t\tstring(\"ExternalCloudProviderAzure=true\"),\n+ \t\tstring(\"ExternalCloudProviderExternal=true\"),\n+ \t\tstring(\"ExternalCloudProviderGCP=false\"),
    string(\"GCPLabelsTags=false\"),\n+ \t\tstring(\"GatewayAPI=false\"), ...,\n+ \t},\n+ \t\"servingInfo\":
    map[string]any{\n+ \t\t\"cipherSuites\": []any{\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\"),\n+ \t\t\tstring(\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\"),\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"),\n+ \t\t\tstring(\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"),\n+ \t\t\tstring(\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\"),\n+ \t\t\tstring(\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"),\n+ \t\t},\n+ \t\t\"minTLSVersion\":
    string(\"VersionTLS12\"),\n+ \t},\n  }\n"
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c900177f69
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6628"
    uid: b00ea192-fac9-47b0-82fa-4d9c9b40573b
  reason: ObservedConfigChanged
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:23Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    changed from Unknown to False ("All is well")'
  metadata:
    creationTimestamp: "2025-11-17T09:20:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:23Z"
    name: kube-controller-manager-operator.1878c0c9009f4b2b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6627"
    uid: 849cf980-584b-435f-924f-6940b38837d4
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 13
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:26Z"
  message: 'configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0'
  metadata:
    creationTimestamp: "2025-11-17T09:20:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:30Z"
    name: kube-controller-manager-operator.1878c0c917f943b1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7200"
    uid: 63bf8fe6-60c6-41f7-8458-d9bcddad4f0f
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:24Z"
  message: Created PodDisruptionBudget.policy/kube-controller-manager-guard-pdb -n
    openshift-kube-controller-manager because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:24Z"
    name: kube-controller-manager-operator.1878c0c91831a95e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6664"
    uid: 6e4dfe15-05a9-46a0-b4a0-abb6e417b145
  reason: PodDisruptionBudgetCreated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:24Z"
  message: new revision 1 triggered by "configmap \"kube-controller-manager-pod\"
    not found"
  metadata:
    creationTimestamp: "2025-11-17T09:20:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:24Z"
    name: kube-controller-manager-operator.1878c0c923cee517
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6681"
    uid: 65aecf94-5eb7-4e5c-a36f-ffce185b4ce6
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:24Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]",Progressing
    message changed from "All is well" to "NodeInstallerProgressing: 2 nodes are at
    revision 0",Available changed from Unknown to False ("StaticPodsAvailable: 0 nodes
    are active; 2 nodes are at revision 0")'
  metadata:
    creationTimestamp: "2025-11-17T09:20:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:24Z"
    name: kube-controller-manager-operator.1878c0c924784b97
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6689"
    uid: 5a44863f-90e0-4ed7-aa84-42f3d8545da9
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:24Z"
  message: '"csr-controller-signer-ca" in "openshift-kube-controller-manager-operator"
    requires a new cert'
  metadata:
    creationTimestamp: "2025-11-17T09:20:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:24Z"
    name: kube-controller-manager-operator.1878c0c92fb72d3c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6704"
    uid: c32e9666-72e4-4c9b-bcf6-71f2a0b0a4e8
  reason: CABundleUpdateRequired
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:24Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]" to
    "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:25Z"
    name: kube-controller-manager-operator.1878c0c948488d77
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6766"
    uid: aeedb682-fb2f-4f15-bba0-f91db9152e91
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:25Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:25Z"
    name: kube-controller-manager-operator.1878c0c9602435c4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6786"
    uid: e961100d-5a36-4480-8b52-5c697ac64fa9
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:25Z"
  message: Created ConfigMap/revision-status-1 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:26Z"
    name: kube-controller-manager-operator.1878c0c96b3f9cbc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6817"
    uid: e81eaa86-7b37-4193-afaf-059c96566e48
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:25Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:26Z"
    name: kube-controller-manager-operator.1878c0c977e9acc2
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6829"
    uid: 092029fc-44c7-499f-8430-a3bc653122fd
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:25Z"
  message: Created ConfigMap/csr-controller-signer-ca -n openshift-kube-controller-manager-operator
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:26Z"
    name: kube-controller-manager-operator.1878c0c98316c576
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6861"
    uid: 5cc12fc0-97d7-48e2-87df-aafd6f298bb5
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:25Z"
  message: '"csr-signer" in "openshift-kube-controller-manager-operator" requires
    a new target cert/key pair: missing notAfter'
  metadata:
    creationTimestamp: "2025-11-17T09:20:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:27Z"
    name: kube-controller-manager-operator.1878c0c983181821
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6907"
    uid: 60d95d1b-fcd2-4a17-9031-c280f0be7d28
  reason: TargetUpdateRequired
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:26Z"
  message: Deleted target configmap openshift-config-managed/csr-controller-ca because
    source config does not exist
  metadata:
    creationTimestamp: "2025-11-17T09:20:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:26Z"
    name: kube-controller-manager-operator.1878c0c98ef328c6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6877"
    uid: 08999627-0748-4e4a-8abe-a3c74e427503
  reason: TargetConfigDeleted
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:26Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:27Z"
    name: kube-controller-manager-operator.1878c0c99bd31c00
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6892"
    uid: f57e5fad-4204-4d22-96c3-8a1a13116861
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 24
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:38Z"
  message: 'unexpected addresses: XXXXXXXXXXX'
  metadata:
    creationTimestamp: "2025-11-17T09:20:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:38Z"
    name: kube-controller-manager-operator.1878c0c9ca8c4b44
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "9286"
    uid: 0ffe5744-beab-482d-804b-93f228e363e6
  reason: SATokenSignerControllerStuck
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: Created Secret/csr-signer -n openshift-kube-controller-manager-operator
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:28Z"
    name: kube-controller-manager-operator.1878c0c9d68b94a5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6963"
    uid: d4ff352c-08a1-4be8-915f-17d30d9af503
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: Created ConfigMap/service-ca -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:28Z"
    name: kube-controller-manager-operator.1878c0c9e283e69a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "6983"
    uid: dd378086-8525-425d-a3ba-444c9ac97f79
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 27
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:48Z"
  message: new revision 2 triggered by "configmap \"kube-controller-manager-pod\"
    not found"
  metadata:
    creationTimestamp: "2025-11-17T09:20:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:48Z"
    name: kube-controller-manager-operator.1878c0c9e2eb7b30
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8228"
    uid: f92091a8-b960-4c48-94d2-8ccc83b8c231
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 9
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:33Z"
  message: 'configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1'
  metadata:
    creationTimestamp: "2025-11-17T09:20:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:36Z"
    name: kube-controller-manager-operator.1878c0c9e2f6f04f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7699"
    uid: 4bd0e745-d13f-4c81-96d6-7b504503af4b
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: Created ServiceAccount/installer-sa -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:28Z"
    name: kube-controller-manager-operator.1878c0c9ee5dd873
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7001"
    uid: d10bbcd5-237d-4d5a-abf7-4c12278b2109
  reason: ServiceAccountCreated
  reportingComponent: kube-controller-manager-operator-backingresourcecontroller-backingresourcecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-backingresourcecontroller-backingresourcecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:openshift-kube-controller-manager-installer
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:29Z"
    name: kube-controller-manager-operator.1878c0c9ee979084
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7113"
    uid: 01bbafb6-8b4c-42c7-abce-9319447c751f
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-controller-manager-operator-backingresourcecontroller-backingresourcecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-backingresourcecontroller-backingresourcecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: Updated Namespace/openshift-kube-controller-manager because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:20:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:29Z"
    name: kube-controller-manager-operator.1878c0c9fa5091b1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7019"
    uid: 65e0ac3d-61af-4058-ae01-b7ff7263aef7
  reason: NamespaceUpdated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:27Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-0,config-0,controller-manager-kubeconfig-0,kube-controller-cert-syncer-kubeconfig-0,kube-controller-manager-pod-0,recycler-config-0,service-ca-0,serviceaccount-ca-0,
    secrets: localhost-recovery-client-token-0,service-account-private-key-0]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: aggregator-client-ca,client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found",Progressing changed from
    False to True ("NodeInstallerProgressing: 2 nodes are at revision 0; 0 nodes have
    achieved new revision 1"),Available message changed from "StaticPodsAvailable:
    0 nodes are active; 2 nodes are at revision 0" to "StaticPodsAvailable: 0 nodes
    are active; 2 nodes are at revision 0; 0 nodes have achieved new revision 1"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:29Z"
    name: kube-controller-manager-operator.1878c0c9fb32738b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7033"
    uid: 2781bec5-3a7b-4e75-93b0-715946e7fd47
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:28Z"
  message: Created ConfigMap/config -n openshift-kube-controller-manager because it
    was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:29Z"
    name: kube-controller-manager-operator.1878c0ca0635e5f8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7047"
    uid: 00146e1a-9df6-429f-a87b-086f590df864
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:28Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:28Z"
  message: Created Secret/service-account-private-key -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:29Z"
    name: kube-controller-manager-operator.1878c0ca1e0f1302
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7074"
    uid: 6afef869-efaa-426a-8ef1-bc50a28153df
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:29Z"
  message: Created ConfigMap/revision-status-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:30Z"
    name: kube-controller-manager-operator.1878c0ca41c8469a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7171"
    uid: 771785ab-34f2-402a-902e-60ee33267858
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:29Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:30Z"
    name: kube-controller-manager-operator.1878c0ca4dc330d7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7178"
    uid: 70f47400-f15a-43c9-b51f-23aa3c018d9e
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:29Z"
  message: Created RoleBinding.rbac.authorization.k8s.io/system:openshift:leader-locking-kube-controller-manager
    -n kube-system because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:31Z"
    name: kube-controller-manager-operator.1878c0ca4e0f8223
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7231"
    uid: 3c8a2e7f-73c3-4412-bc81-8b1971bd64c9
  reason: RoleBindingCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:29Z"
  message: Created Role.rbac.authorization.k8s.io/system:openshift:leader-election-lock-cluster-policy-controller
    -n openshift-kube-controller-manager because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:32Z"
    name: kube-controller-manager-operator.1878c0ca4e43fd50
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7361"
    uid: 44973b45-6e2d-4b7d-b046-47ad9ac936e0
  reason: RoleCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:29Z"
  message: Created RoleBinding.rbac.authorization.k8s.io/system:openshift:leader-election-lock-cluster-policy-controller
    -n openshift-kube-controller-manager because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:33Z"
    name: kube-controller-manager-operator.1878c0ca4e8f8350
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7435"
    uid: 0896f55f-78ba-4bc8-9002-a688b8c10365
  reason: RoleBindingCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:30Z"
  message: observed change in config
  metadata:
    creationTimestamp: "2025-11-17T09:20:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:32Z"
    name: kube-controller-manager-operator.1878c0ca73ad9d4c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7383"
    uid: 20661742-b6e4-4bae-8413-1ab4dc36ac1c
  reason: ObserveServiceCAConfigMap
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:30Z"
  message: "Writing updated observed config:   map[string]any{\n  \t\"extendedArguments\":
    map[string]any{\"cluster-cidr\": []any{string(\"10.128.0.0/14\"), string(\"fd02::/48\")},
    \"cluster-name\": []any{string(\"hlxcl51-5vf88\")}, \"feature-gates\": []any{string(\"AdminNetworkPolicy=false\"),
    string(\"AdmissionWebhookMatchConditions=false\"), string(\"AlibabaPlatform=true\"),
    string(\"AutomatedEtcdBackup=false\"), ...}, \"service-cluster-ip-range\": []any{string(\"172.30.0.0/16,fd03::/112\")}},\n  \t\"featureGates\":
    \     []any{string(\"AdminNetworkPolicy=false\"), string(\"AdmissionWebhookMatchConditions=false\"),
    string(\"AlibabaPlatform=true\"), string(\"AutomatedEtcdBackup=false\"), ...},\n+ \t\"serviceServingCert\":
    map[string]any{\n+ \t\t\"certFile\": string(\"/etc/kubernetes/static-pod-resources/configmaps/service-ca/ca-bundle.crt\"),\n+ \t},\n  \t\"servingInfo\":
    map[string]any{\"cipherSuites\": []any{string(\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\"),
    string(\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\"), string(\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"),
    string(\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"), ...}, \"minTLSVersion\": string(\"VersionTLS12\")},\n  }\n"
  metadata:
    creationTimestamp: "2025-11-17T09:20:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:33Z"
    name: kube-controller-manager-operator.1878c0ca73bd51e4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7448"
    uid: 0dcf0c36-0fb2-4b4b-a8e8-eb5ac650f710
  reason: ObservedConfigChanged
  reportingComponent: kube-controller-manager-operator-config-observer-configobserver
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-config-observer-configobserver
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:31Z"
  message: Created ConfigMap/cluster-policy-controller-config -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:32Z"
    name: kube-controller-manager-operator.1878c0cab908b696
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7315"
    uid: 70b6ce4d-657c-45ce-ba0f-b10dc1cec529
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:32Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:32Z"
  message: Created Service/kube-controller-manager -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:33Z"
    name: kube-controller-manager-operator.1878c0cb188643e0
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7538"
    uid: 1d7d6f7d-9357-4e4b-8727-1572c49af9af
  reason: ServiceCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:33Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:33Z"
  message: Created ConfigMap/recycler-config -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:34Z"
    name: kube-controller-manager-operator.1878c0cb480d27c6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7568"
    uid: 57796281-72a7-486b-ba69-557b2fbe20da
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:35Z"
  message: Created ServiceAccount/kube-controller-manager-sa -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:35Z"
    name: kube-controller-manager-operator.1878c0cba76339d4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7645"
    uid: 97e25e0a-c4d7-460d-98b8-b4e9dea11b2f
  reason: ServiceAccountCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:37Z"
  message: Created ConfigMap/csr-signer-ca -n openshift-kube-controller-manager-operator
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:37Z"
    name: kube-controller-manager-operator.1878c0cc1ea895ff
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7729"
    uid: 7a98e534-ae5d-4d41-95a6-21bba1dbca56
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:37Z"
  message: Created ServiceAccount/pv-recycler-controller -n openshift-infra because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:37Z"
    name: kube-controller-manager-operator.1878c0cc2a884120
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7749"
    uid: afea6c89-586d-4056-bd96-9f0523574e95
  reason: ServiceAccountCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:37Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:kube-controller-manager-recovery
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:38Z"
    name: kube-controller-manager-operator.1878c0cc2abf8972
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7784"
    uid: d44729bc-6acc-47db-adde-335a69a4a2c9
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:37Z"
  message: Created ConfigMap/aggregator-client-ca -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:38Z"
    name: kube-controller-manager-operator.1878c0cc36819ddf
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7757"
    uid: 7e8c336d-feba-47c1-85da-2e9fa81b8712
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:38Z"
  message: Created ConfigMap/csr-controller-ca -n openshift-kube-controller-manager-operator
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:39Z"
    name: kube-controller-manager-operator.1878c0cc89f1d551
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7821"
    uid: 006dbed5-5bd2-4a14-a837-8dcfab02d331
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:39Z"
  message: Created ServiceAccount/localhost-recovery-client -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:39Z"
    name: kube-controller-manager-operator.1878c0cc95d9d6dd
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7830"
    uid: dd1fef87-e5ec-472e-817b-0fec5bd2e2c0
  reason: ServiceAccountCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created Secret/localhost-recovery-client-token -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:40Z"
    name: kube-controller-manager-operator.1878c0ccd1670095
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7875"
    uid: 1a03bd77-b5ca-4c62-8843-d26e6b70ce99
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created ClusterRole.rbac.authorization.k8s.io/system:openshift:controller:cluster-csr-approver-controller
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:40Z"
    name: kube-controller-manager-operator.1878c0ccd19e5a0d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7891"
    uid: 436f0608-e9a8-4d86-b5ac-34bdf2208e51
  reason: ClusterRoleCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:controller:cluster-csr-approver-controller
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:40Z"
    name: kube-controller-manager-operator.1878c0ccd1dedb4f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7908"
    uid: 73e0ac63-5aff-41cc-84cc-81cddcda8f77
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created ClusterRole.rbac.authorization.k8s.io/system:openshift:kube-controller-manager:gce-cloud-provider
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:41Z"
    name: kube-controller-manager-operator.1878c0ccd21abfab
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7929"
    uid: d6130465-f325-4fdb-a653-b3a3008fc4ba
  reason: ClusterRoleCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:kube-controller-manager:gce-cloud-provider
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:41Z"
    name: kube-controller-manager-operator.1878c0ccd25205ed
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7944"
    uid: 30e837c3-8919-4aba-b62f-5135975f18b5
  reason: ClusterRoleBindingCreated
  reportingComponent: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-kubecontrollermanagerstaticresources-kubecontrollermanagerstaticresources
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:40Z"
  message: Created ConfigMap/csr-controller-ca -n openshift-config-managed because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:40Z"
    name: kube-controller-manager-operator.1878c0ccdd6dced7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7917"
    uid: cc3aadc9-b44e-4026-b976-39b3dcdd28c6
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:41Z"
  message: 'configmaps: client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1'
  metadata:
    creationTimestamp: "2025-11-17T09:20:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:42Z"
    name: kube-controller-manager-operator.1878c0cd0daafbcc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8002"
    uid: c4f64dfc-0a73-42af-8c9a-b99a05185b9f
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:41Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets:
    csr-signer,kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:41Z"
    name: kube-controller-manager-operator.1878c0cd0e96b108
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "7975"
    uid: edf189f7-4f4b-415f-8b50-0a3d038ece01
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:41Z"
  message: Created Secret/csr-signer -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:42Z"
    name: kube-controller-manager-operator.1878c0cd30d1479c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8015"
    uid: 423b89b1-4ede-4462-9f96-5d274699309a
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 6
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:53Z"
  message: 'configmaps: client-ca, secrets: kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1'
  metadata:
    creationTimestamp: "2025-11-17T09:20:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:53Z"
    name: kube-controller-manager-operator.1878c0cda08f3aa7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8394"
    uid: ed309f36-52a4-46e1-85a7-37db3a788507
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:43Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:43Z"
    name: kube-controller-manager-operator.1878c0cda0e6d2d5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8055"
    uid: c1a1a879-dfd9-41fb-8ba0-f2a5edbd06b4
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:43Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: client-ca, secrets: csr-signer,kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key, configmaps:
    cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:44Z"
    name: kube-controller-manager-operator.1878c0cda15ac4ce
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8069"
    uid: adb6cd08-3ed5-4b18-b2e9-40c3bf10f75f
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:44Z"
  message: Created ConfigMap/serviceaccount-ca -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:44Z"
    name: kube-controller-manager-operator.1878c0cdbfd59ced
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8085"
    uid: eccc9e24-d8e2-44e2-bdd6-8c8b6d8e7e51
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:48Z"
  message: Created ConfigMap/controller-manager-kubeconfig -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:48Z"
    name: kube-controller-manager-operator.1878c0cec626a3ae
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8223"
    uid: f5c18bc9-6b90-48b6-828a-be60b77f39be
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:51Z"
  message: Created ConfigMap/kube-controller-manager-pod -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:51Z"
    name: kube-controller-manager-operator.1878c0cf78ee1b89
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8285"
    uid: 5b4ffa14-0052-4c98-9df2-b4f0eb40920b
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:51Z"
  message: new revision 2 triggered by "configmap \"kube-controller-manager-pod-1\"
    not found"
  metadata:
    creationTimestamp: "2025-11-17T09:20:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:51Z"
    name: kube-controller-manager-operator.1878c0cf78f40db6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8286"
    uid: 6c126c0a-6ac9-4d5d-92e3-ef6a5406f089
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:52Z"
  message: |-
    Updated ConfigMap/revision-status-2 -n openshift-kube-controller-manager:
    cause by changes in data.reason
  metadata:
    creationTimestamp: "2025-11-17T09:20:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:52Z"
    name: kube-controller-manager-operator.1878c0cfa8c3f0e8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8355"
    uid: 76035ce1-a6e3-417d-be07-8e0d5378f42b
  reason: ConfigMapUpdated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:53Z"
  message: Created ConfigMap/kube-controller-manager-pod-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:53Z"
    name: kube-controller-manager-operator.1878c0cfe4568572
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8386"
    uid: e24ba5bc-4951-435a-bc87-f5d7037985da
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:53Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX2, Missing operand on node XXXXXX1]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key, configmaps:
    cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found"'
  metadata:
    creationTimestamp: "2025-11-17T09:20:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:53Z"
    name: kube-controller-manager-operator.1878c0cfff25a311
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8397"
    uid: 279cbfdb-771b-4188-9e79-d03faae09ac3
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:54Z"
  message: Created ConfigMap/config-2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:54Z"
    name: kube-controller-manager-operator.1878c0d037cf2402
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8424"
    uid: 1721ac67-1d42-4bd0-a40a-39805174fac5
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:55Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:55Z"
  message: |-
    Updated ConfigMap/config -n openshift-kube-controller-manager:
    cause by changes in data.config.yaml
  metadata:
    creationTimestamp: "2025-11-17T09:20:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:55Z"
    name: kube-controller-manager-operator.1878c0d06756a013
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8444"
    uid: 45719de1-8f0c-40fc-bd81-b7ca12fe4a74
  reason: ConfigMapUpdated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:56Z"
  message: Created ConfigMap/cluster-policy-controller-config-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:56Z"
    name: kube-controller-manager-operator.1878c0d08b290783
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8454"
    uid: cc071394-543b-49b7-b46e-a93e1bdd4bda
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:57Z"
  message: Created ConfigMap/controller-manager-kubeconfig-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:57Z"
    name: kube-controller-manager-operator.1878c0d0dea29f1c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8480"
    uid: 22145d40-bb4d-4a00-b2e1-8b7ffc3db1aa
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:58Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:58Z"
    name: kube-controller-manager-operator.1878c0d11a2dce5f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8512"
    uid: 9eb2ed46-a7ee-45a7-8316-f86269421048
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:58Z"
  message: |-
    Updated ConfigMap/cluster-policy-controller-config -n openshift-kube-controller-manager:
    cause by changes in data.config.yaml
  metadata:
    creationTimestamp: "2025-11-17T09:20:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:58Z"
    name: kube-controller-manager-operator.1878c0d132105a8e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8524"
    uid: d75f8984-805d-46cd-804e-50eb68f5b49c
  reason: ConfigMapUpdated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:59Z"
  message: Created Secret/kube-controller-manager-client-cert-key -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:59Z"
    name: kube-controller-manager-operator.1878c0d13e05a255
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8534"
    uid: 988c82df-8c57-423d-9254-b268cb68d6ce
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:20:59Z"
  message: Created ConfigMap/serviceaccount-ca-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:20:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:20:59Z"
    name: kube-controller-manager-operator.1878c0d149ee81a1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8538"
    uid: 353786f3-d402-4284-8ca9-553c90cae963
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:00Z"
  message: Created ConfigMap/service-ca-2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:00Z"
    name: kube-controller-manager-operator.1878c0d179991ec2
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8547"
    uid: b26f1996-6225-404d-a607-b23ad27a37be
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:00Z"
  message: Created ConfigMap/recycler-config-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:00Z"
    name: kube-controller-manager-operator.1878c0d1a93e6ab5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8579"
    uid: 6db3278a-cd04-43f9-a450-5123d3b2cc74
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:01Z"
  message: Created Secret/service-account-private-key-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:01Z"
    name: kube-controller-manager-operator.1878c0d1cd0385e5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8589"
    uid: 85486fb1-52d8-42a5-88a7-057fada4462d
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:02Z"
  message: Created Secret/serving-cert-2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:02Z"
    name: kube-controller-manager-operator.1878c0d1fccf5fe8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8607"
    uid: a9231440-9dd2-4cb3-84dd-dabe363d5881
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:03Z"
  message: Created Secret/localhost-recovery-client-token-2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:03Z"
    name: kube-controller-manager-operator.1878c0d22c654673
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8620"
    uid: f1bdca97-dfb2-4a9e-95fa-43fb405ecc65
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:03Z"
  message: Revision 1 created because configmap "kube-controller-manager-pod-1" not
    found
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:03Z"
    name: kube-controller-manager-operator.1878c0d22cd71149
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8622"
    uid: 28c6b2fd-0bad-499f-bc47-033ceae4cad1
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 6
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: 'configmaps: client-ca'
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d22ce0faa9
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8787"
    uid: 084f3808-571a-4e0a-8d0f-6b846a53ff58
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: new revision 3 triggered by "required configmap/config has changed,required
    configmap/cluster-policy-controller-config has changed"
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d22cef84ef
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8777"
    uid: 756acb99-45f6-4da3-8f69-4e907b4cc0b9
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:03Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    configmaps \"kube-controller-manager-pod\" not found" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key, configmaps:
    cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:03Z"
    name: kube-controller-manager-operator.1878c0d22d3ada14
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8627"
    uid: 5cbb3f40-0740-4157-8017-6797bff0e18a
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:03Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: [configmaps: client-ca, secrets: kube-controller-manager-client-cert-key,
    configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1,
    secrets: localhost-recovery-client-token-1,service-account-private-key-1]\nGuardControllerDegraded:
    [Missing operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]",Progressing message changed from "NodeInstallerProgressing:
    2 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing:
    2 nodes are at revision 0; 0 nodes have achieved new revision 2",Available message
    changed from "StaticPodsAvailable: 0 nodes are active; 2 nodes are at revision
    0; 0 nodes have achieved new revision 1" to "StaticPodsAvailable: 0 nodes are
    active; 2 nodes are at revision 0; 0 nodes have achieved new revision 2"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:03Z"
    name: kube-controller-manager-operator.1878c0d22da2e79c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8630"
    uid: c692f307-6c68-4fa8-bcdc-1af988f94ecf
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:04Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:04Z"
  message: Created ConfigMap/revision-status-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:04Z"
    name: kube-controller-manager-operator.1878c0d273e3dd2b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8644"
    uid: ad7f2291-c314-4399-aa75-312bde662e76
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:05Z"
  message: Created ConfigMap/kube-controller-manager-pod-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:05Z"
    name: kube-controller-manager-operator.1878c0d2bb73f77a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8657"
    uid: ad2e0f20-9f77-404d-86ae-c385c6c7c5e7
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:06Z"
  message: Created ConfigMap/config-3 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:06Z"
    name: kube-controller-manager-operator.1878c0d2f712715d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8673"
    uid: 58886b62-048e-4bef-b257-aa4ae97f2c14
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:07Z"
  message: Created ConfigMap/cluster-policy-controller-config-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:07Z"
    name: kube-controller-manager-operator.1878c0d332aa2020
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8686"
    uid: b039f494-413d-4dfb-8281-9fb87e7ea082
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:08Z"
  message: Created ConfigMap/controller-manager-kubeconfig-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:08Z"
    name: kube-controller-manager-operator.1878c0d3566d0d8f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8701"
    uid: b5102200-cfc7-4447-bdf7-1612cf18e2d2
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:08Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:08Z"
    name: kube-controller-manager-operator.1878c0d37a2218ed
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8723"
    uid: c43bf4f5-29b4-4646-922c-324a1d54bb88
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:09Z"
  message: Created ConfigMap/serviceaccount-ca-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:09Z"
    name: kube-controller-manager-operator.1878c0d39df3f8fc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8726"
    uid: b610ee27-8e11-4b8d-82ea-4465e6023ee0
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:09Z"
  message: Created ConfigMap/service-ca-3 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:09Z"
    name: kube-controller-manager-operator.1878c0d3c1b4ab1e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8728"
    uid: 3d842539-e350-43cc-9c86-9682264351fe
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:10Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:10Z"
  message: Created ConfigMap/recycler-config-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:10Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:10Z"
    name: kube-controller-manager-operator.1878c0d3e57554de
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8732"
    uid: 1e66fe2f-2f05-4193-8cc9-3faead7866c8
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:11Z"
  message: Created Secret/service-account-private-key-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:11Z"
    name: kube-controller-manager-operator.1878c0d4093576ff
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8742"
    uid: 6b5a9442-8dcd-4ec6-bb74-c4be812c4802
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:11Z"
  message: Created Secret/serving-cert-3 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:11Z"
    name: kube-controller-manager-operator.1878c0d438f6e4af
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8751"
    uid: 2ab66808-6800-4178-883b-1d9e862c92d2
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: Created Secret/localhost-recovery-client-token-3 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d46891b7a1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8773"
    uid: 9c769298-1d44-46c8-bd78-d0827ad7ce9f
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: Revision 2 created because required configmap/config has changed,required
    configmap/cluster-policy-controller-config has changed
  metadata:
    creationTimestamp: "2025-11-17T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d468fddafc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8775"
    uid: 903f5696-470e-4de2-83aa-d70b2fc4490a
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 0 nodes
    have achieved new revision 2" to "NodeInstallerProgressing: 2 nodes are at revision
    0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable:
    0 nodes are active; 2 nodes are at revision 0; 0 nodes have achieved new revision
    2" to "StaticPodsAvailable: 0 nodes are active; 2 nodes are at revision 0; 0 nodes
    have achieved new revision 3"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d469d3a870
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8781"
    uid: 7a56a90f-33db-436f-aecf-8860e99ae252
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    3"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d46b53744c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8786"
    uid: c15e4470-f865-48d2-b072-b04f9df711b6
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:12Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:12Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    conflicting XXXXXXAvailableRevision 3" to "NodeControllerDegraded: All XXXXXX
    nodes are ready\nInstallerControllerDegraded: missing required resources: configmaps:
    client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:12Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:12Z"
    name: kube-controller-manager-operator.1878c0d46bec26fd
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "8789"
    uid: 57eb5840-ca1d-4493-b8b0-3c5b494f5c9d
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:49Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure",
    "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource",
    "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP",
    "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController",
    "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration",
    "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass",
    "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2025-11-17T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:49Z"
    name: kube-controller-manager-operator.1878c0dceade6c9b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10058"
    uid: e60ee5b8-2027-4233-abcf-8260b273f28a
  reason: FeatureGatesInitialized
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 17
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:10Z"
  message: 'configmaps: client-ca'
  metadata:
    creationTimestamp: "2025-11-17T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:10Z"
    name: kube-controller-manager-operator.1878c0dd104e6faa
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10753"
    uid: 1ba0ae51-d3db-466a-a829-f3d2e73e9180
  reason: RequiredInstallerResourcesMissing
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:49Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX2,
    Missing operand on node XXXXXX1]"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:49Z"
    name: kube-controller-manager-operator.1878c0dd12019414
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10162"
    uid: f2d8891e-e8ff-4443-a1e2-efaaf5e9a61b
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:49Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX2, Missing operand on node XXXXXX1]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:21:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:49Z"
    name: kube-controller-manager-operator.1878c0dd14bddc46
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10169"
    uid: d9ee758d-749d-457d-b81b-efbb5d15d5fe
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 34
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:45Z"
  message: 'unexpected addresses: XXXXXXXXXXX'
  metadata:
    creationTimestamp: "2025-11-17T09:21:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:45Z"
    name: kube-controller-manager-operator.1878c0ddceeda435
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13958"
    uid: a76ec016-cc31-4b61-a6ad-999cf54f1a84
  reason: SATokenSignerControllerStuck
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:38Z"
  message: |-
    Updated ConfigMap/serviceaccount-ca -n openshift-kube-controller-manager:
    cause by changes in data.ca-bundle.crt
  metadata:
    creationTimestamp: "2025-11-17T09:21:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:38Z"
    name: kube-controller-manager-operator.1878c0df289b9520
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11739"
    uid: 05a2da00-234d-45e2-8d86-c39ef77fdba9
  reason: ConfigMapUpdated
  reportingComponent: kube-controller-manager-operator-targetconfigcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-targetconfigcontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: new revision 4 triggered by "required configmap/serviceaccount-ca has changed"
  metadata:
    creationTimestamp: "2025-11-17T09:21:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0df28b7a542
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10710"
    uid: 4bff87f8-c0ca-4230-8be8-3028c6758b24
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:21:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:21:59Z"
  message: Created ConfigMap/revision-status-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:21:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:21:59Z"
    name: kube-controller-manager-operator.1878c0df586c0be8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10545"
    uid: cf084a0f-45d9-42a5-8114-19eb989b2ca6
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:00Z"
  message: Created ConfigMap/kube-controller-manager-pod-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:00Z"
    name: kube-controller-manager-operator.1878c0df88063c19
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10559"
    uid: ddd30d3a-a3c4-4e98-95e2-92d087563a0a
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:01Z"
  message: Created ConfigMap/config-4 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:01Z"
    name: kube-controller-manager-operator.1878c0dfb7afa9a7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10580"
    uid: 7de7a176-aa0a-4d63-b9a1-76f6e5462fad
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:02Z"
  message: Created ConfigMap/cluster-policy-controller-config-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:02Z"
    name: kube-controller-manager-operator.1878c0dfe75d41bd
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10592"
    uid: 896e859b-6d90-4dd6-9eb7-03f1b1652f62
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:02Z"
  message: Created ConfigMap/controller-manager-kubeconfig-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:02Z"
    name: kube-controller-manager-operator.1878c0e01717fd89
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10602"
    uid: ba165bbf-265d-446d-a9f5-2d37a49ab3d7
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:03Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:03Z"
    name: kube-controller-manager-operator.1878c0e046f818ea
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10622"
    uid: 13f43d80-7b87-44d8-9197-a86f6768b198
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:04Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:04Z"
  message: Created ConfigMap/serviceaccount-ca-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:04Z"
    name: kube-controller-manager-operator.1878c0e076861e5c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10646"
    uid: a44b0bec-a3d4-4789-bef1-f2f5e696f44d
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:05Z"
  message: Created ConfigMap/service-ca-4 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:05Z"
    name: kube-controller-manager-operator.1878c0e0a62dadc7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10655"
    uid: 8cadeaf5-4023-4e6b-98c7-fe8f56dc5e9c
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:06Z"
  message: Created ConfigMap/recycler-config-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:06Z"
    name: kube-controller-manager-operator.1878c0e0d5d77f84
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10663"
    uid: ea5df6f3-589d-4c42-bcbb-693f9cf4fceb
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:06Z"
  message: Created Secret/service-account-private-key-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:06Z"
    name: kube-controller-manager-operator.1878c0e1057c97a7
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10677"
    uid: 08f0970e-9cb6-4604-a798-d48f06a36cab
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:07Z"
  message: Created Secret/serving-cert-4 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:07Z"
    name: kube-controller-manager-operator.1878c0e1353a98b4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10683"
    uid: f1c7f7ac-79f7-40dc-80bc-b1d4577af356
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: Created Secret/localhost-recovery-client-token-4 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0e16502a9ac
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10705"
    uid: 47c9e733-04f9-45f2-95cc-d4e54b4d8a65
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: Revision 3 created because required configmap/serviceaccount-ca has changed
  metadata:
    creationTimestamp: "2025-11-17T09:22:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0e16593af87
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10707"
    uid: a87f5974-d857-4e90-bf3d-d0e6b46b2edc
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 0 nodes
    have achieved new revision 3" to "NodeInstallerProgressing: 2 nodes are at revision
    0; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable:
    0 nodes are active; 2 nodes are at revision 0; 0 nodes have achieved new revision
    3" to "StaticPodsAvailable: 0 nodes are active; 2 nodes are at revision 0; 0 nodes
    have achieved new revision 4"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0e166c1d31b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10713"
    uid: 4680229d-3320-436b-96db-8be7a2b8d580
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX1, Missing operand on node XXXXXX2]" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    4"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0e168559d1e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10718"
    uid: ba536e40-8fd0-45dc-89f0-52c9321ffc06
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:08Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:08Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nInstallerControllerDegraded:
    missing required resources: configmaps: client-ca\nGuardControllerDegraded: [Missing
    operand on node XXXXXX1, Missing operand on node XXXXXX2]\nRevisionControllerDegraded:
    conflicting XXXXXXAvailableRevision 4" to "NodeControllerDegraded: All XXXXXX
    nodes are ready\nInstallerControllerDegraded: missing required resources: configmaps:
    client-ca\nGuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:08Z"
    name: kube-controller-manager-operator.1878c0e168da6dca
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "10721"
    uid: 930b539b-fb1e-4065-802e-91806ba1deaf
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:24Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from False to True ("GuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]\nInstallerControllerDegraded: missing required
    resources: configmaps: client-ca")'
  metadata:
    creationTimestamp: "2025-11-17T09:22:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:24Z"
    name: kube-controller-manager-operator.1878c0e509e017d6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11182"
    uid: 7ebb8c67-dcf8-47e1-a246-8d7b541617b1
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:30Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:30Z"
  message: Created ConfigMap/client-ca -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:30Z"
    name: kube-controller-manager-operator.1878c0e692cc8676
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11329"
    uid: e33ed640-f9f2-426a-804d-43d074e91e37
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-resource-sync-controller-resourcesynccontroller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: new revision 5 triggered by "required configmap/serviceaccount-ca has changed"
  metadata:
    creationTimestamp: "2025-11-17T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e84c0a7378
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11919"
    uid: 0bfa21c8-7ff3-4b47-8022-960bef47a0d5
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:38Z"
  message: Created ConfigMap/revision-status-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:38Z"
    name: kube-controller-manager-operator.1878c0e86f91467a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11781"
    uid: 464f54b6-8db3-426d-8e33-c8d1ec46fa4f
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:39Z"
  message: Created ConfigMap/kube-controller-manager-pod-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:39Z"
    name: kube-controller-manager-operator.1878c0e89364ae36
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11791"
    uid: 4c75db41-8cab-4920-8a0e-25c6003529b4
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:39Z"
  message: Created ConfigMap/config-5 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:39Z"
    name: kube-controller-manager-operator.1878c0e8b71200c8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11822"
    uid: 2b2988ad-bfa5-49fb-8f46-04bd1b1d4d3a
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:40Z"
  message: Created ConfigMap/cluster-policy-controller-config-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:40Z"
    name: kube-controller-manager-operator.1878c0e8dadec5cb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11831"
    uid: 233a5508-9ba8-4a80-a956-caf78f55702f
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:41Z"
  message: Created ConfigMap/controller-manager-kubeconfig-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:41Z"
    name: kube-controller-manager-operator.1878c0e8fe9e2358
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11841"
    uid: 37928926-fc3e-4835-98e8-3691ee8086c2
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:41Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:41Z"
    name: kube-controller-manager-operator.1878c0e92e4d30ce
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11858"
    uid: 9e537400-27c8-443c-b26e-5de9945f32b5
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:42Z"
  message: Created ConfigMap/serviceaccount-ca-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:42Z"
    name: kube-controller-manager-operator.1878c0e949ffc673
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11864"
    uid: 6108ddee-2462-4a50-8731-b86064f55015
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:42Z"
  message: Created ConfigMap/service-ca-5 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:42Z"
    name: kube-controller-manager-operator.1878c0e95dd847f1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11870"
    uid: b8f31089-b65a-4f7b-a419-053dad884ea4
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:42Z"
  message: Created ConfigMap/recycler-config-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:42Z"
    name: kube-controller-manager-operator.1878c0e95ebb9eb5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11881"
    uid: 7324e736-a0dd-4148-9a9e-56ad989850c3
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:42Z"
  message: Created Secret/service-account-private-key-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:42Z"
    name: kube-controller-manager-operator.1878c0e95f5e7766
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11884"
    uid: e235fe50-cbbb-4d85-bf55-4207889ac123
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: Created Secret/serving-cert-5 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e975da2e2d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11901"
    uid: 00db125c-5df3-4798-a0f5-1418d306964c
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: Created Secret/localhost-recovery-client-token-5 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e9a5783d7a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11915"
    uid: e595bb2e-416c-43ec-af56-f6c898d6b6ef
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: Revision 4 created because required configmap/serviceaccount-ca has changed
  metadata:
    creationTimestamp: "2025-11-17T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e9a5fe85b6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11917"
    uid: d25d58af-9716-422f-ac4b-9a38eb045f36
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca" to "GuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]\nInstallerControllerDegraded: missing required
    resources: configmaps: client-ca\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    5"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e9a724a28d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11924"
    uid: 06ba2e89-6606-4bb6-94c0-8071b40f4cd1
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:43Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    5" to "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing operand
    on node XXXXXX2]\nInstallerControllerDegraded: missing required resources: configmaps:
    client-ca"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:43Z"
    name: kube-controller-manager-operator.1878c0e9a85b26d3
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11926"
    uid: 58508006-bd78-443a-a668-a956a1677df6
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:44Z"
  message: Updating node "XXXXXX1" from revision 0 to 5 because node XXXXXX1 static
    pod not found
  metadata:
    creationTimestamp: "2025-11-17T09:22:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:44Z"
    name: kube-controller-manager-operator.1878c0e9d5a778eb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11944"
    uid: 8dd46243-859f-43f0-85b1-e0c02ad1768f
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:44Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 0 nodes
    have achieved new revision 4" to "NodeInstallerProgressing: 2 nodes are at revision
    0; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable:
    0 nodes are active; 2 nodes are at revision 0; 0 nodes have achieved new revision
    4" to "StaticPodsAvailable: 0 nodes are active; 2 nodes are at revision 0; 0 nodes
    have achieved new revision 5"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:44Z"
    name: kube-controller-manager-operator.1878c0e9d62077b5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11946"
    uid: 2f3b8a36-db5c-4c83-ae68-0625ffeb7a23
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:44Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]\nInstallerControllerDegraded: missing required resources:
    configmaps: client-ca" to "GuardControllerDegraded: [Missing operand on node XXXXXX1,
    Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:44Z"
    name: kube-controller-manager-operator.1878c0e9d79cc1d3
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "11950"
    uid: d3a59981-6684-4a69-90dd-6b7f30014940
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:47Z"
  message: Created Pod/installer-5-XXXXXX1 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:22:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:47Z"
    name: kube-controller-manager-operator.1878c0ea64692365
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12001"
    uid: da07e978-1be9-4a91-b4db-21606327d014
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:51Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]" to "GuardControllerDegraded: [Missing operand on node
    XXXXXX2, Missing operand on node XXXXXX1]"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:51Z"
    name: kube-controller-manager-operator.1878c0eb891d2184
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12149"
    uid: 34e78ccf-adc7-4548-b404-45b59825106d
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:22:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:22:59Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX2, Missing
    operand on node XXXXXX1]" to "GuardControllerDegraded: [Missing operand on node
    XXXXXX1, Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:22:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:22:59Z"
    name: kube-controller-manager-operator.1878c0ed661f1c97
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12314"
    uid: dc21c1a8-bb11-46ae-9bd5-c4775589a882
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:31Z"
  message: clusteroperator/kube-controller-manager version "operator" changed from
    "" to "4.14.59"
  metadata:
    creationTimestamp: "2025-11-17T09:23:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:31Z"
    name: kube-controller-manager-operator.1878c0f4d0ba4d63
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12608"
    uid: d712f982-09c4-45c8-979d-d2713cd41281
  reason: OperatorVersionChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:31Z"
  message: clusteroperator/kube-controller-manager version "kube-controller-manager"
    changed from "" to "1.27.16"
  metadata:
    creationTimestamp: "2025-11-17T09:23:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:31Z"
    name: kube-controller-manager-operator.1878c0f4d0ba67f4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12607"
    uid: 35abbe54-8b58-46a5-8e01-7038b225a73c
  reason: OperatorVersionChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:31Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: status.versions
    changed from [{"raw-internal" "4.14.59"}] to [{"raw-internal" "4.14.59"} {"operator"
    "4.14.59"} {"kube-controller-manager" "1.27.16"}]'
  metadata:
    creationTimestamp: "2025-11-17T09:23:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:31Z"
    name: kube-controller-manager-operator.1878c0f4d1279fdc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12604"
    uid: 914e1e39-758d-4238-8af3-2e3ace0d45ea
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:31Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:31Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing operand on node XXXXXX1, Missing
    operand on node XXXXXX2]" to "GuardControllerDegraded: [Missing PodIP in operand
    kube-controller-manager-XXXXXX1 on node XXXXXX1, Missing operand on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:23:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:31Z"
    name: kube-controller-manager-operator.1878c0f4d2dca8f2
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12610"
    uid: e06475cc-227c-4019-9c0a-00c066004376
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:35Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-XXXXXX1
    on node XXXXXX1, Missing operand on node XXXXXX2]" to "GuardControllerDegraded:
    [Missing PodIP in operand kube-controller-manager-XXXXXX1 on node XXXXXX1, Missing
    operand on node XXXXXX2]\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: "'
  metadata:
    creationTimestamp: "2025-11-17T09:23:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:35Z"
    name: kube-controller-manager-operator.1878c0f590486e87
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12652"
    uid: 2a646fdf-5076-4fd2-9d2f-d845b912d7fb
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:35Z"
  message: Created Pod/kube-controller-manager-guard-XXXXXX1 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:23:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:35Z"
    name: kube-controller-manager-operator.1878c0f5b347ead1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12660"
    uid: d05e72ed-969f-4291-bad8-e309d718e82a
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:35Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-XXXXXX1
    on node XXXXXX1, Missing operand on node XXXXXX2]\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand
    on node XXXXXX2\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: "'
  metadata:
    creationTimestamp: "2025-11-17T09:23:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:35Z"
    name: kube-controller-manager-operator.1878c0f5b43c24b6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12666"
    uid: cf3d0101-bca1-4084-bb10-b3624edab44a
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:40Z"
  message: 'Failed to update Pod/kube-controller-manager-guard-XXXXXX1 -n openshift-kube-controller-manager:
    Operation cannot be fulfilled on pods "kube-controller-manager-guard-XXXXXX1":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again'
  metadata:
    creationTimestamp: "2025-11-17T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:40Z"
    name: kube-controller-manager-operator.1878c0f6c550b32d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12727"
    uid: b4aa7dfd-9554-4b6c-a5d3-22adea19a5d9
  reason: PodUpdateFailed
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:40Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: Missing operand on node XXXXXX2\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    " to "GuardControllerDegraded: [Unable to apply pod kube-controller-manager-guard-XXXXXX1
    changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX1\":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again, Missing operand on node XXXXXX2]\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: "'
  metadata:
    creationTimestamp: "2025-11-17T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:40Z"
    name: kube-controller-manager-operator.1878c0f6c63938fb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12730"
    uid: 0e1b1775-c3c9-4139-a394-eb63f938d90a
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:40Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Unable to apply pod kube-controller-manager-guard-XXXXXX1
    changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX1\":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again, Missing operand on node XXXXXX2]\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1
    container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX1 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX1 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: " to "GuardControllerDegraded: [Unable to apply
    pod kube-controller-manager-guard-XXXXXX1 changes: Operation cannot be fulfilled
    on pods \"kube-controller-manager-guard-XXXXXX1\": the object has been modified;
    please apply your changes to the XXXXXX version and try again, Missing operand
    on node XXXXXX2]"'
  metadata:
    creationTimestamp: "2025-11-17T09:23:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:40Z"
    name: kube-controller-manager-operator.1878c0f6ea2f444c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12738"
    uid: fc457c08-ce32-49e4-b97c-4f653845cdd5
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:44Z"
  message: Updated Pod/kube-controller-manager-guard-XXXXXX1 -n openshift-kube-controller-manager
    because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:23:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:44Z"
    name: kube-controller-manager-operator.1878c0f7cbc15907
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12826"
    uid: f1bdc936-f786-480b-bece-aea7bc421cf5
  reason: PodUpdated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:44Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: [Unable to apply pod kube-controller-manager-guard-XXXXXX1
    changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX1\":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again, Missing operand on node XXXXXX2]" to "GuardControllerDegraded:
    Missing operand on node XXXXXX2"'
  metadata:
    creationTimestamp: "2025-11-17T09:23:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:44Z"
    name: kube-controller-manager-operator.1878c0f7ccb98d0e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "12829"
    uid: 5affbfc2-2479-4cdc-a876-f424ab9b9c34
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:54Z"
  message: Updated node "XXXXXX1" from revision 0 to 5 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:23:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:54Z"
    name: kube-controller-manager-operator.1878c0fa2c0bb813
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13105"
    uid: 27fa448d-de22-4a91-9594-92c4cead75a5
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:54Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:54Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 0 nodes
    have achieved new revision 5" to "NodeInstallerProgressing: 1 nodes are at revision
    0; 1 nodes are at revision 5",Available changed from False to True ("StaticPodsAvailable:
    1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5")'
  metadata:
    creationTimestamp: "2025-11-17T09:23:54Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:54Z"
    name: kube-controller-manager-operator.1878c0fa2c89dd52
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13107"
    uid: d6f3af60-3f98-4d90-9172-db5e0983d0f7
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:57Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:57Z"
  message: Updating node "XXXXXX2" from revision 0 to 5 because node XXXXXX2 static
    pod not found
  metadata:
    creationTimestamp: "2025-11-17T09:23:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:57Z"
    name: kube-controller-manager-operator.1878c0faaf172f30
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13215"
    uid: a90e7939-9809-4703-bc8c-dffe7bfa5958
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:59Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:23:59Z"
  message: Created Pod/installer-5-XXXXXX2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:23:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:23:59Z"
    name: kube-controller-manager-operator.1878c0fb31e2cea8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13247"
    uid: a94f74a6-3c6a-4caa-845b-354c6f2ba512
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:34Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: Missing operand on node XXXXXX2" to "GuardControllerDegraded:
    Missing PodIP in operand kube-controller-manager-XXXXXX2 on node XXXXXX2"'
  metadata:
    creationTimestamp: "2025-11-17T09:24:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:34Z"
    name: kube-controller-manager-operator.1878c103679c033d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13727"
    uid: 23acacef-5dd7-4918-a71a-c12d665fcd63
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:35Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "GuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX2
    on node XXXXXX2" to "GuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX2
    on node XXXXXX2\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2 container
    \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: "'
  metadata:
    creationTimestamp: "2025-11-17T09:24:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:35Z"
    name: kube-controller-manager-operator.1878c1038af95104
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13739"
    uid: e23bd775-c24c-4c26-87e1-c8e0245cba8f
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:42Z"
  message: Created Pod/kube-controller-manager-guard-XXXXXX2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:24:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:42Z"
    name: kube-controller-manager-operator.1878c1055b0542a3
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13815"
    uid: 2d8ae7f0-3d03-42a2-9b5f-3ef324d7b635
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:42Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    ")'
  metadata:
    creationTimestamp: "2025-11-17T09:24:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:42Z"
    name: kube-controller-manager-operator.1878c1055c08714a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "13821"
    uid: 66e40f6c-63b1-4b11-bc60-916e366aa808
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:49Z"
  message: 'Failed to update Pod/kube-controller-manager-guard-XXXXXX2 -n openshift-kube-controller-manager:
    Operation cannot be fulfilled on pods "kube-controller-manager-guard-XXXXXX2":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again'
  metadata:
    creationTimestamp: "2025-11-17T09:24:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:49Z"
    name: kube-controller-manager-operator.1878c106cc8ebb43
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "14008"
    uid: d680ef71-f834-41d1-8694-001ec5ab19d5
  reason: PodUpdateFailed
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:49Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    " to "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot
    be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has
    been modified; please apply your changes to the XXXXXX version and try again\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    "'
  metadata:
    creationTimestamp: "2025-11-17T09:24:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:49Z"
    name: kube-controller-manager-operator.1878c106cd857d8e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "14011"
    uid: 31fac728-2400-4a24-ab47-4bb00d1a9823
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:24:50Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot
    be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has
    been modified; please apply your changes to the XXXXXX version and try again\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX2 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX2
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    " to "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot
    be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has
    been modified; please apply your changes to the XXXXXX version and try again"'
  metadata:
    creationTimestamp: "2025-11-17T09:24:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:24:50Z"
    name: kube-controller-manager-operator.1878c107096885fb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "14046"
    uid: 9e81c8ac-0fae-4aa2-b7e2-6b9f26822cfb
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:36Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure",
    "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource",
    "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP",
    "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController",
    "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration",
    "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass",
    "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2025-11-17T09:29:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:36Z"
    name: kube-controller-manager-operator.1878c149b4d47fd3
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15375"
    uid: 4125eeab-3b43-4abe-a965-033db51176ea
  reason: FeatureGatesInitialized
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: new revision 6 triggered by "required secret/localhost-recovery-client-token
    has changed"
  metadata:
    creationTimestamp: "2025-11-17T09:29:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c149bbe9c7f8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15567"
    uid: 7c69f7df-3625-478f-b3db-9e946ce30dbf
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:36Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from False to True ("GuardControllerDegraded: Unable to apply pod kube-controller-manager-guard-XXXXXX2
    changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\":
    the object has been modified; please apply your changes to the XXXXXX version
    and try again")'
  metadata:
    creationTimestamp: "2025-11-17T09:29:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:36Z"
    name: kube-controller-manager-operator.1878c149bc4ee4f5
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15378"
    uid: 459056ef-7552-4f4a-8d0e-e0931079894f
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:39Z"
  message: Created ConfigMap/revision-status-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:39Z"
    name: kube-controller-manager-operator.1878c14a688f1055
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15393"
    uid: 1892abeb-80b1-443e-bbb2-52796f9f99d8
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:41Z"
  message: Created ConfigMap/kube-controller-manager-pod-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:41Z"
    name: kube-controller-manager-operator.1878c14ac7f6d2dc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15398"
    uid: 781286b1-6c94-4407-84b4-a50693e09e1c
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:41Z"
  message: found expected kube-apiserver endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:29:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:41Z"
    name: kube-controller-manager-operator.1878c14adf8c0cf8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15399"
    uid: 2a529244-e954-45f3-a90e-0ed7c12b1ec2
  reason: SATokenSignerControllerOK
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:42Z"
  message: Updated node "XXXXXX2" from revision 0 to 5 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:29:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:42Z"
    name: kube-controller-manager-operator.1878c14b04092bcd
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15401"
    uid: 8898de94-a387-4c38-ac6f-b0a10cfd9b7d
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:42Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    changed from True to False ("NodeInstallerProgressing: 2 nodes are at revision
    5"),Available message changed from "StaticPodsAvailable: 1 nodes are active; 1
    nodes are at revision 0; 1 nodes are at revision 5" to "StaticPodsAvailable: 2
    nodes are active; 2 nodes are at revision 5"'
  metadata:
    creationTimestamp: "2025-11-17T09:29:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:42Z"
    name: kube-controller-manager-operator.1878c14b04917538
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15403"
    uid: dc480b50-8a63-4a15-b998-961e3361ab92
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:42Z"
  message: Created ConfigMap/config-6 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:42Z"
    name: kube-controller-manager-operator.1878c14b0f6f8f4a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15406"
    uid: 98f5d205-0c6b-43ba-a33f-0a90d208be29
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:43Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:43Z"
  message: Created ConfigMap/cluster-policy-controller-config-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:43Z"
    name: kube-controller-manager-operator.1878c14b62d0b669
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15416"
    uid: 152ae35d-62fb-493a-8f35-aeae6822de46
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:44Z"
  message: Created ConfigMap/controller-manager-kubeconfig-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:44Z"
    name: kube-controller-manager-operator.1878c14baa5f3835
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15463"
    uid: 345095d2-6f5e-4dfc-9e83-06f943ac55c6
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:45Z"
  message: Updated Pod/kube-controller-manager-guard-XXXXXX2 -n openshift-kube-controller-manager
    because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:29:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:45Z"
    name: kube-controller-manager-operator.1878c14bb6f6bb37
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15469"
    uid: 3a5e8559-3d39-4f9c-8671-4cc96c07a683
  reason: PodUpdated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:45Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready")'
  metadata:
    creationTimestamp: "2025-11-17T09:29:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:45Z"
    name: kube-controller-manager-operator.1878c14bb81a419c
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15472"
    uid: c6e4d66a-e632-49cb-a2ea-c5502c0a97ce
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:45Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:45Z"
    name: kube-controller-manager-operator.1878c14be5fb87fe
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15475"
    uid: e1398f99-c2cd-47e1-b30d-ef18210573a9
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:47Z"
  message: Created Secret/next-service-account-private-key -n openshift-kube-controller-manager-operator
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:47Z"
    name: kube-controller-manager-operator.1878c14c457b7628
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15501"
    uid: 3e65cc32-bd97-4ad0-8baf-86438c8f9043
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:47Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:47Z"
  message: Created ConfigMap/serviceaccount-ca-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:47Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:47Z"
    name: kube-controller-manager-operator.1878c14c515123b8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15503"
    uid: f2a67dec-c4dd-476b-b1de-eb8a855e00bd
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:48Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:48Z"
  message: |-
    Updated ConfigMap/sa-token-signing-certs -n openshift-config-managed:
    cause by changes in data.service-account-002.pub
  metadata:
    creationTimestamp: "2025-11-17T09:29:48Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:48Z"
    name: kube-controller-manager-operator.1878c14c98bd519e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15529"
    uid: 90c72a4e-0b1e-4fee-9383-08dafebb2f6c
  reason: ConfigMapUpdated
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:49Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:49Z"
  message: Created ConfigMap/service-ca-6 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:49Z"
    name: kube-controller-manager-operator.1878c14ca4afbe11
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15534"
    uid: 6110744d-a1da-47aa-9325-0282d8277ab7
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:50Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:50Z"
  message: Created ConfigMap/recycler-config-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:50Z"
    name: kube-controller-manager-operator.1878c14cec48b77e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15554"
    uid: ef42ad9e-b0a9-4b37-9b8f-3d47af5e79fb
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:51Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:51Z"
  message: Created Secret/service-account-private-key-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:51Z"
    name: kube-controller-manager-operator.1878c14d33d5be6b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15556"
    uid: 6918a8c2-f145-4cc0-805a-b0a511e41ce4
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: Created Secret/serving-cert-6 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c14d63921ef1
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15560"
    uid: 4a7c692e-8e17-4b48-bd7c-70d050720640
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: Created Secret/localhost-recovery-client-token-6 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c14d87418f5b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15564"
    uid: 6675d59b-a6c2-4718-bd16-6d52829d1787
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: Revision 5 created because required secret/localhost-recovery-client-token
    has changed
  metadata:
    creationTimestamp: "2025-11-17T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c14d87d35c88
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15566"
    uid: 53da8a9c-d803-4a3b-a025-746be84d208e
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    6"'
  metadata:
    creationTimestamp: "2025-11-17T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c14d89392cf2
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15571"
    uid: bc9dffa0-4e73-4b17-991c-52a37f891367
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:52Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:52Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nRevisionControllerDegraded:
    conflicting XXXXXXAvailableRevision 6" to "NodeControllerDegraded: All XXXXXX
    nodes are ready"'
  metadata:
    creationTimestamp: "2025-11-17T09:29:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:52Z"
    name: kube-controller-manager-operator.1878c14d8a09b5bf
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15573"
    uid: 7b4e3f1e-58b3-49c4-a16e-b6f1621e7494
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:56Z"
  message: Updating node "XXXXXX1" from revision 5 to 6 because node XXXXXX1 with
    revision 5 is the oldest
  metadata:
    creationTimestamp: "2025-11-17T09:29:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:56Z"
    name: kube-controller-manager-operator.1878c14e5e432aef
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15610"
    uid: bfa1dbc6-ff82-4ef0-9a41-53ad16233d7f
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:56Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:56Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    changed from False to True ("NodeInstallerProgressing: 2 nodes are at revision
    5; 0 nodes have achieved new revision 6"),Available message changed from "StaticPodsAvailable:
    2 nodes are active; 2 nodes are at revision 5" to "StaticPodsAvailable: 2 nodes
    are active; 2 nodes are at revision 5; 0 nodes have achieved new revision 6"'
  metadata:
    creationTimestamp: "2025-11-17T09:29:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:56Z"
    name: kube-controller-manager-operator.1878c14e5fcee716
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15614"
    uid: a767965d-0d64-44c3-abd9-878059fe16bc
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:29:58Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:29:58Z"
  message: Created Pod/installer-6-XXXXXX1 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:29:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:29:58Z"
    name: kube-controller-manager-operator.1878c14ec94c3cb6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "15622"
    uid: 9a00440b-9755-4bd1-b2a7-4bf2132fd2c9
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:13Z"
  message: FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform",
    "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure",
    "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy",
    "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource",
    "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP",
    "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController",
    "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration",
    "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass",
    "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
  metadata:
    creationTimestamp: "2025-11-17T09:33:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:13Z"
    name: kube-controller-manager-operator.1878c17c58097440
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19585"
    uid: 93507123-6d61-4547-8a77-a2450d9108ee
  reason: FeatureGatesInitialized
  reportingComponent: kube-controller-manager-operator
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:18Z"
  message: found expected kube-apiserver endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:33:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:18Z"
    name: kube-controller-manager-operator.1878c17d775449cc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19693"
    uid: b265858a-4cc7-407d-96f7-e1a10f6380b3
  reason: SATokenSignerControllerOK
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:19Z"
  message: Updated node "XXXXXX1" from revision 5 to 6 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:33:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:19Z"
    name: kube-controller-manager-operator.1878c17da820cf4e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19706"
    uid: 6cbcb857-26c2-4f20-a41b-a63b9716aaf1
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:19Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 5; 0 nodes
    have achieved new revision 6" to "NodeInstallerProgressing: 1 nodes are at revision
    5; 1 nodes are at revision 6",Available message changed from "StaticPodsAvailable:
    2 nodes are active; 2 nodes are at revision 5; 0 nodes have achieved new revision
    6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes
    are at revision 6"'
  metadata:
    creationTimestamp: "2025-11-17T09:33:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:19Z"
    name: kube-controller-manager-operator.1878c17da8d7e01e
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19708"
    uid: aba32822-5cc0-40ee-8122-186983c8011b
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:25Z"
  message: Updating node "XXXXXX2" from revision 5 to 6 because node XXXXXX2 with
    revision 5 is the oldest
  metadata:
    creationTimestamp: "2025-11-17T09:33:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:25Z"
    name: kube-controller-manager-operator.1878c17f253d0b30
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19821"
    uid: 521893fd-faf5-493b-ba31-8c8ea19c1d1e
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:27Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:27Z"
  message: Created Pod/installer-6-XXXXXX2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:33:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:27Z"
    name: kube-controller-manager-operator.1878c17f9c1d9c3b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19841"
    uid: adebd3dc-a1e6-4b9c-a89d-fee9cd48e21a
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:35Z"
  message: Observed new XXXXXX node XXXXXX0
  metadata:
    creationTimestamp: "2025-11-17T09:33:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:35Z"
    name: kube-controller-manager-operator.1878c1815cc038da
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19964"
    uid: b0509be2-f97c-42eb-bcc9-371c463026e9
  reason: MasterNodeObserved
  reportingComponent: kube-controller-manager-operator-nodecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-nodecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:35Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded:
    The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35
    +0000 UTC because KubeletNotReady ([container runtime network not ready: NetworkReady=false
    reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration
    file in /etc/kubernetes/cni/net.d/. Has your network provider started?, failed
    to initialize CSINode: error updating CSINode annotation: timed out waiting for
    the condition; caused by: nodes \"XXXXXX0\" not found])"'
  metadata:
    creationTimestamp: "2025-11-17T09:33:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:35Z"
    name: kube-controller-manager-operator.1878c1815eac94d4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19967"
    uid: cee3ac44-74ae-4223-ac00-d797348aa59a
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:35Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:35Z"
  message: Updated PodDisruptionBudget.policy/kube-controller-manager-guard-pdb -n
    openshift-kube-controller-manager because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:33:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:35Z"
    name: kube-controller-manager-operator.1878c1816177f7ff
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "19985"
    uid: dc9519d7-fdad-4de3-afda-4fea18fc27b0
  reason: PodDisruptionBudgetUpdated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:37Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 1 nodes are at revision 5; 1 nodes
    are at revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 0; 1
    nodes are at revision 5; 1 nodes are at revision 6",Available message changed
    from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes
    are at revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at
    revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6"'
  metadata:
    creationTimestamp: "2025-11-17T09:33:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:37Z"
    name: kube-controller-manager-operator.1878c181d91ae41d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20142"
    uid: 82e8ae88-2170-445f-b598-2bbdfe479a92
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:33:45Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady ([container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?, failed to initialize CSINode: error updating
    CSINode annotation: timed out waiting for the condition; caused by: nodes \"XXXXXX0\"
    not found])" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)"'
  metadata:
    creationTimestamp: "2025-11-17T09:33:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:33:45Z"
    name: kube-controller-manager-operator.1878c183b6be2329
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20282"
    uid: 58b16bea-d644-4e11-a9f0-c8c4c48f0232
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:34Z"
  message: Updated node "XXXXXX2" from revision 5 to 6 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:34:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:34Z"
    name: kube-controller-manager-operator.1878c18f1348c284
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20854"
    uid: c843be75-dcdd-4c59-a97f-132a10365ac5
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:34Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:34Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes
    are at revision 5; 1 nodes are at revision 6" to "NodeInstallerProgressing: 1
    nodes are at revision 0; 2 nodes are at revision 6",Available message changed
    from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes
    are at revision 5; 1 nodes are at revision 6" to "StaticPodsAvailable: 2 nodes
    are active; 1 nodes are at revision 0; 2 nodes are at revision 6"'
  metadata:
    creationTimestamp: "2025-11-17T09:34:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:34Z"
    name: kube-controller-manager-operator.1878c18f1416af93
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20856"
    uid: 26cd83a2-00c4-4884-be2a-bd84a69491dc
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:36Z"
  message: Created Pod/revision-pruner-6-XXXXXX1 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:34:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:36Z"
    name: kube-controller-manager-operator.1878c18f962fdf07
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20869"
    uid: d355e255-9402-4cbb-998f-de0c1eafed75
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:38Z"
  message: Updating node "XXXXXX0" from revision 0 to 6 because node XXXXXX0 static
    pod not found
  metadata:
    creationTimestamp: "2025-11-17T09:34:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:38Z"
    name: kube-controller-manager-operator.1878c190019a5680
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20888"
    uid: dcdae036-1f8a-4311-8a75-0e118b02bc0f
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:39Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:39Z"
  message: Created Pod/revision-pruner-6-XXXXXX2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:34:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:39Z"
    name: kube-controller-manager-operator.1878c1903cdbcc1b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20896"
    uid: c1596fec-3ef3-4d22-aaf0-a708885af328
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:42Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:42Z"
  message: Created Pod/revision-pruner-6-XXXXXX0 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:34:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:42Z"
    name: kube-controller-manager-operator.1878c190efa1c015
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20927"
    uid: 97c0e3dc-f7b0-43e9-9147-3b90336e2806
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:45Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:34:45Z"
  message: Created Pod/installer-6-XXXXXX0 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:34:45Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:34:45Z"
    name: kube-controller-manager-operator.1878c191ae605b43
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "20955"
    uid: b2cf8771-0f90-4878-a51f-0383b141c7d2
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:35:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:35:50Z"
  message: 'Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager:
    rpc error: code = DeadlineExceeded desc = context deadline exceeded'
  metadata:
    creationTimestamp: "2025-11-17T09:36:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:01Z"
    name: kube-controller-manager-operator.1878c19a2f340d17
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21091"
    uid: fa4ebda0-ad9d-44c8-8477-ca9363a21262
  reason: SecretUpdateFailed
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:01Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:01Z"
  message: Updated Secret/service-account-private-key -n openshift-kube-controller-manager
    because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:36:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:01Z"
    name: kube-controller-manager-operator.1878c1a361fe9263
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21097"
    uid: d482c48e-d8b5-4af5-8412-c8a02b48594b
  reason: SecretUpdated
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Normal
- apiVersion: v1
  count: 5
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:09Z"
  message: 'Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager:
    Operation cannot be fulfilled on secrets "service-account-private-key": the object
    has been modified; please apply your changes to the XXXXXX version and try again'
  metadata:
    creationTimestamp: "2025-11-17T09:36:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:09Z"
    name: kube-controller-manager-operator.1878c1a39a780613
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21250"
    uid: 53551673-b43f-42ac-922b-da377e17e281
  reason: SecretUpdateFailed
  reportingComponent: kube-controller-manager-operator-satokensignercontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-satokensignercontroller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:02Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:02Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from False to True ("NodeControllerDegraded: The XXXXXX nodes not ready: node
    \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady
    (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady
    message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)")'
  metadata:
    creationTimestamp: "2025-11-17T09:36:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:02Z"
    name: kube-controller-manager-operator.1878c1a39b113c4d
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21126"
    uid: 6fd49351-8738-47ec-8518-7474662074e7
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:03Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)" to "NodeControllerDegraded: The XXXXXX nodes
    not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because
    KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady
    message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be
    fulfilled on secrets \"service-account-private-key\": the object has been modified;
    please apply your changes to the XXXXXX version and try again"'
  metadata:
    creationTimestamp: "2025-11-17T09:36:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:03Z"
    name: kube-controller-manager-operator.1878c1a3edc184fe
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21171"
    uid: 831ef5db-3fa6-4c12-8923-6dff7a85f582
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:07Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:21Z"
  message: new revision 7 triggered by "required secret/service-account-private-key
    has changed"
  metadata:
    creationTimestamp: "2025-11-17T09:36:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:21Z"
    name: kube-controller-manager-operator.1878c1a4b963fd04
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21397"
    uid: 77725130-1bf5-4b1a-9a67-cb06ab19f2fb
  reason: RevisionTriggered
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:09Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be
    fulfilled on secrets \"service-account-private-key\": the object has been modified;
    please apply your changes to the XXXXXX version and try again" to "NodeControllerDegraded:
    The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35
    +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false
    reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration
    file in /etc/kubernetes/cni/net.d/. Has your network provider started?)"'
  metadata:
    creationTimestamp: "2025-11-17T09:36:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:09Z"
    name: kube-controller-manager-operator.1878c1a53d238a19
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21253"
    uid: ff16e771-f7fe-411f-b9ba-a61a67304059
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:09Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:09Z"
  message: Created ConfigMap/revision-status-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:09Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:09Z"
    name: kube-controller-manager-operator.1878c1a547ec80dc
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21258"
    uid: dc40fc3d-a7e4-4956-8d39-750a85528b1c
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:11Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:11Z"
  message: Created ConfigMap/kube-controller-manager-pod-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:11Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:11Z"
    name: kube-controller-manager-operator.1878c1a5b37846e0
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21267"
    uid: e2bcc8b0-883f-4d04-b453-282e7146d971
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:13Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:13Z"
  message: Created ConfigMap/config-7 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:13Z"
    name: kube-controller-manager-operator.1878c1a6126141b4
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21286"
    uid: 4740395d-843f-4f69-b418-8574d2b42a57
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:14Z"
  message: Created ConfigMap/cluster-policy-controller-config-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:14Z"
    name: kube-controller-manager-operator.1878c1a66641c3fb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21293"
    uid: 1be99805-2d89-4947-be2f-bb43dc3785d7
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created ConfigMap/controller-manager-kubeconfig-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:15Z"
    name: kube-controller-manager-operator.1878c1a6b95a626a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21306"
    uid: 38340944-7391-4a30-b3e6-ff111f05138a
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:16Z"
  message: Created ConfigMap/kube-controller-cert-syncer-kubeconfig-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:16Z"
    name: kube-controller-manager-operator.1878c1a6f4fae143
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21312"
    uid: 665ea084-f891-43fa-8316-868f59793391
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:17Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:17Z"
  message: Created ConfigMap/serviceaccount-ca-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:17Z"
    name: kube-controller-manager-operator.1878c1a73098055a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21327"
    uid: 36ffc449-1578-46a1-8881-e3a51db3d51c
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:18Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:18Z"
  message: Created ConfigMap/service-ca-7 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:18Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:18Z"
    name: kube-controller-manager-operator.1878c1a76c2a2652
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21353"
    uid: d1111888-99cb-4334-a94a-1e36ffea65d4
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:19Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:19Z"
  message: Created ConfigMap/recycler-config-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:19Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:19Z"
    name: kube-controller-manager-operator.1878c1a78fd4b577
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21364"
    uid: 8b0dda58-e65b-41f2-801b-109ed397f2bf
  reason: ConfigMapCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:20Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:20Z"
  message: Created Secret/service-account-private-key-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:20Z"
    name: kube-controller-manager-operator.1878c1a7b3ab5ad8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21385"
    uid: 0639a3bd-eec3-4051-843c-80d4ee86190d
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:20Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:20Z"
  message: Created Secret/serving-cert-7 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:20Z"
    name: kube-controller-manager-operator.1878c1a7d76e4f37
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21389"
    uid: d4a6e23b-0dcb-43af-9c6b-0d9aeabb1949
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:21Z"
  message: Created Secret/localhost-recovery-client-token-7 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:21Z"
    name: kube-controller-manager-operator.1878c1a7fb33cc27
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21393"
    uid: 8ccfbd65-b6d1-4cec-9dcb-e5c289dbd130
  reason: SecretCreated
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:21Z"
  message: Revision 6 created because required secret/service-account-private-key
    has changed
  metadata:
    creationTimestamp: "2025-11-17T09:36:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:21Z"
    name: kube-controller-manager-operator.1878c1a7fbea90db
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21395"
    uid: afdde509-d36f-4c5c-bb94-f0c33047646b
  reason: RevisionCreate
  reportingComponent: kube-controller-manager-operator-revisioncontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-revisioncontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:21Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)" to "NodeControllerDegraded: The XXXXXX nodes
    not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because
    KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady
    message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    7"'
  metadata:
    creationTimestamp: "2025-11-17T09:36:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:21Z"
    name: kube-controller-manager-operator.1878c1a7fd4a2178
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21400"
    uid: 703e3553-db23-444a-8499-1ce8bdd6f237
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:21Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\"
    not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container
    runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision
    7" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not
    ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime
    network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network
    plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/.
    Has your network provider started?)"'
  metadata:
    creationTimestamp: "2025-11-17T09:36:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:21Z"
    name: kube-controller-manager-operator.1878c1a7fdf6b63b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21402"
    uid: 756a8207-deb6-41a4-9677-62313c4d873b
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:23Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes
    are at revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 0; 2
    nodes are at revision 6; 0 nodes have achieved new revision 7",Available message
    changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision
    0; 2 nodes are at revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes
    are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision
    7"'
  metadata:
    creationTimestamp: "2025-11-17T09:36:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:23Z"
    name: kube-controller-manager-operator.1878c1a8739eb86a
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21482"
    uid: 78f5267f-e2e9-48e2-9bbc-9586a9dc80b9
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:23Z"
  message: Created Pod/revision-pruner-7-XXXXXX1 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:23Z"
    name: kube-controller-manager-operator.1878c1a87e629514
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21485"
    uid: 14764448-cec5-4059-b613-8cca65267986
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:26Z"
  message: Created Pod/installer-7-XXXXXX0 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:26Z"
    name: kube-controller-manager-operator.1878c1a92527dd30
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21566"
    uid: ce552213-fa5c-4772-93ea-cfc6d1130f2d
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:26Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:26Z"
  message: Created Pod/revision-pruner-7-XXXXXX2 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:26Z"
    name: kube-controller-manager-operator.1878c1a9311b8749
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21574"
    uid: d1c18333-5507-411a-9b1a-9d9b5149376a
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:36:29Z"
  message: Created Pod/revision-pruner-7-XXXXXX0 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:36:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:36:29Z"
    name: kube-controller-manager-operator.1878c1a9d828d4fb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "21620"
    uid: 5a65260d-36b4-4179-8e45-0c6a9fe552b0
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-prunecontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-prunecontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:38:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:38:21Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded changed
    from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready")'
  metadata:
    creationTimestamp: "2025-11-17T09:38:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:38:21Z"
    name: kube-controller-manager-operator.1878c1c40852c692
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "23526"
    uid: d481b0e6-0c6e-4458-9dd6-8b3ad5ea2557
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:38:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:38:23Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded:
    All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0"'
  metadata:
    creationTimestamp: "2025-11-17T09:38:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:38:23Z"
    name: kube-controller-manager-operator.1878c1c474b018c9
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "23595"
    uid: 1ac3aecf-6704-45c2-993f-c08ca893aa40
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:21Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:21Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Missing operand on node XXXXXX0" to "NodeControllerDegraded: All XXXXXX nodes
    are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    "'
  metadata:
    creationTimestamp: "2025-11-17T09:39:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:21Z"
    name: kube-controller-manager-operator.1878c1d1e5dba129
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "25653"
    uid: 9d648f7d-434c-4351-a4f9-9ae836c001ae
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:24Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Missing operand on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: " to "NodeControllerDegraded: All XXXXXX nodes
    are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX0
    on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container
    \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting:
    ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container
    \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\"
    is waiting: ContainerCreating: "'
  metadata:
    creationTimestamp: "2025-11-17T09:39:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:24Z"
    name: kube-controller-manager-operator.1878c1d2b0a7258f
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "25748"
    uid: e7abb717-c87b-4c71-9176-1402a3be8ffb
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:30Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:30Z"
  message: Created Pod/kube-controller-manager-guard-XXXXXX0 -n openshift-kube-controller-manager
    because it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:39:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:30Z"
    name: kube-controller-manager-operator.1878c1d3fd1c6957
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "25885"
    uid: 7f33b252-c47d-4aa3-ad4b-acdd359d45d9
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:32Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:32Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded:
    Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    " to "NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    "'
  metadata:
    creationTimestamp: "2025-11-17T09:39:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:32Z"
    name: kube-controller-manager-operator.1878c1d4696df41b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "25922"
    uid: 33f67487-7901-49aa-8eb2-f8bb0b34f609
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:38Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:38Z"
  message: Updated Pod/kube-controller-manager-guard-XXXXXX0 -n openshift-kube-controller-manager
    because it changed
  metadata:
    creationTimestamp: "2025-11-17T09:39:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:38Z"
    name: kube-controller-manager-operator.1878c1d5f1f948f6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26071"
    uid: a1bd9c92-d984-4947-a2bb-6c1b3278ad1f
  reason: PodUpdated
  reportingComponent: kube-controller-manager-operator-guardcontroller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-guardcontroller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:41Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:41Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Degraded message
    changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is
    waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded:
    pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\"
    is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0
    container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating:
    " to "NodeControllerDegraded: All XXXXXX nodes are ready"'
  metadata:
    creationTimestamp: "2025-11-17T09:39:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:41Z"
    name: kube-controller-manager-operator.1878c1d68e2d9e92
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26131"
    uid: 28923b4a-e2aa-4bf5-8311-e58650e084d2
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:53Z"
  message: Updated node "XXXXXX0" from revision 0 to 7 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:39:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:53Z"
    name: kube-controller-manager-operator.1878c1d958798590
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26346"
    uid: f4a84912-36a8-466b-bdd0-b8de832598c2
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:53Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:39:53Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes
    are at revision 6; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing:
    2 nodes are at revision 6; 1 nodes are at revision 7",Available message changed
    from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes
    are at revision 6; 0 nodes have achieved new revision 7" to "StaticPodsAvailable:
    3 nodes are active; 2 nodes are at revision 6; 1 nodes are at revision 7"'
  metadata:
    creationTimestamp: "2025-11-17T09:39:53Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:39:53Z"
    name: kube-controller-manager-operator.1878c1d9591159aa
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26348"
    uid: f4fcd2f9-97f6-4c7f-a653-9c92fe864d1a
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:03Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:40:03Z"
  message: Updating node "XXXXXX1" from revision 6 to 7 because node XXXXXX1 with
    revision 6 is the oldest
  metadata:
    creationTimestamp: "2025-11-17T09:40:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:40:03Z"
    name: kube-controller-manager-operator.1878c1dbc528f78b
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26688"
    uid: 635e0406-e7d6-497b-81d0-d8ed2f3e3217
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:05Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:40:05Z"
  message: Created Pod/installer-7-XXXXXX1 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:40:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:40:05Z"
    name: kube-controller-manager-operator.1878c1dc3b65e5fe
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "26724"
    uid: 560b0d20-9ae4-4ab8-bd04-20d54e22501b
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:41:06Z"
  message: Updated node "XXXXXX1" from revision 6 to 7 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:41:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:41:06Z"
    name: kube-controller-manager-operator.1878c1ea4e8e45c6
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "27655"
    uid: b4819c12-e003-48b2-9236-a7a9dcc3db84
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:06Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:41:06Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    message changed from "NodeInstallerProgressing: 2 nodes are at revision 6; 1 nodes
    are at revision 7" to "NodeInstallerProgressing: 1 nodes are at revision 6; 2
    nodes are at revision 7",Available message changed from "StaticPodsAvailable:
    3 nodes are active; 2 nodes are at revision 6; 1 nodes are at revision 7" to "StaticPodsAvailable:
    3 nodes are active; 1 nodes are at revision 6; 2 nodes are at revision 7"'
  metadata:
    creationTimestamp: "2025-11-17T09:41:06Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:41:06Z"
    name: kube-controller-manager-operator.1878c1ea4f6768ca
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "27657"
    uid: 19301dd3-dd7a-4b34-99bd-2fdf8e4c2f2f
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:14Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:41:14Z"
  message: Updating node "XXXXXX2" from revision 6 to 7 because node XXXXXX2 with
    revision 6 is the oldest
  metadata:
    creationTimestamp: "2025-11-17T09:41:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:41:14Z"
    name: kube-controller-manager-operator.1878c1ec374d7dbb
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "27732"
    uid: 0c638b89-8d3a-4d17-a726-b3d0cd9a54f4
  reason: NodeTargetRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:16Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:41:16Z"
  message: Created Pod/installer-7-XXXXXX2 -n openshift-kube-controller-manager because
    it was missing
  metadata:
    creationTimestamp: "2025-11-17T09:41:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:41:16Z"
    name: kube-controller-manager-operator.1878c1ecd1e85283
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "27772"
    uid: 28539cc1-f29c-4a4a-b966-bd9f2f1b0107
  reason: PodCreated
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:42:25Z"
  message: Updated node "XXXXXX2" from revision 6 to 7 because static pod is ready
  metadata:
    creationTimestamp: "2025-11-17T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:42:25Z"
    name: kube-controller-manager-operator.1878c1fcaa96caa8
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "28495"
    uid: 49b931b1-3847-47b5-8c46-179285a9e951
  reason: NodeCurrentRevisionChanged
  reportingComponent: kube-controller-manager-operator-installer-controller
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-installer-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:25Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: kube-controller-manager-operator
    namespace: openshift-kube-controller-manager-operator
    uid: 080df1e1-bf40-4e25-9ebc-542ab5be96d2
  kind: Event
  lastTimestamp: "2025-11-17T09:42:25Z"
  message: 'Status for clusteroperator/kube-controller-manager changed: Progressing
    changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision
    7"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1
    nodes are at revision 6; 2 nodes are at revision 7" to "StaticPodsAvailable: 3
    nodes are active; 3 nodes are at revision 7"'
  metadata:
    creationTimestamp: "2025-11-17T09:42:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-controller-manager-operator
      operation: Update
      time: "2025-11-17T09:42:25Z"
    name: kube-controller-manager-operator.1878c1fcab030d91
    namespace: openshift-kube-controller-manager-operator
    resourceVersion: "28497"
    uid: a6283ed6-1f06-43d7-b437-4daeb8734929
  reason: OperatorStatusChanged
  reportingComponent: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  reportingInstance: ""
  source:
    component: kube-controller-manager-operator-status-controller-statussyncer_kube-controller-manager
  type: Normal
kind: EventList
metadata:
  resourceVersion: "32509"
