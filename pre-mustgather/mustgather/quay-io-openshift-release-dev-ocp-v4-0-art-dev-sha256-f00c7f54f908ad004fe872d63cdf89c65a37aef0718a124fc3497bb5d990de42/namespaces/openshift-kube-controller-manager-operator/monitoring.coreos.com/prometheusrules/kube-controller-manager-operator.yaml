---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2025-11-17T09:05:44Z"
  generation: 1
  managedFields:
  - apiVersion: monitoring.coreos.com/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"5b5cce96-2701-4c85-af4f-4dbf8e0e7775"}: {}
      f:spec:
        .: {}
        f:groups:
          .: {}
          k:{"name":"cluster-version"}:
            .: {}
            f:name: {}
            f:rules: {}
    manager: cluster-version-operator
    operation: Update
    time: "2025-11-17T09:05:44Z"
  name: kube-controller-manager-operator
  namespace: openshift-kube-controller-manager-operator
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: 5b5cce96-2701-4c85-af4f-4dbf8e0e7775
  resourceVersion: "1666"
  uid: 66ea0a70-b859-4aad-beba-a6198ff2732e
spec:
  groups:
  - name: cluster-version
    rules:
    - alert: KubeControllerManagerDown
      annotations:
        description: KubeControllerManager has disappeared from Prometheus target
          discovery.
        runbook_url: https://github.com/openshift/runbooks/blob/XXXXXX/alerts/cluster-kube-controller-manager-operator/KubeControllerManagerDown.md
        summary: Target disappeared from Prometheus target discovery.
      expr: |
        absent(up{job="kube-controller-manager"} == 1)
      for: 15m
      labels:
        namespace: openshift-kube-controller-manager
        severity: critical
    - alert: PodDisruptionBudgetAtLimit
      annotations:
        description: The pod disruption budget is at the minimum disruptions allowed
          level. The number of current healthy pods is equal to the desired healthy
          pods.
        runbook_url: https://github.com/openshift/runbooks/blob/XXXXXX/alerts/cluster-kube-controller-manager-operator/PodDisruptionBudgetAtLimit.md
        summary: The pod disruption budget is preventing further disruption to pods.
      expr: |
        max by(namespace, poddisruptionbudget) (kube_poddisruptionbudget_status_current_healthy == kube_poddisruptionbudget_status_desired_healthy and on (namespace, poddisruptionbudget) kube_poddisruptionbudget_status_expected_pods > 0)
      for: 60m
      labels:
        severity: warning
    - alert: PodDisruptionBudgetLimit
      annotations:
        description: The pod disruption budget is below the minimum disruptions allowed
          level and is not satisfied. The number of current healthy pods is less than
          the desired healthy pods.
        runbook_url: https://github.com/openshift/runbooks/blob/XXXXXX/alerts/cluster-kube-controller-manager-operator/PodDisruptionBudgetLimit.md
        summary: The pod disruption budget registers insufficient amount of pods.
      expr: |
        max by (namespace, poddisruptionbudget) (kube_poddisruptionbudget_status_current_healthy < kube_poddisruptionbudget_status_desired_healthy)
      for: 15m
      labels:
        severity: critical
    - alert: GarbageCollectorSyncFailed
      annotations:
        description: Garbage Collector had a problem with syncing and monitoring the
          available resources. Please see KubeControllerManager logs for more details.
        runbook_url: https://github.com/openshift/runbooks/blob/XXXXXX/alerts/cluster-kube-controller-manager-operator/GarbageCollectorSyncFailed.md
        summary: There was a problem with syncing the resources for garbage collection.
      expr: |
        rate(garbagecollector_controller_resources_sync_error_total{}[5m]) > 0
      for: 60m
      labels:
        severity: warning
