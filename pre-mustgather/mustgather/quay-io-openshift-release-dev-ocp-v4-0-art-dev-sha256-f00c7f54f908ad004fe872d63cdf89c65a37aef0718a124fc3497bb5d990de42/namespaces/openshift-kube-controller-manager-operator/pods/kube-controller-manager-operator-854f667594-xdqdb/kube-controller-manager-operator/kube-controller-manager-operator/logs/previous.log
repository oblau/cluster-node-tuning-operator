2025-11-17T09:27:00.302021533Z I1117 09:27:00.301919       1 cmd.go:233] Using service-serving-cert provided certificates
2025-11-17T09:27:00.302021533Z I1117 09:27:00.301994       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-11-17T09:27:00.302342263Z I1117 09:27:00.302323       1 observer_polling.go:159] Starting file observer
2025-11-17T09:27:13.296399460Z I1117 09:27:13.292333       1 builder.go:271] kube-controller-manager-operator version 4.14.0-202511060117.p2.g4e05963.assembly.stream.el8-4e05963-4e059638c2cbf003551ee699106dc024760eece3
2025-11-17T09:27:13.951890534Z I1117 09:27:13.951837       1 secure_serving.go:57] Forcing use of http/1.1 only
2025-11-17T09:27:13.951890534Z W1117 09:27:13.951860       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:13.951890534Z W1117 09:27:13.951867       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:13.965733927Z I1117 09:27:13.965523       1 leaderelection.go:245] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2025-11-17T09:27:13.966242609Z I1117 09:27:13.966200       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2025-11-17T09:27:13.966276537Z I1117 09:27:13.966264       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2025-11-17T09:27:13.966359550Z I1117 09:27:13.966333       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-11-17T09:27:13.966377046Z I1117 09:27:13.966361       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:13.966407235Z I1117 09:27:13.966382       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-11-17T09:27:13.966426110Z I1117 09:27:13.966413       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:13.968699230Z I1117 09:27:13.968667       1 secure_serving.go:213] Serving securely on [::]:8443
2025-11-17T09:27:13.978744859Z I1117 09:27:13.976508       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2025-11-17T09:27:13.978744859Z I1117 09:27:13.976603       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2025-11-17T09:27:14.067459343Z I1117 09:27:14.067389       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2025-11-17T09:27:14.067459343Z I1117 09:27:14.067371       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:14.076838273Z I1117 09:27:14.076743       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:29:36.413906578Z I1117 09:29:36.413807       1 leaderelection.go:255] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2025-11-17T09:29:36.415825652Z I1117 09:29:36.413999       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"35c308bc-048c-4f6a-821b-922780b1aecf", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"15372", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-854f667594-xdqdb_a285a008-7dba-4235-88fb-8392e871cbbf became leader
2025-11-17T09:29:36.415931784Z I1117 09:29:36.415900       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2025-11-17T09:29:36.426314938Z I1117 09:29:36.426255       1 starter.go:85] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AdmissionWebhookMatchConditions AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BuildCSIVolumes CSIDriverSharedResource CloudDualStackNodeIPs DynamicResourceAllocation EventedPLEG ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP GCPLabelsTags GatewayAPI InsightsConfigAPI MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MaxUnavailableStatefulSet NetworkLiveMigration NodeSwap OpenShiftPodSecurityAdmission PrivateHostedZoneAWS RetroactiveDefaultStorageClass RouteExternalCertificate SigstoreImageVerification VSphereStaticIPs ValidatingAdmissionPolicy]
2025-11-17T09:29:36.426365835Z I1117 09:29:36.426338       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform", "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource", "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration", "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass", "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
2025-11-17T09:29:36.442296872Z I1117 09:29:36.442245       1 base_controller.go:67] Waiting for caches to sync for GarbageCollectorWatcherController
2025-11-17T09:29:36.442418513Z I1117 09:29:36.442388       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2025-11-17T09:29:36.442418513Z I1117 09:29:36.442404       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2025-11-17T09:29:36.442473284Z I1117 09:29:36.442438       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2025-11-17T09:29:36.442479180Z I1117 09:29:36.442473       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2025-11-17T09:29:36.442485069Z I1117 09:29:36.442477       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2025-11-17T09:29:36.442526800Z I1117 09:29:36.442508       1 base_controller.go:67] Waiting for caches to sync for PruneController
2025-11-17T09:29:36.442533062Z I1117 09:29:36.442525       1 base_controller.go:67] Waiting for caches to sync for NodeController
2025-11-17T09:29:36.442577083Z I1117 09:29:36.442550       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:29:36.442577083Z I1117 09:29:36.442571       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2025-11-17T09:29:36.442604974Z I1117 09:29:36.442589       1 base_controller.go:67] Waiting for caches to sync for GuardController
2025-11-17T09:29:36.442633872Z I1117 09:29:36.442393       1 base_controller.go:67] Waiting for caches to sync for SATokenSignerController
2025-11-17T09:29:36.442641153Z I1117 09:29:36.442393       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:29:36.442795127Z I1117 09:29:36.442774       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2025-11-17T09:29:36.442862534Z I1117 09:29:36.442851       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-11-17T09:29:36.442934299Z I1117 09:29:36.442922       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2025-11-17T09:29:36.443029879Z I1117 09:29:36.443005       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2025-11-17T09:29:36.443738592Z I1117 09:29:36.443707       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2025-11-17T09:29:36.443804052Z I1117 09:29:36.443778       1 base_controller.go:67] Waiting for caches to sync for KubeControllerManagerStaticResources
2025-11-17T09:29:36.444214681Z I1117 09:29:36.444191       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2025-11-17T09:29:36.542839240Z I1117 09:29:36.542787       1 base_controller.go:73] Caches are synced for InstallerStateController 
2025-11-17T09:29:36.542899524Z I1117 09:29:36.542884       1 base_controller.go:73] Caches are synced for GuardController 
2025-11-17T09:29:36.542905989Z I1117 09:29:36.542899       1 base_controller.go:110] Starting #1 XXXXXX of GuardController controller ...
2025-11-17T09:29:36.542920111Z I1117 09:29:36.542903       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2025-11-17T09:29:36.542926298Z I1117 09:29:36.542921       1 base_controller.go:110] Starting #1 XXXXXX of LoggingSyncer controller ...
2025-11-17T09:29:36.542943209Z I1117 09:29:36.542935       1 base_controller.go:110] Starting #1 XXXXXX of InstallerStateController controller ...
2025-11-17T09:29:36.542970002Z I1117 09:29:36.542808       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2025-11-17T09:29:36.542976112Z I1117 09:29:36.542968       1 base_controller.go:110] Starting #1 XXXXXX of WorkerLatencyProfile controller ...
2025-11-17T09:29:36.543000003Z I1117 09:29:36.542939       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:29:36.543022275Z I1117 09:29:36.543004       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:29:36.543042577Z I1117 09:29:36.542823       1 base_controller.go:73] Caches are synced for GarbageCollectorWatcherController 
2025-11-17T09:29:36.543067127Z I1117 09:29:36.543057       1 base_controller.go:110] Starting #1 XXXXXX of GarbageCollectorWatcherController controller ...
2025-11-17T09:29:36.543099593Z I1117 09:29:36.542833       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-controller-manager 
2025-11-17T09:29:36.543107707Z I1117 09:29:36.543100       1 base_controller.go:110] Starting #1 XXXXXX of StatusSyncer_kube-controller-manager controller ...
2025-11-17T09:29:36.543134049Z I1117 09:29:36.543068       1 base_controller.go:73] Caches are synced for RevisionController 
2025-11-17T09:29:36.543134049Z I1117 09:29:36.543131       1 base_controller.go:110] Starting #1 XXXXXX of RevisionController controller ...
2025-11-17T09:29:36.543157046Z I1117 09:29:36.542854       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:29:36.543194745Z I1117 09:29:36.543164       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:29:36.543265376Z I1117 09:29:36.542860       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2025-11-17T09:29:36.543274900Z I1117 09:29:36.543264       1 base_controller.go:110] Starting #1 XXXXXX of MissingStaticPodController controller ...
2025-11-17T09:29:36.543349529Z I1117 09:29:36.542867       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2025-11-17T09:29:36.543365029Z I1117 09:29:36.543346       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateController controller ...
2025-11-17T09:29:36.543365029Z I1117 09:29:36.542872       1 base_controller.go:73] Caches are synced for PruneController 
2025-11-17T09:29:36.543373027Z I1117 09:29:36.543364       1 base_controller.go:110] Starting #1 XXXXXX of PruneController controller ...
2025-11-17T09:29:36.543440192Z I1117 09:29:36.542879       1 base_controller.go:73] Caches are synced for NodeController 
2025-11-17T09:29:36.543449012Z I1117 09:29:36.543439       1 base_controller.go:110] Starting #1 XXXXXX of NodeController controller ...
2025-11-17T09:29:36.543881399Z I1117 09:29:36.543853       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:36.543989867Z I1117 09:29:36.543970       1 base_controller.go:73] Caches are synced for InstallerController 
2025-11-17T09:29:36.543989867Z I1117 09:29:36.543984       1 base_controller.go:110] Starting #1 XXXXXX of InstallerController controller ...
2025-11-17T09:29:36.544610003Z I1117 09:29:36.544562       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:36Z","message":"GuardControllerDegraded: Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:36.545121603Z I1117 09:29:36.545087       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2025-11-17T09:29:36.551693888Z I1117 09:29:36.551649       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from False to True ("GuardControllerDegraded: Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has been modified; please apply your changes to the XXXXXX version and try again")
2025-11-17T09:29:36.643185578Z I1117 09:29:36.643126       1 base_controller.go:73] Caches are synced for SATokenSignerController 
2025-11-17T09:29:36.643185578Z I1117 09:29:36.643146       1 base_controller.go:110] Starting #1 XXXXXX of SATokenSignerController controller ...
2025-11-17T09:29:37.044787004Z I1117 09:29:37.044654       1 base_controller.go:73] Caches are synced for BackingResourceController 
2025-11-17T09:29:37.044787004Z I1117 09:29:37.044699       1 base_controller.go:110] Starting #1 XXXXXX of BackingResourceController controller ...
2025-11-17T09:29:37.243365630Z I1117 09:29:37.243298       1 base_controller.go:73] Caches are synced for ConfigObserver 
2025-11-17T09:29:37.243365630Z I1117 09:29:37.243318       1 base_controller.go:110] Starting #1 XXXXXX of ConfigObserver controller ...
2025-11-17T09:29:37.243365630Z I1117 09:29:37.243307       1 base_controller.go:73] Caches are synced for TargetConfigController 
2025-11-17T09:29:37.243365630Z I1117 09:29:37.243338       1 base_controller.go:110] Starting #1 XXXXXX of TargetConfigController controller ...
2025-11-17T09:29:37.635906243Z I1117 09:29:37.635781       1 request.go:696] Waited for 1.193119873s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/secrets?limit=500&resourceVersion=0
2025-11-17T09:29:38.443264275Z I1117 09:29:38.442961       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-11-17T09:29:38.443264275Z I1117 09:29:38.443011       1 base_controller.go:110] Starting #1 XXXXXX of ResourceSyncController controller ...
2025-11-17T09:29:38.636004247Z I1117 09:29:38.635859       1 request.go:696] Waited for 2.192302011s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0
2025-11-17T09:29:38.644542096Z I1117 09:29:38.644397       1 base_controller.go:73] Caches are synced for KubeControllerManagerStaticResources 
2025-11-17T09:29:38.644542096Z I1117 09:29:38.644439       1 base_controller.go:110] Starting #1 XXXXXX of KubeControllerManagerStaticResources controller ...
2025-11-17T09:29:39.441878785Z I1117 09:29:39.441807       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:39.835946989Z I1117 09:29:39.835884       1 request.go:696] Waited for 3.192601694s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2025-11-17T09:29:41.036405320Z I1117 09:29:41.036149       1 request.go:696] Waited for 1.594484284s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2025-11-17T09:29:41.042518536Z I1117 09:29:41.042250       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:41.438563045Z I1117 09:29:41.438508       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2025-11-17T09:29:42.038616412Z I1117 09:29:42.038569       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:29:42.038616412Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:29:42.038616412Z  CurrentRevision: (int32) 5,
2025-11-17T09:29:42.038616412Z  TargetRevision: (int32) 0,
2025-11-17T09:29:42.038616412Z  LastFailedRevision: (int32) 0,
2025-11-17T09:29:42.038616412Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:29:42.038616412Z  LastFailedReason: (string) "",
2025-11-17T09:29:42.038616412Z  LastFailedCount: (int) 0,
2025-11-17T09:29:42.038616412Z  LastFallbackCount: (int) 0,
2025-11-17T09:29:42.038616412Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:29:42.038616412Z }
2025-11-17T09:29:42.038616412Z  because static pod is ready
2025-11-17T09:29:42.051033547Z I1117 09:29:42.050983       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:42.051124926Z I1117 09:29:42.050122       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 0 to 5 because static pod is ready
2025-11-17T09:29:42.051262938Z I1117 09:29:42.051241       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:36Z","message":"GuardControllerDegraded: Unable to apply pod kube-controller-manager-guard-XXXXXX2 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-XXXXXX2\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:42Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:42.059693908Z I1117 09:29:42.059056       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 2 nodes are at revision 5"),Available message changed from "StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5" to "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5"
2025-11-17T09:29:42.236237796Z I1117 09:29:42.236160       1 request.go:696] Waited for 1.193887205s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2025-11-17T09:29:42.241431348Z I1117 09:29:42.241381       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:43.435657338Z I1117 09:29:43.435619       1 request.go:696] Waited for 1.384456306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:29:43.640448113Z I1117 09:29:43.640311       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:44.446343590Z I1117 09:29:44.436171       1 request.go:696] Waited for 1.383535784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:29:44.840977503Z I1117 09:29:44.840915       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:45.052093285Z I1117 09:29:45.052019       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-XXXXXX2 -n openshift-kube-controller-manager because it changed
2025-11-17T09:29:45.064747676Z I1117 09:29:45.064682       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:42Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:45.065023542Z I1117 09:29:45.064993       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:45.071854390Z I1117 09:29:45.071729       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready")
2025-11-17T09:29:45.840903849Z I1117 09:29:45.840846       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:46.235996366Z I1117 09:29:46.235829       1 request.go:696] Waited for 1.191671248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:29:47.435523719Z I1117 09:29:47.435475       1 request.go:696] Waited for 1.71340228s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/secrets
2025-11-17T09:29:47.443102906Z I1117 09:29:47.442999       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/next-service-account-private-key -n openshift-kube-controller-manager-operator because it was missing
2025-11-17T09:29:47.643985557Z I1117 09:29:47.641908       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:48.635590997Z I1117 09:29:48.635538       1 request.go:696] Waited for 1.395137782s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:29:48.841019622Z I1117 09:29:48.840650       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-config-managed:
2025-11-17T09:29:48.841019622Z cause by changes in data.service-account-002.pub
2025-11-17T09:29:49.040625595Z I1117 09:29:49.040368       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:49.636259000Z I1117 09:29:49.636206       1 request.go:696] Waited for 1.397370744s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2025-11-17T09:29:50.241610909Z I1117 09:29:50.241530       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:50.835723678Z I1117 09:29:50.835596       1 request.go:696] Waited for 1.196217286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2025-11-17T09:29:51.442140591Z I1117 09:29:51.442028       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:52.243716474Z I1117 09:29:52.243631       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:52.841735006Z I1117 09:29:52.841662       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-6 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:52.851345332Z I1117 09:29:52.851274       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 5 created because required secret/localhost-recovery-client-token has changed
2025-11-17T09:29:52.852250406Z I1117 09:29:52.852204       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:52.853126452Z I1117 09:29:52.853079       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2025-11-17T09:29:52.856350349Z W1117 09:29:52.856301       1 staticpod.go:38] revision 6 is unexpectedly already the XXXXXX available revision. This is a possible race!
2025-11-17T09:29:52.865905964Z E1117 09:29:52.865862       1 base_controller.go:268] RevisionController reconciliation failed: conflicting XXXXXXAvailableRevision 6
2025-11-17T09:29:52.866661246Z I1117 09:29:52.866616       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:52.866828137Z I1117 09:29:52.866796       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 6","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:42Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:52.876707576Z I1117 09:29:52.875031       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: All XXXXXX nodes are ready\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 6"
2025-11-17T09:29:52.881269478Z I1117 09:29:52.881223       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:52.881510754Z I1117 09:29:52.881468       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:42Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:52.888337383Z I1117 09:29:52.888281       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 6" to "NodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:29:56.438428379Z I1117 09:29:56.438374       1 installer_controller.go:524] node XXXXXX1 with revision 5 is the oldest and needs new revision 6
2025-11-17T09:29:56.438428379Z I1117 09:29:56.438420       1 installer_controller.go:532] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:29:56.438428379Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:29:56.438428379Z  CurrentRevision: (int32) 5,
2025-11-17T09:29:56.438428379Z  TargetRevision: (int32) 6,
2025-11-17T09:29:56.438428379Z  LastFailedRevision: (int32) 0,
2025-11-17T09:29:56.438428379Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:29:56.438428379Z  LastFailedReason: (string) "",
2025-11-17T09:29:56.438428379Z  LastFailedCount: (int) 0,
2025-11-17T09:29:56.438428379Z  LastFallbackCount: (int) 0,
2025-11-17T09:29:56.438428379Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:29:56.438428379Z }
2025-11-17T09:29:56.448899213Z I1117 09:29:56.448843       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX1" from revision 5 to 6 because node XXXXXX1 with revision 5 is the oldest
2025-11-17T09:29:56.449764148Z I1117 09:29:56.449723       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:29:56.451774769Z I1117 09:29:56.451748       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:29:56.474834186Z I1117 09:29:56.474767       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from False to True ("NodeInstallerProgressing: 2 nodes are at revision 5; 0 nodes have achieved new revision 6"),Available message changed from "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5" to "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5; 0 nodes have achieved new revision 6"
2025-11-17T09:29:58.244690087Z I1117 09:29:58.244423       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-XXXXXX1 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:29:59.239155854Z I1117 09:29:59.239090       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:29:59.436089706Z I1117 09:29:59.435976       1 request.go:696] Waited for 1.189215093s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:00.635724261Z I1117 09:30:00.635493       1 request.go:696] Waited for 1.1958537s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:01.438820580Z I1117 09:30:01.438763       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:30:01.635976614Z I1117 09:30:01.635838       1 request.go:696] Waited for 1.087588967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:02.636202126Z I1117 09:30:02.636147       1 request.go:696] Waited for 1.196299979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX1
2025-11-17T09:30:03.636532787Z I1117 09:30:03.636400       1 request.go:696] Waited for 1.19812995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:30:03.839395818Z I1117 09:30:03.839341       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:30:05.638926560Z I1117 09:30:05.638869       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:30:35.064050931Z I1117 09:30:35.063984       1 request.go:696] Waited for 1.097179617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:36.066438626Z I1117 09:30:36.066080       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:30:36.263942572Z I1117 09:30:36.263888       1 request.go:696] Waited for 1.19757851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:37.464073436Z I1117 09:30:37.464018       1 request.go:696] Waited for 1.028997245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:38.464102188Z I1117 09:30:38.464060       1 request.go:696] Waited for 1.395982623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:30:39.663867277Z I1117 09:30:39.663814       1 request.go:696] Waited for 1.192725459s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:40.066193767Z I1117 09:30:40.066142       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2025-11-17T09:30:42.666010437Z I1117 09:30:42.665925       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2025-11-17T09:30:47.063741711Z I1117 09:30:47.063686       1 request.go:696] Waited for 1.112668488s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX1
2025-11-17T09:30:49.065159918Z I1117 09:30:49.065103       1 request.go:696] Waited for 1.121726688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:30:49.275376939Z I1117 09:30:49.271829       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because static pod is pending
2025-11-17T09:30:50.263498104Z I1117 09:30:50.263358       1 request.go:696] Waited for 1.187818323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:30:51.263912363Z I1117 09:30:51.263855       1 request.go:696] Waited for 1.384171732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2025-11-17T09:30:52.463936177Z I1117 09:30:52.463887       1 request.go:696] Waited for 1.397765067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:30:53.663316082Z I1117 09:30:53.663241       1 request.go:696] Waited for 1.195589569s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:31:53.667601793Z E1117 09:31:53.667505       1 guard_controller.go:339] Unable to apply pod kube-controller-manager-guard-XXXXXX1 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1": stream error: stream ID 1255; INTERNAL_ERROR; received from peer
2025-11-17T09:31:54.445409773Z E1117 09:31:54.445367       1 leaderelection.go:327] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io kube-controller-manager-operator-lock)
2025-11-17T09:32:00.279007535Z E1117 09:32:00.278916       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1": stream error: stream ID 1251; INTERNAL_ERROR; received from peer
2025-11-17T09:32:00.675911264Z W1117 09:32:00.675848       1 base_controller.go:232] Updating status of "GuardController" failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:32:00.675957729Z E1117 09:32:00.675906       1 base_controller.go:268] GuardController reconciliation failed: Unable to apply pod kube-controller-manager-guard-XXXXXX1 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1": stream error: stream ID 1255; INTERNAL_ERROR; received from peer
2025-11-17T09:32:36.546995256Z E1117 09:32:36.546809       1 base_controller.go:268] InstallerStateController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)
2025-11-17T09:32:41.445471300Z E1117 09:32:41.445345       1 leaderelection.go:327] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": context deadline exceeded
2025-11-17T09:32:41.445471300Z I1117 09:32:41.445414       1 leaderelection.go:280] failed to renew lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: timed out waiting for the condition
2025-11-17T09:32:49.462513646Z W1117 09:32:49.461656       1 leaderelection.go:85] leader election lost
