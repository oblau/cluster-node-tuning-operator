2025-11-17T09:33:13.363619493Z I1117 09:33:13.363495       1 cmd.go:233] Using service-serving-cert provided certificates
2025-11-17T09:33:13.363619493Z I1117 09:33:13.363587       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-11-17T09:33:13.364440607Z I1117 09:33:13.364073       1 observer_polling.go:159] Starting file observer
2025-11-17T09:33:13.383395092Z I1117 09:33:13.383342       1 builder.go:271] kube-controller-manager-operator version 4.14.0-202511060117.p2.g4e05963.assembly.stream.el8-4e05963-4e059638c2cbf003551ee699106dc024760eece3
2025-11-17T09:33:13.888676512Z I1117 09:33:13.888622       1 secure_serving.go:57] Forcing use of http/1.1 only
2025-11-17T09:33:13.888676512Z W1117 09:33:13.888646       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:33:13.888676512Z W1117 09:33:13.888654       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:33:13.895313340Z I1117 09:33:13.895240       1 leaderelection.go:245] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2025-11-17T09:33:13.897681604Z I1117 09:33:13.897655       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2025-11-17T09:33:13.897719165Z I1117 09:33:13.897686       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2025-11-17T09:33:13.897725687Z I1117 09:33:13.897698       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-11-17T09:33:13.897742905Z I1117 09:33:13.897731       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:33:13.897760662Z I1117 09:33:13.897736       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-11-17T09:33:13.897782445Z I1117 09:33:13.897769       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:33:13.898680096Z I1117 09:33:13.898297       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2025-11-17T09:33:13.899586542Z I1117 09:33:13.899560       1 secure_serving.go:213] Serving securely on [::]:8443
2025-11-17T09:33:13.899635213Z I1117 09:33:13.899615       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2025-11-17T09:33:13.909801357Z I1117 09:33:13.909758       1 leaderelection.go:255] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2025-11-17T09:33:13.909963751Z I1117 09:33:13.909916       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"35c308bc-048c-4f6a-821b-922780b1aecf", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"19584", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-854f667594-xdqdb_ccfd78ca-edf6-4b6e-a9fd-3ce89f61f677 became leader
2025-11-17T09:33:13.910476083Z I1117 09:33:13.910456       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2025-11-17T09:33:13.912783185Z I1117 09:33:13.912739       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform", "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource", "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration", "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass", "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
2025-11-17T09:33:13.912783185Z I1117 09:33:13.912747       1 starter.go:85] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AdmissionWebhookMatchConditions AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BuildCSIVolumes CSIDriverSharedResource CloudDualStackNodeIPs DynamicResourceAllocation EventedPLEG ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP GCPLabelsTags GatewayAPI InsightsConfigAPI MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MaxUnavailableStatefulSet NetworkLiveMigration NodeSwap OpenShiftPodSecurityAdmission PrivateHostedZoneAWS RetroactiveDefaultStorageClass RouteExternalCertificate SigstoreImageVerification VSphereStaticIPs ValidatingAdmissionPolicy]
2025-11-17T09:33:13.933266032Z I1117 09:33:13.933221       1 base_controller.go:67] Waiting for caches to sync for GarbageCollectorWatcherController
2025-11-17T09:33:13.933266032Z I1117 09:33:13.933232       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2025-11-17T09:33:13.933266032Z I1117 09:33:13.933245       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2025-11-17T09:33:13.933341032Z I1117 09:33:13.933327       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2025-11-17T09:33:13.933361885Z I1117 09:33:13.933352       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-11-17T09:33:13.933413707Z I1117 09:33:13.933397       1 base_controller.go:67] Waiting for caches to sync for SATokenSignerController
2025-11-17T09:33:13.933436945Z I1117 09:33:13.933418       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2025-11-17T09:33:13.933490073Z I1117 09:33:13.933478       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2025-11-17T09:33:13.933508454Z I1117 09:33:13.933492       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:33:13.933524461Z I1117 09:33:13.933516       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2025-11-17T09:33:13.933616949Z I1117 09:33:13.933602       1 base_controller.go:67] Waiting for caches to sync for KubeControllerManagerStaticResources
2025-11-17T09:33:13.933623589Z I1117 09:33:13.933617       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2025-11-17T09:33:13.933645032Z I1117 09:33:13.933636       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2025-11-17T09:33:13.933659199Z I1117 09:33:13.933651       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2025-11-17T09:33:13.933672431Z I1117 09:33:13.933665       1 base_controller.go:67] Waiting for caches to sync for PruneController
2025-11-17T09:33:13.934055408Z I1117 09:33:13.934039       1 base_controller.go:67] Waiting for caches to sync for NodeController
2025-11-17T09:33:13.934274596Z I1117 09:33:13.934231       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2025-11-17T09:33:13.934274596Z I1117 09:33:13.934258       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:33:13.934274596Z I1117 09:33:13.934271       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2025-11-17T09:33:13.934313494Z I1117 09:33:13.934282       1 base_controller.go:67] Waiting for caches to sync for GuardController
2025-11-17T09:33:13.997978363Z I1117 09:33:13.997907       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:33:13.998065671Z I1117 09:33:13.998036       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:33:13.999499941Z I1117 09:33:13.999441       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2025-11-17T09:33:14.033848221Z I1117 09:33:14.033777       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-controller-manager 
2025-11-17T09:33:14.033848221Z I1117 09:33:14.033811       1 base_controller.go:110] Starting #1 XXXXXX of StatusSyncer_kube-controller-manager controller ...
2025-11-17T09:33:14.033915353Z I1117 09:33:14.033871       1 base_controller.go:73] Caches are synced for PruneController 
2025-11-17T09:33:14.033915353Z I1117 09:33:14.033876       1 base_controller.go:110] Starting #1 XXXXXX of PruneController controller ...
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034590       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034619       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034624       1 base_controller.go:73] Caches are synced for NodeController 
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034630       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034639       1 base_controller.go:73] Caches are synced for BackingResourceController 
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034645       1 base_controller.go:110] Starting #1 XXXXXX of BackingResourceController controller ...
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034631       1 base_controller.go:110] Starting #1 XXXXXX of NodeController controller ...
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034663       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2025-11-17T09:33:14.035009715Z I1117 09:33:14.034666       1 base_controller.go:110] Starting #1 XXXXXX of LoggingSyncer controller ...
2025-11-17T09:33:14.035209812Z I1117 09:33:14.034657       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:33:14.035209812Z I1117 09:33:14.035202       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:33:14.234060451Z I1117 09:33:14.233991       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2025-11-17T09:33:14.234060451Z I1117 09:33:14.234017       1 base_controller.go:110] Starting #1 XXXXXX of WorkerLatencyProfile controller ...
2025-11-17T09:33:14.234060451Z I1117 09:33:14.234033       1 base_controller.go:73] Caches are synced for RevisionController 
2025-11-17T09:33:14.234060451Z I1117 09:33:14.234050       1 base_controller.go:110] Starting #1 XXXXXX of RevisionController controller ...
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334094       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334118       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateController controller ...
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334128       1 base_controller.go:73] Caches are synced for InstallerController 
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334136       1 base_controller.go:73] Caches are synced for InstallerStateController 
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334140       1 base_controller.go:110] Starting #1 XXXXXX of InstallerStateController controller ...
2025-11-17T09:33:14.334165893Z I1117 09:33:14.334140       1 base_controller.go:110] Starting #1 XXXXXX of InstallerController controller ...
2025-11-17T09:33:14.334241001Z I1117 09:33:14.334131       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2025-11-17T09:33:14.334241001Z I1117 09:33:14.334170       1 base_controller.go:110] Starting #1 XXXXXX of MissingStaticPodController controller ...
2025-11-17T09:33:14.334546008Z I1117 09:33:14.334519       1 base_controller.go:73] Caches are synced for GuardController 
2025-11-17T09:33:14.334546008Z I1117 09:33:14.334534       1 base_controller.go:110] Starting #1 XXXXXX of GuardController controller ...
2025-11-17T09:33:14.833796935Z I1117 09:33:14.833736       1 base_controller.go:73] Caches are synced for ConfigObserver 
2025-11-17T09:33:14.833796935Z I1117 09:33:14.833769       1 base_controller.go:110] Starting #1 XXXXXX of ConfigObserver controller ...
2025-11-17T09:33:14.833858351Z I1117 09:33:14.833734       1 base_controller.go:73] Caches are synced for GarbageCollectorWatcherController 
2025-11-17T09:33:14.833858351Z I1117 09:33:14.833806       1 base_controller.go:110] Starting #1 XXXXXX of GarbageCollectorWatcherController controller ...
2025-11-17T09:33:15.034484438Z I1117 09:33:15.034357       1 base_controller.go:73] Caches are synced for SATokenSignerController 
2025-11-17T09:33:15.034484438Z I1117 09:33:15.034399       1 base_controller.go:110] Starting #1 XXXXXX of SATokenSignerController controller ...
2025-11-17T09:33:15.129794145Z I1117 09:33:15.129727       1 request.go:696] Waited for 1.194312227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?limit=500&resourceVersion=0
2025-11-17T09:33:15.333743424Z I1117 09:33:15.333669       1 base_controller.go:73] Caches are synced for TargetConfigController 
2025-11-17T09:33:15.333743424Z I1117 09:33:15.333692       1 base_controller.go:110] Starting #1 XXXXXX of TargetConfigController controller ...
2025-11-17T09:33:15.733578629Z I1117 09:33:15.733524       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-11-17T09:33:15.733578629Z I1117 09:33:15.733540       1 base_controller.go:110] Starting #1 XXXXXX of ResourceSyncController controller ...
2025-11-17T09:33:16.236360827Z I1117 09:33:16.236299       1 base_controller.go:73] Caches are synced for KubeControllerManagerStaticResources 
2025-11-17T09:33:16.236360827Z I1117 09:33:16.236330       1 base_controller.go:110] Starting #1 XXXXXX of KubeControllerManagerStaticResources controller ...
2025-11-17T09:33:16.330031088Z I1117 09:33:16.329438       1 request.go:696] Waited for 2.294215083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:33:17.330173782Z I1117 09:33:17.330037       1 request.go:696] Waited for 2.29544547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2025-11-17T09:33:18.530065880Z I1117 09:33:18.530012       1 request.go:696] Waited for 1.396072267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:33:18.732941310Z I1117 09:33:18.732868       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2025-11-17T09:33:19.539482940Z I1117 09:33:19.537768       1 installer_controller.go:500] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:33:19.539482940Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:33:19.539482940Z  CurrentRevision: (int32) 6,
2025-11-17T09:33:19.539482940Z  TargetRevision: (int32) 0,
2025-11-17T09:33:19.539482940Z  LastFailedRevision: (int32) 0,
2025-11-17T09:33:19.539482940Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:33:19.539482940Z  LastFailedReason: (string) "",
2025-11-17T09:33:19.539482940Z  LastFailedCount: (int) 0,
2025-11-17T09:33:19.539482940Z  LastFallbackCount: (int) 0,
2025-11-17T09:33:19.539482940Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:33:19.539482940Z }
2025-11-17T09:33:19.539482940Z  because static pod is ready
2025-11-17T09:33:19.551564444Z I1117 09:33:19.551489       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX1" from revision 5 to 6 because static pod is ready
2025-11-17T09:33:19.553408232Z I1117 09:33:19.553355       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:19.555373483Z I1117 09:33:19.555336       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:19.563511064Z I1117 09:33:19.563438       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 5; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 5; 1 nodes are at revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 2 nodes are at revision 5; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes are at revision 6"
2025-11-17T09:33:19.730161387Z I1117 09:33:19.730092       1 request.go:696] Waited for 1.196304821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:33:20.930248205Z I1117 09:33:20.930191       1 request.go:696] Waited for 1.195788409s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:33:22.734437763Z I1117 09:33:22.733474       1 installer_controller.go:500] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:33:22.734437763Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:33:22.734437763Z  CurrentRevision: (int32) 6,
2025-11-17T09:33:22.734437763Z  TargetRevision: (int32) 0,
2025-11-17T09:33:22.734437763Z  LastFailedRevision: (int32) 0,
2025-11-17T09:33:22.734437763Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:33:22.734437763Z  LastFailedReason: (string) "",
2025-11-17T09:33:22.734437763Z  LastFailedCount: (int) 0,
2025-11-17T09:33:22.734437763Z  LastFallbackCount: (int) 0,
2025-11-17T09:33:22.734437763Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:33:22.734437763Z }
2025-11-17T09:33:22.734437763Z  because static pod is ready
2025-11-17T09:33:25.933417364Z I1117 09:33:25.933270       1 installer_controller.go:524] node XXXXXX2 with revision 5 is the oldest and needs new revision 6
2025-11-17T09:33:25.933417364Z I1117 09:33:25.933326       1 installer_controller.go:532] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:33:25.933417364Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:33:25.933417364Z  CurrentRevision: (int32) 5,
2025-11-17T09:33:25.933417364Z  TargetRevision: (int32) 6,
2025-11-17T09:33:25.933417364Z  LastFailedRevision: (int32) 0,
2025-11-17T09:33:25.933417364Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:33:25.933417364Z  LastFailedReason: (string) "",
2025-11-17T09:33:25.933417364Z  LastFailedCount: (int) 0,
2025-11-17T09:33:25.933417364Z  LastFallbackCount: (int) 0,
2025-11-17T09:33:25.933417364Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:33:25.933417364Z }
2025-11-17T09:33:25.945624508Z I1117 09:33:25.945569       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:25.945693857Z I1117 09:33:25.945648       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX2" from revision 5 to 6 because node XXXXXX2 with revision 5 is the oldest
2025-11-17T09:33:27.130235426Z I1117 09:33:27.130144       1 request.go:696] Waited for 1.181288424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:33:27.940610093Z I1117 09:33:27.940082       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-XXXXXX2 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:33:28.933026643Z I1117 09:33:28.932974       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:33:29.129600256Z I1117 09:33:29.129406       1 request.go:696] Waited for 1.189560706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:33:30.329760198Z I1117 09:33:30.329706       1 request.go:696] Waited for 1.193793382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:33:31.330456341Z I1117 09:33:31.330333       1 request.go:696] Waited for 1.197669368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX2
2025-11-17T09:33:31.333965570Z I1117 09:33:31.333930       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:33:32.730183165Z I1117 09:33:32.730141       1 request.go:696] Waited for 1.127109586s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX2
2025-11-17T09:33:33.734188227Z I1117 09:33:33.734136       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:33:35.472186719Z I1117 09:33:35.468755       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new XXXXXX node XXXXXX0
2025-11-17T09:33:35.483666851Z I1117 09:33:35.483543       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new XXXXXX node XXXXXX0
2025-11-17T09:33:35.484708322Z I1117 09:33:35.484665       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady ([container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?, failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes \"XXXXXX0\" not found])","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:35.485161423Z I1117 09:33:35.485137       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:35.499402768Z I1117 09:33:35.499345       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady ([container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?, failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes \"XXXXXX0\" not found])"
2025-11-17T09:33:35.546202821Z I1117 09:33:35.545790       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:35.549879789Z I1117 09:33:35.546614       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetUpdated' Updated PodDisruptionBudget.policy/kube-controller-manager-guard-pdb -n openshift-kube-controller-manager because it changed
2025-11-17T09:33:36.329846043Z I1117 09:33:36.329785       1 request.go:696] Waited for 1.153547863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX2
2025-11-17T09:33:37.330359803Z I1117 09:33:37.330192       1 request.go:696] Waited for 1.197132823s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:33:37.532881039Z I1117 09:33:37.532822       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:33:37.543961868Z I1117 09:33:37.543913       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:37.545307083Z I1117 09:33:37.545257       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady ([container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?, failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes \"XXXXXX0\" not found])","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:37.553518012Z I1117 09:33:37.553465       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 5; 1 nodes are at revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 5; 1 nodes are at revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6"
2025-11-17T09:33:38.729555238Z I1117 09:33:38.729353       1 request.go:696] Waited for 1.184637903s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX2
2025-11-17T09:33:39.732847561Z I1117 09:33:39.732798       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:33:41.732545573Z I1117 09:33:41.732492       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:33:43.732938370Z I1117 09:33:43.732851       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:45.533399336Z I1117 09:33:45.532642       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:45.556985945Z I1117 09:33:45.556940       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:33:45.557854938Z I1117 09:33:45.557808       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:45.567166130Z I1117 09:33:45.567118       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:33:45.567235821Z I1117 09:33:45.567212       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady ([container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?, failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes \"XXXXXX0\" not found])" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)"
2025-11-17T09:33:45.573869171Z E1117 09:33:45.573819       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:33:46.730397006Z I1117 09:33:46.730262       1 request.go:696] Waited for 1.17097913s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-XXXXXX2
2025-11-17T09:33:47.732676286Z I1117 09:33:47.732619       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:33:48.932818163Z I1117 09:33:48.932765       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:51.332747215Z I1117 09:33:51.332693       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:52.932651293Z I1117 09:33:52.932607       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:33:55.769029551Z I1117 09:33:55.768986       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:08.362170129Z I1117 09:34:08.361873       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:08.364004404Z I1117 09:34:08.363973       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:34:10.163318432Z I1117 09:34:10.163223       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2025-11-17T09:34:10.562348948Z I1117 09:34:10.562273       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:11.961812048Z I1117 09:34:11.961689       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:12.362625189Z I1117 09:34:12.362485       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2025-11-17T09:34:20.362120481Z I1117 09:34:20.361983       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2025-11-17T09:34:20.762478864Z I1117 09:34:20.762425       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:22.962108338Z I1117 09:34:22.962050       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because static pod is pending
2025-11-17T09:34:23.966771272Z I1117 09:34:23.966688       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:25.163576709Z I1117 09:34:25.163514       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because static pod is pending
2025-11-17T09:34:26.562145202Z I1117 09:34:26.562092       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:26.962472722Z I1117 09:34:26.962329       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because static pod is pending
2025-11-17T09:34:32.164055428Z I1117 09:34:32.162698       1 installer_controller.go:512] "XXXXXX2" is in transition to 6, but has not made progress because static pod is pending
2025-11-17T09:34:32.354325899Z I1117 09:34:32.354266       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:34.353070841Z I1117 09:34:34.353004       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:34:34.353070841Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:34:34.353070841Z  CurrentRevision: (int32) 6,
2025-11-17T09:34:34.353070841Z  TargetRevision: (int32) 0,
2025-11-17T09:34:34.353070841Z  LastFailedRevision: (int32) 0,
2025-11-17T09:34:34.353070841Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:34:34.353070841Z  LastFailedReason: (string) "",
2025-11-17T09:34:34.353070841Z  LastFailedCount: (int) 0,
2025-11-17T09:34:34.353070841Z  LastFallbackCount: (int) 0,
2025-11-17T09:34:34.353070841Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:34:34.353070841Z }
2025-11-17T09:34:34.353070841Z  because static pod is ready
2025-11-17T09:34:34.366539889Z I1117 09:34:34.366455       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 5 to 6 because static pod is ready
2025-11-17T09:34:34.367628083Z I1117 09:34:34.367579       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:29:45Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:34:34.379468257Z I1117 09:34:34.377257       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 5; 1 nodes are at revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6"
2025-11-17T09:34:35.550450099Z I1117 09:34:35.550307       1 request.go:696] Waited for 1.178730284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2025-11-17T09:34:35.952999813Z I1117 09:34:35.952942       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:35.955149703Z I1117 09:34:35.955044       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:36.559963045Z I1117 09:34:36.559889       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-XXXXXX1 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:34:36.750982635Z I1117 09:34:36.750832       1 request.go:696] Waited for 1.198304118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2025-11-17T09:34:37.950077582Z I1117 09:34:37.949863       1 request.go:696] Waited for 1.389433733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-6-XXXXXX2
2025-11-17T09:34:38.353082789Z I1117 09:34:38.352939       1 installer_controller.go:524] node XXXXXX0 static pod not found and needs new revision 6
2025-11-17T09:34:38.353082789Z I1117 09:34:38.352983       1 installer_controller.go:532] "XXXXXX0" moving to (v1.NodeStatus) {
2025-11-17T09:34:38.353082789Z  NodeName: (string) (len=7) "XXXXXX0",
2025-11-17T09:34:38.353082789Z  CurrentRevision: (int32) 0,
2025-11-17T09:34:38.353082789Z  TargetRevision: (int32) 6,
2025-11-17T09:34:38.353082789Z  LastFailedRevision: (int32) 0,
2025-11-17T09:34:38.353082789Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:34:38.353082789Z  LastFailedReason: (string) "",
2025-11-17T09:34:38.353082789Z  LastFailedCount: (int) 0,
2025-11-17T09:34:38.353082789Z  LastFallbackCount: (int) 0,
2025-11-17T09:34:38.353082789Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:34:38.353082789Z }
2025-11-17T09:34:38.362091886Z I1117 09:34:38.362051       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX0" from revision 0 to 6 because node XXXXXX0 static pod not found
2025-11-17T09:34:38.950585387Z I1117 09:34:38.950399       1 request.go:696] Waited for 1.397392297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2025-11-17T09:34:39.356221616Z I1117 09:34:39.356132       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-XXXXXX2 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:34:39.950667106Z I1117 09:34:39.950458       1 request.go:696] Waited for 1.587103423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:34:41.150017863Z I1117 09:34:41.149971       1 request.go:696] Waited for 1.596062828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:34:42.150224007Z I1117 09:34:42.150171       1 request.go:696] Waited for 1.396340106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:34:42.355747478Z I1117 09:34:42.355614       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-XXXXXX0 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:34:42.759135742Z I1117 09:34:42.759066       1 installer_controller.go:524] node XXXXXX0 static pod not found and needs new revision 6
2025-11-17T09:34:42.759168319Z I1117 09:34:42.759133       1 installer_controller.go:532] "XXXXXX0" moving to (v1.NodeStatus) {
2025-11-17T09:34:42.759168319Z  NodeName: (string) (len=7) "XXXXXX0",
2025-11-17T09:34:42.759168319Z  CurrentRevision: (int32) 0,
2025-11-17T09:34:42.759168319Z  TargetRevision: (int32) 6,
2025-11-17T09:34:42.759168319Z  LastFailedRevision: (int32) 0,
2025-11-17T09:34:42.759168319Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:34:42.759168319Z  LastFailedReason: (string) "",
2025-11-17T09:34:42.759168319Z  LastFailedCount: (int) 0,
2025-11-17T09:34:42.759168319Z  LastFallbackCount: (int) 0,
2025-11-17T09:34:42.759168319Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:34:42.759168319Z }
2025-11-17T09:34:43.350593552Z I1117 09:34:43.350529       1 request.go:696] Waited for 1.38713024s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2025-11-17T09:34:44.350908098Z I1117 09:34:44.350780       1 request.go:696] Waited for 1.398049888s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:34:44.353788734Z I1117 09:34:44.353753       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:34:45.549950413Z I1117 09:34:45.549904       1 request.go:696] Waited for 1.396332014s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2025-11-17T09:34:45.555839891Z I1117 09:34:45.555693       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-XXXXXX0 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:34:46.550351295Z I1117 09:34:46.550276       1 request.go:696] Waited for 1.396527026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-6-XXXXXX2
2025-11-17T09:34:46.952886450Z I1117 09:34:46.952764       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:34:47.750197920Z I1117 09:34:47.750071       1 request.go:696] Waited for 1.395652126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:34:48.950641813Z I1117 09:34:48.950578       1 request.go:696] Waited for 1.397889989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2025-11-17T09:34:49.351934978Z I1117 09:34:49.351883       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:34:49.553628395Z I1117 09:34:49.553563       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:35:22.077496296Z I1117 09:35:22.077430       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:29.102835795Z E1117 09:35:29.101339       1 base_controller.go:268] SATokenSignerController reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:29.119361124Z E1117 09:35:29.116535       1 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-operator.1878c19a2f340d17", GenerateName:"", Namespace:"openshift-kube-controller-manager-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"SecretUpdateFailed", Message:"Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = DeadlineExceeded desc = context deadline exceeded", Source:v1.EventSource{Component:"kube-controller-manager-operator-satokensignercontroller", Host:""}, FirstTimestamp:time.Date(2025, time.November, 17, 9, 35, 22, 76613911, time.Local), LastTimestamp:time.Date(2025, time.November, 17, 9, 35, 22, 76613911, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kube-controller-manager-operator-satokensignercontroller", ReportingInstance:""}': 'rpc error: code = DeadlineExceeded desc = context deadline exceeded' (will not retry!)
2025-11-17T09:35:36.138792058Z I1117 09:35:36.138668       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:43.440082982Z E1117 09:35:43.439868       1 base_controller.go:268] SATokenSignerController reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:50.457256932Z I1117 09:35:50.456814       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:57.462941457Z E1117 09:35:57.462873       1 base_controller.go:268] SATokenSignerController reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:35:57.957896905Z E1117 09:35:57.957792       1 leaderelection.go:327] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": stream error: stream ID 1489; INTERNAL_ERROR; received from peer
2025-11-17T09:36:01.583784260Z I1117 09:36:01.583719       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/service-account-private-key -n openshift-kube-controller-manager because it changed
2025-11-17T09:36:02.531587091Z I1117 09:36:02.531510       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"NodeController_MasterNodesReady","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.531968691Z I1117 09:36:02.531603       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.542773977Z I1117 09:36:02.541104       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from False to True ("NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)")
2025-11-17T09:36:02.542773977Z I1117 09:36:02.542221       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:02.547354378Z E1117 09:36:02.545165       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.547577209Z I1117 09:36:02.547443       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.552119466Z E1117 09:36:02.551885       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.552119466Z I1117 09:36:02.551879       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.552591662Z E1117 09:36:02.552568       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.560195468Z I1117 09:36:02.560149       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.567127285Z E1117 09:36:02.565830       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.581868912Z I1117 09:36:02.581825       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.599705279Z E1117 09:36:02.595244       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.620369944Z I1117 09:36:02.616641       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.622707384Z E1117 09:36:02.620727       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.664360318Z I1117 09:36:02.662764       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.669066311Z E1117 09:36:02.668894       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.752595904Z I1117 09:36:02.749754       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.762320350Z E1117 09:36:02.761626       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:02.926633342Z I1117 09:36:02.923490       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:02.988329467Z I1117 09:36:02.986023       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:03.290711855Z E1117 09:36:03.288533       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:03.290711855Z I1117 09:36:03.290029       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:03.318709992Z E1117 09:36:03.318585       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:03.322389368Z I1117 09:36:03.319204       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again","reason":"NodeController_MasterNodesReady::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:03.928931962Z I1117 09:36:03.928323       1 request.go:696] Waited for 1.114238964s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts?resourceVersion=21060
2025-11-17T09:36:03.928931962Z I1117 09:36:03.928801       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again"
2025-11-17T09:36:05.129847364Z I1117 09:36:05.129793       1 request.go:696] Waited for 2.163049604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:06.328187355Z I1117 09:36:06.328118       1 request.go:696] Waited for 3.168668155s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?resourceVersion=21060
2025-11-17T09:36:07.133460152Z I1117 09:36:07.133399       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:07.133518881Z E1117 09:36:07.133494       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:07.329296499Z I1117 09:36:07.329223       1 request.go:696] Waited for 4.00663337s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets?resourceVersion=21049
2025-11-17T09:36:07.347564135Z I1117 09:36:07.345061       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "required secret/service-account-private-key has changed"
2025-11-17T09:36:08.527997818Z I1117 09:36:08.527937       1 request.go:696] Waited for 4.334019861s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2025-11-17T09:36:09.528813905Z I1117 09:36:09.528735       1 request.go:696] Waited for 2.393769062s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key
2025-11-17T09:36:09.533260371Z I1117 09:36:09.533213       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:09.533385269Z E1117 09:36:09.533360       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the XXXXXX version and try again
2025-11-17T09:36:09.545563555Z I1117 09:36:09.545500       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"NodeController_MasterNodesReady","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:09.555351791Z I1117 09:36:09.555277       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the XXXXXX version and try again" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)"
2025-11-17T09:36:09.736468912Z I1117 09:36:09.736393       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:10.728684809Z I1117 09:36:10.728622       1 request.go:696] Waited for 1.796531863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:11.131772776Z I1117 09:36:11.131631       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:11.543355997Z I1117 09:36:11.540569       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:11.928800420Z I1117 09:36:11.928728       1 request.go:696] Waited for 1.793182214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:36:13.128087666Z I1117 09:36:13.128030       1 request.go:696] Waited for 1.587592186s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2025-11-17T09:36:13.133296665Z I1117 09:36:13.133231       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:13.933177146Z I1117 09:36:13.933119       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:14.130715711Z I1117 09:36:14.130631       1 installer_controller.go:512] "XXXXXX0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:14.327963567Z I1117 09:36:14.327905       1 request.go:696] Waited for 1.395266258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-6-XXXXXX0
2025-11-17T09:36:14.540116754Z I1117 09:36:14.540070       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:15.327977149Z I1117 09:36:15.327921       1 request.go:696] Waited for 1.391969869s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:36:15.934165671Z I1117 09:36:15.934112       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:16.529653712Z I1117 09:36:16.528783       1 request.go:696] Waited for 1.388932182s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2025-11-17T09:36:16.934835191Z I1117 09:36:16.934629       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:17.934678093Z I1117 09:36:17.934623       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:18.730471646Z I1117 09:36:18.730407       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:18.934256316Z I1117 09:36:18.934196       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:19.532761278Z I1117 09:36:19.532667       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:20.134738346Z I1117 09:36:20.133962       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:20.733898215Z I1117 09:36:20.733849       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:21.333894129Z I1117 09:36:21.333833       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:21.345994360Z I1117 09:36:21.345955       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 6 created because required secret/service-account-private-key has changed
2025-11-17T09:36:21.348597877Z I1117 09:36:21.348554       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "required secret/service-account-private-key has changed"
2025-11-17T09:36:21.351433819Z W1117 09:36:21.351413       1 staticpod.go:38] revision 7 is unexpectedly already the XXXXXX available revision. This is a possible race!
2025-11-17T09:36:21.360066443Z E1117 09:36:21.360033       1 base_controller.go:268] RevisionController reconciliation failed: conflicting XXXXXXAvailableRevision 7
2025-11-17T09:36:21.361626698Z I1117 09:36:21.361601       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 7","reason":"NodeController_MasterNodesReady::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:21.369297342Z I1117 09:36:21.368949       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 7"
2025-11-17T09:36:21.373763824Z I1117 09:36:21.373715       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"NodeController_MasterNodesReady","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:21.380216966Z I1117 09:36:21.380143       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)\nRevisionControllerDegraded: conflicting XXXXXXAvailableRevision 7" to "NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)"
2025-11-17T09:36:22.530412669Z I1117 09:36:22.530361       1 request.go:696] Waited for 1.180914008s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:36:23.332732520Z I1117 09:36:23.332687       1 installer_controller.go:500] "XXXXXX0" moving to (v1.NodeStatus) {
2025-11-17T09:36:23.332732520Z  NodeName: (string) (len=7) "XXXXXX0",
2025-11-17T09:36:23.332732520Z  CurrentRevision: (int32) 0,
2025-11-17T09:36:23.332732520Z  TargetRevision: (int32) 7,
2025-11-17T09:36:23.332732520Z  LastFailedRevision: (int32) 0,
2025-11-17T09:36:23.332732520Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:36:23.332732520Z  LastFailedReason: (string) "",
2025-11-17T09:36:23.332732520Z  LastFailedCount: (int) 0,
2025-11-17T09:36:23.332732520Z  LastFallbackCount: (int) 0,
2025-11-17T09:36:23.332732520Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:36:23.332732520Z }
2025-11-17T09:36:23.332732520Z  because new revision pending
2025-11-17T09:36:23.346455085Z I1117 09:36:23.346410       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:36:02Z","message":"NodeControllerDegraded: The XXXXXX nodes not ready: node \"XXXXXX0\" not ready since 2025-11-17 09:33:35 +0000 UTC because KubeletNotReady (container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration file in /etc/kubernetes/cni/net.d/. Has your network provider started?)","reason":"NodeController_MasterNodesReady","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:36:23.354359755Z I1117 09:36:23.354161       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7"
2025-11-17T09:36:23.534809156Z I1117 09:36:23.534742       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-XXXXXX1 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:23.728008767Z I1117 09:36:23.727953       1 request.go:696] Waited for 1.184134237s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:36:24.728248235Z I1117 09:36:24.728196       1 request.go:696] Waited for 1.382729295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:25.927989001Z I1117 09:36:25.927942       1 request.go:696] Waited for 1.596987845s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/kube-controller-manager-pod
2025-11-17T09:36:26.332990427Z I1117 09:36:26.332653       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-XXXXXX0 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:26.533448975Z I1117 09:36:26.533390       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-XXXXXX2 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:27.128228749Z I1117 09:36:27.128155       1 request.go:696] Waited for 1.397887026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:36:27.734382305Z I1117 09:36:27.734166       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:28.128541665Z I1117 09:36:28.128393       1 request.go:696] Waited for 1.38871506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:36:28.533856214Z I1117 09:36:28.533807       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:29.328179624Z I1117 09:36:29.328130       1 request.go:696] Waited for 1.397368385s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2025-11-17T09:36:29.335891775Z I1117 09:36:29.335842       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-XXXXXX0 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:36:30.328479330Z I1117 09:36:30.328349       1 request.go:696] Waited for 1.395919214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2025-11-17T09:36:30.531677447Z I1117 09:36:30.531612       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:31.528249272Z I1117 09:36:31.528188       1 request.go:696] Waited for 1.396165614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2025-11-17T09:36:32.728318128Z I1117 09:36:32.728245       1 request.go:696] Waited for 1.397021258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:36:33.331248765Z I1117 09:36:33.331183       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:33.928474004Z I1117 09:36:33.928279       1 request.go:696] Waited for 1.392195421s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:36:34.131468293Z I1117 09:36:34.131414       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:35.731773228Z I1117 09:36:35.731705       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:36:37.530864895Z I1117 09:36:37.530808       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:37.534753053Z I1117 09:36:37.534638       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:45.582945807Z I1117 09:36:45.581384       1 request.go:696] Waited for 1.01348355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:46.781086291Z I1117 09:36:46.780997       1 request.go:696] Waited for 1.997179391s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2025-11-17T09:36:47.981241846Z I1117 09:36:47.981201       1 request.go:696] Waited for 2.379373417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:49.180523413Z I1117 09:36:49.180468       1 request.go:696] Waited for 1.192310377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2025-11-17T09:36:54.982274670Z I1117 09:36:54.982216       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:56.594394386Z I1117 09:36:56.594337       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:58.863709161Z I1117 09:36:58.863617       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:36:58.984456047Z I1117 09:36:58.984394       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:14.586091337Z I1117 09:37:14.586006       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:17.741060160Z I1117 09:37:17.740988       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:20.340779196Z I1117 09:37:20.340689       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:21.141699064Z I1117 09:37:21.141619       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:21.940433931Z I1117 09:37:21.940374       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:22.941556685Z I1117 09:37:22.941474       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:37:23.348510035Z I1117 09:37:23.348444       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:24.739866024Z I1117 09:37:24.739822       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:25.540380733Z I1117 09:37:25.540279       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:26.340319064Z I1117 09:37:26.340252       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:29.113232235Z I1117 09:37:29.113166       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:39.837667595Z I1117 09:37:39.837616       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:50.830996293Z I1117 09:37:50.830922       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:51.758431562Z I1117 09:37:51.758300       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:52.086740017Z I1117 09:37:52.086591       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:58.010512809Z I1117 09:37:58.010431       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:58.038934993Z I1117 09:37:58.038869       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:37:58.344909891Z I1117 09:37:58.344776       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:00.332054741Z I1117 09:38:00.331978       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:03.166418458Z I1117 09:38:03.165784       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:05.188954290Z I1117 09:38:05.188816       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:07.368315042Z I1117 09:38:07.368258       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:07.607987057Z I1117 09:38:07.607736       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:07.618326475Z I1117 09:38:07.618264       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:09.172430620Z I1117 09:38:09.172370       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:10.372529220Z I1117 09:38:10.372474       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:10.772827833Z I1117 09:38:10.772754       1 guard_controller.go:267] Node XXXXXX0 not ready, skipping reconciling the guard pod
2025-11-17T09:38:21.719530557Z I1117 09:38:21.716777       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:38:21.813485527Z I1117 09:38:21.813416       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from True to False ("NodeControllerDegraded: All XXXXXX nodes are ready")
2025-11-17T09:38:22.432900219Z I1117 09:38:22.432843       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:23.209563148Z E1117 09:38:23.209367       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:23.466431307Z I1117 09:38:23.466370       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:38:23.617361887Z E1117 09:38:23.616527       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:23.631785583Z I1117 09:38:23.631729       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0"
2025-11-17T09:38:25.308745292Z I1117 09:38:25.308680       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:25.505331507Z I1117 09:38:25.505262       1 request.go:696] Waited for 1.003175856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:38:25.508173679Z E1117 09:38:25.508133       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:27.108002810Z E1117 09:38:27.107927       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:29.517588068Z E1117 09:38:29.517527       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:29.517839127Z E1117 09:38:29.517803       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:31.907567466Z E1117 09:38:31.907508       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:31.907796362Z E1117 09:38:31.907765       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:33.911171668Z E1117 09:38:33.907874       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:33.911171668Z E1117 09:38:33.908134       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:35.508138914Z E1117 09:38:35.508057       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:35.508386293Z E1117 09:38:35.508360       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:37.108178054Z E1117 09:38:37.108035       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:37.108601401Z E1117 09:38:37.108572       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:39.305408127Z I1117 09:38:39.305356       1 request.go:696] Waited for 1.04522984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:38:39.507772038Z E1117 09:38:39.507700       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:39.507948610Z E1117 09:38:39.507925       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:40.505483165Z I1117 09:38:40.505439       1 request.go:696] Waited for 1.197491761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:38:40.507867465Z I1117 09:38:40.507831       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:42.507611471Z I1117 09:38:42.507566       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:38:43.506968043Z E1117 09:38:43.506921       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:43.507190265Z E1117 09:38:43.507172       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:46.109353161Z E1117 09:38:46.107712       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:46.109353161Z E1117 09:38:46.107994       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:48.507739960Z E1117 09:38:48.507678       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:48.508133735Z E1117 09:38:48.508113       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:49.705116463Z I1117 09:38:49.705033       1 request.go:696] Waited for 1.108520765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:38:50.507534972Z I1117 09:38:50.507466       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:38:52.105148004Z I1117 09:38:52.105091       1 request.go:696] Waited for 1.092675548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2025-11-17T09:38:53.019636408Z I1117 09:38:53.019591       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:38:53.105503246Z I1117 09:38:53.105457       1 request.go:696] Waited for 1.397761135s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:38:53.117426725Z E1117 09:38:53.117159       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:53.118153504Z E1117 09:38:53.118120       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:53.120560716Z E1117 09:38:53.120533       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:38:54.305610107Z I1117 09:38:54.305553       1 request.go:696] Waited for 1.183945381s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:38:55.307162956Z I1117 09:38:55.307118       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:38:55.504683745Z I1117 09:38:55.504609       1 request.go:696] Waited for 1.19199123s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX1
2025-11-17T09:38:56.505454058Z I1117 09:38:56.505391       1 request.go:696] Waited for 1.197147351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:38:57.705187563Z I1117 09:38:57.705116       1 request.go:696] Waited for 1.196565013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:38:57.708363811Z I1117 09:38:57.708319       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:38:57.908533391Z E1117 09:38:57.908483       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:38:59.707891894Z I1117 09:38:59.707824       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:39:01.516677113Z I1117 09:39:01.516598       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:39:01.707945440Z E1117 09:39:01.707877       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:01.708181302Z E1117 09:39:01.708157       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:02.908661172Z E1117 09:39:02.908600       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:03.908174578Z E1117 09:39:03.908112       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:04.911263677Z E1117 09:39:04.911190       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:04.911506018Z E1117 09:39:04.911483       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:05.707833416Z E1117 09:39:05.707779       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:05.708045904Z E1117 09:39:05.708015       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:06.108577150Z E1117 09:39:06.108511       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:06.508210451Z E1117 09:39:06.508132       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:10.091925004Z E1117 09:39:10.091860       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:10.092140710Z E1117 09:39:10.092118       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:11.713406352Z E1117 09:39:11.713335       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:11.713692287Z E1117 09:39:11.713672       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:15.094082308Z E1117 09:39:15.094020       1 guard_controller.go:271] Missing operand on node XXXXXX0
2025-11-17T09:39:15.094273098Z E1117 09:39:15.094247       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node XXXXXX0
2025-11-17T09:39:20.470801531Z E1117 09:39:20.470733       1 guard_controller.go:277] Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0
2025-11-17T09:39:21.142241485Z I1117 09:39:21.142173       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:39:21.355915505Z I1117 09:39:21.355857       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:39:21.366320525Z I1117 09:39:21.364538       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0" to "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2025-11-17T09:39:22.543337156Z I1117 09:39:22.538660       1 request.go:696] Waited for 1.182988688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX1
2025-11-17T09:39:23.539038178Z I1117 09:39:23.538910       1 request.go:696] Waited for 1.591663288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2025-11-17T09:39:24.539263845Z I1117 09:39:24.539196       1 request.go:696] Waited for 1.394042991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:24.758954128Z E1117 09:39:24.758904       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0
2025-11-17T09:39:24.759942354Z I1117 09:39:24.759892       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:39:24.769355107Z I1117 09:39:24.766822       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing operand on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2025-11-17T09:39:25.144909789Z I1117 09:39:25.144857       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:25.739344004Z I1117 09:39:25.739207       1 request.go:696] Waited for 1.39640603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2025-11-17T09:39:26.939676255Z I1117 09:39:26.939605       1 request.go:696] Waited for 1.193211678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2025-11-17T09:39:28.139066641Z I1117 09:39:28.139004       1 request.go:696] Waited for 1.1954176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:39:28.941738739Z I1117 09:39:28.941662       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:29.339053376Z I1117 09:39:29.338958       1 request.go:696] Waited for 1.197466078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:39:30.344814547Z I1117 09:39:30.344759       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-XXXXXX0 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:39:31.539405259Z I1117 09:39:31.539341       1 request.go:696] Waited for 1.193336284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:39:32.154678262Z I1117 09:39:32.154503       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:39:32.161848653Z I1117 09:39:32.161788       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-XXXXXX0 on node XXXXXX0\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2025-11-17T09:39:32.738780419Z I1117 09:39:32.738704       1 request.go:696] Waited for 1.194927301s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:39:33.739522022Z I1117 09:39:33.739444       1 request.go:696] Waited for 1.577983691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:39:34.143272583Z I1117 09:39:34.143195       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:34.739570691Z I1117 09:39:34.739498       1 request.go:696] Waited for 1.197613736s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX2
2025-11-17T09:39:35.939089463Z I1117 09:39:35.938947       1 request.go:696] Waited for 1.396777386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2025-11-17T09:39:36.939646626Z I1117 09:39:36.939507       1 request.go:696] Waited for 1.395415775s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:37.943048840Z I1117 09:39:37.942885       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:38.139359567Z I1117 09:39:38.139189       1 request.go:696] Waited for 1.193685516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:38.747861444Z I1117 09:39:38.747791       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-XXXXXX0 -n openshift-kube-controller-manager because it changed
2025-11-17T09:39:39.938930574Z I1117 09:39:39.938877       1 request.go:696] Waited for 1.1910028s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:41.139608977Z I1117 09:39:41.139537       1 request.go:696] Waited for 1.195115921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:41.360218615Z I1117 09:39:41.360041       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:39:41.368585887Z I1117 09:39:41.368537       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-XXXXXX0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "NodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:39:41.541721069Z I1117 09:39:41.541583       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:42.339548473Z I1117 09:39:42.339412       1 request.go:696] Waited for 1.195127248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:39:43.539352719Z I1117 09:39:43.539222       1 request.go:696] Waited for 1.587739024s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2025-11-17T09:39:44.539450841Z I1117 09:39:44.539348       1 request.go:696] Waited for 1.197639145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2025-11-17T09:39:45.545013366Z I1117 09:39:45.544943       1 installer_controller.go:512] "XXXXXX0" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:39:45.738679221Z I1117 09:39:45.738622       1 request.go:696] Waited for 1.196338247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2025-11-17T09:39:53.342566315Z I1117 09:39:53.342506       1 installer_controller.go:500] "XXXXXX0" moving to (v1.NodeStatus) {
2025-11-17T09:39:53.342566315Z  NodeName: (string) (len=7) "XXXXXX0",
2025-11-17T09:39:53.342566315Z  CurrentRevision: (int32) 7,
2025-11-17T09:39:53.342566315Z  TargetRevision: (int32) 0,
2025-11-17T09:39:53.342566315Z  LastFailedRevision: (int32) 0,
2025-11-17T09:39:53.342566315Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:39:53.342566315Z  LastFailedReason: (string) "",
2025-11-17T09:39:53.342566315Z  LastFailedCount: (int) 0,
2025-11-17T09:39:53.342566315Z  LastFallbackCount: (int) 0,
2025-11-17T09:39:53.342566315Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:39:53.342566315Z }
2025-11-17T09:39:53.342566315Z  because static pod is ready
2025-11-17T09:39:53.352195064Z I1117 09:39:53.352134       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX0" from revision 0 to 7 because static pod is ready
2025-11-17T09:39:53.353618852Z I1117 09:39:53.353532       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 2 nodes are at revision 6; 1 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 6; 1 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:39:53.362433276Z I1117 09:39:53.362380       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 2 nodes are at revision 6; 1 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 6; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 6; 1 nodes are at revision 7"
2025-11-17T09:39:54.539577222Z I1117 09:39:54.539373       1 request.go:696] Waited for 1.185181718s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2025-11-17T09:39:55.539796510Z I1117 09:39:55.539551       1 request.go:696] Waited for 1.397107946s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX0
2025-11-17T09:39:56.739404903Z I1117 09:39:56.739342       1 request.go:696] Waited for 1.196491942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX0
2025-11-17T09:39:56.743177977Z I1117 09:39:56.743144       1 installer_controller.go:500] "XXXXXX0" moving to (v1.NodeStatus) {
2025-11-17T09:39:56.743177977Z  NodeName: (string) (len=7) "XXXXXX0",
2025-11-17T09:39:56.743177977Z  CurrentRevision: (int32) 7,
2025-11-17T09:39:56.743177977Z  TargetRevision: (int32) 0,
2025-11-17T09:39:56.743177977Z  LastFailedRevision: (int32) 0,
2025-11-17T09:39:56.743177977Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:39:56.743177977Z  LastFailedReason: (string) "",
2025-11-17T09:39:56.743177977Z  LastFailedCount: (int) 0,
2025-11-17T09:39:56.743177977Z  LastFallbackCount: (int) 0,
2025-11-17T09:39:56.743177977Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:39:56.743177977Z }
2025-11-17T09:39:56.743177977Z  because static pod is ready
2025-11-17T09:39:57.388336565Z I1117 09:39:57.388251       1 gcwatcher_controller.go:250] Synced alerting rules cache
2025-11-17T09:39:57.739630408Z I1117 09:39:57.739583       1 request.go:696] Waited for 1.197862361s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:39:58.939622196Z I1117 09:39:58.939565       1 request.go:696] Waited for 1.396131839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2025-11-17T09:40:00.139567772Z I1117 09:40:00.139494       1 request.go:696] Waited for 1.19687642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2025-11-17T09:40:01.339481963Z I1117 09:40:01.339430       1 request.go:696] Waited for 1.196281644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:40:03.743042388Z I1117 09:40:03.742892       1 installer_controller.go:524] node XXXXXX1 with revision 6 is the oldest and needs new revision 7
2025-11-17T09:40:03.743042388Z I1117 09:40:03.742944       1 installer_controller.go:532] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:40:03.743042388Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:40:03.743042388Z  CurrentRevision: (int32) 6,
2025-11-17T09:40:03.743042388Z  TargetRevision: (int32) 7,
2025-11-17T09:40:03.743042388Z  LastFailedRevision: (int32) 0,
2025-11-17T09:40:03.743042388Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:40:03.743042388Z  LastFailedReason: (string) "",
2025-11-17T09:40:03.743042388Z  LastFailedCount: (int) 0,
2025-11-17T09:40:03.743042388Z  LastFallbackCount: (int) 0,
2025-11-17T09:40:03.743042388Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:40:03.743042388Z }
2025-11-17T09:40:03.765822921Z I1117 09:40:03.765747       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX1" from revision 6 to 7 because node XXXXXX1 with revision 6 is the oldest
2025-11-17T09:40:04.938626922Z I1117 09:40:04.938584       1 request.go:696] Waited for 1.171901888s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:40:05.749261486Z I1117 09:40:05.749184       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-XXXXXX1 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:40:06.939735957Z I1117 09:40:06.939638       1 request.go:696] Waited for 1.190498615s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX1
2025-11-17T09:40:06.944530366Z I1117 09:40:06.944436       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:40:08.138728543Z I1117 09:40:08.138669       1 request.go:696] Waited for 1.39347493s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:40:09.139228147Z I1117 09:40:09.139155       1 request.go:696] Waited for 1.194790398s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2025-11-17T09:40:09.544431216Z I1117 09:40:09.544241       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:40:10.338765189Z I1117 09:40:10.338707       1 request.go:696] Waited for 1.195923494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/controller-manager-kubeconfig
2025-11-17T09:40:11.339256186Z I1117 09:40:11.339191       1 request.go:696] Waited for 1.193375013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2025-11-17T09:40:11.746511091Z I1117 09:40:11.746457       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:40:15.539665493Z I1117 09:40:15.539535       1 request.go:696] Waited for 1.197169529s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-XXXXXX2
2025-11-17T09:40:41.892708160Z I1117 09:40:41.892620       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:40:43.689132843Z I1117 09:40:43.689081       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2025-11-17T09:40:46.488730535Z I1117 09:40:46.488675       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2025-11-17T09:40:53.957054475Z I1117 09:40:53.956989       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:40:55.948025494Z I1117 09:40:55.947964       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:40:58.147513062Z I1117 09:40:58.147457       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:41:03.998081800Z I1117 09:41:03.997922       1 installer_controller.go:512] "XXXXXX1" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:41:06.190014489Z I1117 09:41:06.189929       1 installer_controller.go:500] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:41:06.190014489Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:41:06.190014489Z  CurrentRevision: (int32) 7,
2025-11-17T09:41:06.190014489Z  TargetRevision: (int32) 0,
2025-11-17T09:41:06.190014489Z  LastFailedRevision: (int32) 0,
2025-11-17T09:41:06.190014489Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:41:06.190014489Z  LastFailedReason: (string) "",
2025-11-17T09:41:06.190014489Z  LastFailedCount: (int) 0,
2025-11-17T09:41:06.190014489Z  LastFallbackCount: (int) 0,
2025-11-17T09:41:06.190014489Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:41:06.190014489Z }
2025-11-17T09:41:06.190014489Z  because static pod is ready
2025-11-17T09:41:06.200237336Z I1117 09:41:06.200176       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX1" from revision 6 to 7 because static pod is ready
2025-11-17T09:41:06.206952842Z I1117 09:41:06.206917       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:29:56Z","message":"NodeInstallerProgressing: 1 nodes are at revision 6; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 6; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:41:06.214507961Z I1117 09:41:06.214459       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 6; 1 nodes are at revision 7" to "NodeInstallerProgressing: 1 nodes are at revision 6; 2 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 6; 1 nodes are at revision 7" to "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 6; 2 nodes are at revision 7"
2025-11-17T09:41:07.387748179Z I1117 09:41:07.387693       1 request.go:696] Waited for 1.180621205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX1
2025-11-17T09:41:08.388035203Z I1117 09:41:08.387899       1 request.go:696] Waited for 1.178942732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2025-11-17T09:41:09.587903258Z I1117 09:41:09.587813       1 request.go:696] Waited for 1.195995457s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2025-11-17T09:41:09.990869972Z I1117 09:41:09.990804       1 installer_controller.go:500] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:41:09.990869972Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:41:09.990869972Z  CurrentRevision: (int32) 7,
2025-11-17T09:41:09.990869972Z  TargetRevision: (int32) 0,
2025-11-17T09:41:09.990869972Z  LastFailedRevision: (int32) 0,
2025-11-17T09:41:09.990869972Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:41:09.990869972Z  LastFailedReason: (string) "",
2025-11-17T09:41:09.990869972Z  LastFailedCount: (int) 0,
2025-11-17T09:41:09.990869972Z  LastFallbackCount: (int) 0,
2025-11-17T09:41:09.990869972Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:41:09.990869972Z }
2025-11-17T09:41:09.990869972Z  because static pod is ready
2025-11-17T09:41:10.588152929Z I1117 09:41:10.588081       1 request.go:696] Waited for 1.197535384s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:41:14.390453840Z I1117 09:41:14.390323       1 installer_controller.go:524] node XXXXXX2 with revision 6 is the oldest and needs new revision 7
2025-11-17T09:41:14.390453840Z I1117 09:41:14.390374       1 installer_controller.go:532] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:41:14.390453840Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:41:14.390453840Z  CurrentRevision: (int32) 6,
2025-11-17T09:41:14.390453840Z  TargetRevision: (int32) 7,
2025-11-17T09:41:14.390453840Z  LastFailedRevision: (int32) 0,
2025-11-17T09:41:14.390453840Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:41:14.390453840Z  LastFailedReason: (string) "",
2025-11-17T09:41:14.390453840Z  LastFailedCount: (int) 0,
2025-11-17T09:41:14.390453840Z  LastFallbackCount: (int) 0,
2025-11-17T09:41:14.390453840Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:41:14.390453840Z }
2025-11-17T09:41:14.400396200Z I1117 09:41:14.400345       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX2" from revision 6 to 7 because node XXXXXX2 with revision 6 is the oldest
2025-11-17T09:41:15.587618412Z I1117 09:41:15.587556       1 request.go:696] Waited for 1.186071146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX1
2025-11-17T09:41:16.787960988Z I1117 09:41:16.787893       1 request.go:696] Waited for 1.197822557s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX2
2025-11-17T09:41:16.993818735Z I1117 09:41:16.993747       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-XXXXXX2 -n openshift-kube-controller-manager because it was missing
2025-11-17T09:41:18.187785944Z I1117 09:41:18.187729       1 request.go:696] Waited for 1.194003102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-XXXXXX2
2025-11-17T09:41:18.190868338Z I1117 09:41:18.190828       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:41:19.188060992Z I1117 09:41:19.187971       1 request.go:696] Waited for 1.1920518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:41:20.387655669Z I1117 09:41:20.387591       1 request.go:696] Waited for 1.194575024s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2025-11-17T09:41:20.590617061Z I1117 09:41:20.590478       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:41:21.388177555Z I1117 09:41:21.388042       1 request.go:696] Waited for 1.195474269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2025-11-17T09:41:22.388316227Z I1117 09:41:22.388130       1 request.go:696] Waited for 1.197541589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX1
2025-11-17T09:41:22.791002368Z I1117 09:41:22.790940       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:41:53.201371658Z I1117 09:41:53.201219       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:41:55.557897635Z I1117 09:41:55.557832       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2025-11-17T09:41:57.557752837Z I1117 09:41:57.557687       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2025-11-17T09:42:03.208437799Z I1117 09:42:03.208341       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2025-11-17T09:42:06.005147481Z I1117 09:42:06.005080       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:42:08.004549972Z I1117 09:42:08.004489       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:42:14.153676954Z I1117 09:42:14.153596       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:42:16.644619580Z I1117 09:42:16.644546       1 installer_controller.go:512] "XXXXXX2" is in transition to 7, but has not made progress because static pod is pending
2025-11-17T09:42:25.044051243Z I1117 09:42:25.043986       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:42:25.044051243Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:42:25.044051243Z  CurrentRevision: (int32) 7,
2025-11-17T09:42:25.044051243Z  TargetRevision: (int32) 0,
2025-11-17T09:42:25.044051243Z  LastFailedRevision: (int32) 0,
2025-11-17T09:42:25.044051243Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:42:25.044051243Z  LastFailedReason: (string) "",
2025-11-17T09:42:25.044051243Z  LastFailedCount: (int) 0,
2025-11-17T09:42:25.044051243Z  LastFallbackCount: (int) 0,
2025-11-17T09:42:25.044051243Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:42:25.044051243Z }
2025-11-17T09:42:25.044051243Z  because static pod is ready
2025-11-17T09:42:25.053667618Z I1117 09:42:25.053615       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 6 to 7 because static pod is ready
2025-11-17T09:42:25.054720529Z I1117 09:42:25.054661       1 status_controller.go:215] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:38:21Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:42:25Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:23:54Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:22Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:22Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:42:25.064631618Z I1117 09:42:25.060592       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"080df1e1-bf40-4e25-9ebc-542ab5be96d2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 7"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 6; 2 nodes are at revision 7" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7"
2025-11-17T09:42:26.241084616Z I1117 09:42:26.240993       1 request.go:696] Waited for 1.185777768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2025-11-17T09:42:27.241483844Z I1117 09:42:27.241424       1 request.go:696] Waited for 1.196078351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX2
2025-11-17T09:42:28.441439564Z I1117 09:42:28.441370       1 request.go:696] Waited for 1.196451738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-XXXXXX0
2025-11-17T09:42:28.845064826Z I1117 09:42:28.845006       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:42:28.845064826Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:42:28.845064826Z  CurrentRevision: (int32) 7,
2025-11-17T09:42:28.845064826Z  TargetRevision: (int32) 0,
2025-11-17T09:42:28.845064826Z  LastFailedRevision: (int32) 0,
2025-11-17T09:42:28.845064826Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:42:28.845064826Z  LastFailedReason: (string) "",
2025-11-17T09:42:28.845064826Z  LastFailedCount: (int) 0,
2025-11-17T09:42:28.845064826Z  LastFallbackCount: (int) 0,
2025-11-17T09:42:28.845064826Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:42:28.845064826Z }
2025-11-17T09:42:28.845064826Z  because static pod is ready
2025-11-17T09:42:29.641061430Z I1117 09:42:29.640999       1 request.go:696] Waited for 1.19555684s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/revision-status-2
2025-11-17T09:42:30.641334720Z I1117 09:42:30.641236       1 request.go:696] Waited for 1.197143023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-XXXXXX2
2025-11-17T09:42:38.641188866Z I1117 09:42:38.640984       1 request.go:696] Waited for 1.172213347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2025-11-17T09:46:07.536856325Z I1117 09:46:07.536624       1 request.go:696] Waited for 1.197732996s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:46:08.736799440Z I1117 09:46:08.736721       1 request.go:696] Waited for 1.197126087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2025-11-17T09:46:15.536974038Z I1117 09:46:15.536871       1 request.go:696] Waited for 1.193413119s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
