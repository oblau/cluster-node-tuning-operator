2025-11-17T09:27:22.437113431Z I1117 09:27:22.436808       1 profiler.go:21] Starting profiling endpoint at http://127.0.0.1:6060/debug/pprof/
2025-11-17T09:27:22.437257940Z I1117 09:27:22.437051       1 observer_polling.go:159] Starting file observer
2025-11-17T09:27:22.437326109Z I1117 09:27:22.437308       1 cmd.go:233] Using service-serving-cert provided certificates
2025-11-17T09:27:22.437383144Z I1117 09:27:22.437355       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-11-17T09:27:22.438041116Z I1117 09:27:22.438012       1 observer_polling.go:159] Starting file observer
2025-11-17T09:27:22.455680957Z I1117 09:27:22.455547       1 builder.go:271] openshift-cluster-etcd-operator version 4.14.0-202511060117.p2.g9abf7d2.assembly.stream.el8-9abf7d2-9abf7d22b5fda0e06fb1f9a2fa90caaa09d5a932
2025-11-17T09:27:22.713185176Z I1117 09:27:22.713138       1 secure_serving.go:57] Forcing use of http/1.1 only
2025-11-17T09:27:22.713185176Z W1117 09:27:22.713159       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:22.713185176Z W1117 09:27:22.713166       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:22.715907884Z I1117 09:27:22.715873       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2025-11-17T09:27:22.715929425Z I1117 09:27:22.715901       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-11-17T09:27:22.715929425Z I1117 09:27:22.715915       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2025-11-17T09:27:22.715929425Z I1117 09:27:22.715923       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:22.715937694Z I1117 09:27:22.715927       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-11-17T09:27:22.715953988Z I1117 09:27:22.715942       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:22.716398044Z I1117 09:27:22.716342       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2025-11-17T09:27:22.717210106Z I1117 09:27:22.717125       1 secure_serving.go:210] Serving securely on [::]:8443
2025-11-17T09:27:22.717210106Z I1117 09:27:22.717199       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2025-11-17T09:27:22.721142910Z I1117 09:27:22.721110       1 leaderelection.go:250] attempting to acquire leader lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock...
2025-11-17T09:27:22.819480594Z I1117 09:27:22.819430       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2025-11-17T09:27:22.819480594Z I1117 09:27:22.819458       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:22.819581018Z I1117 09:27:22.819430       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:30:05.862035013Z I1117 09:30:05.861981       1 leaderelection.go:260] successfully acquired lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock
2025-11-17T09:30:05.862250464Z I1117 09:30:05.862194       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-etcd-operator", Name:"openshift-cluster-etcd-operator-lock", UID:"5c5e32c5-449b-4b7e-8531-befaa8976a38", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"15709", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' etcd-operator-6864485db7-n5l65_8cd96a51-f06f-458f-afb5-c55d7d1bab1f became leader
2025-11-17T09:30:05.867716469Z I1117 09:30:05.867592       1 starter.go:166] recorded cluster versions: map[etcd:4.14.59 operator:4.14.59 raw-internal:4.14.59]
2025-11-17T09:30:05.878154054Z I1117 09:30:05.878106       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2025-11-17T09:30:05.880716366Z I1117 09:30:05.880672       1 starter.go:435] FeatureGates initializedenabled[AlibabaPlatform AzureWorkloadIdentity BuildCSIVolumes CloudDualStackNodeIPs ExternalCloudProviderAzure ExternalCloudProviderExternal PrivateHostedZoneAWS]disabled[AdminNetworkPolicy AdmissionWebhookMatchConditions AutomatedEtcdBackup CSIDriverSharedResource DynamicResourceAllocation EventedPLEG ExternalCloudProvider ExternalCloudProviderGCP GCPLabelsTags GatewayAPI InsightsConfigAPI MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MaxUnavailableStatefulSet NetworkLiveMigration NodeSwap OpenShiftPodSecurityAdmission RetroactiveDefaultStorageClass RouteExternalCertificate SigstoreImageVerification VSphereStaticIPs ValidatingAdmissionPolicy]
2025-11-17T09:30:05.880716366Z I1117 09:30:05.880709       1 starter.go:490] waiting for cluster version informer sync...
2025-11-17T09:30:05.880770483Z I1117 09:30:05.880742       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform", "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource", "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration", "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass", "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
2025-11-17T09:30:05.988582858Z I1117 09:30:05.988436       1 starter.go:513] Detected available machine API, starting vertical scaling related controllers and informers...
2025-11-17T09:30:05.988985170Z I1117 09:30:05.988963       1 base_controller.go:67] Waiting for caches to sync for ClusterMemberRemovalController
2025-11-17T09:30:05.989037017Z I1117 09:30:05.989025       1 base_controller.go:67] Waiting for caches to sync for MachineDeletionHooksController
2025-11-17T09:30:05.990197095Z I1117 09:30:05.989954       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2025-11-17T09:30:05.990593395Z I1117 09:30:05.990568       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990684       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990703       1 base_controller.go:67] Waiting for caches to sync for PruneController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990713       1 base_controller.go:67] Waiting for caches to sync for NodeController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990793       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_etcd
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990811       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990824       1 base_controller.go:67] Waiting for caches to sync for ClusterMemberController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990836       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990842       1 base_controller.go:67] Waiting for caches to sync for EtcdMembersController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990846       1 base_controller.go:73] Caches are synced for EtcdMembersController 
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990850       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990854       1 base_controller.go:110] Starting #1 XXXXXX of EtcdMembersController controller ...
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990863       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990873       1 base_controller.go:67] Waiting for caches to sync for GuardController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.990886       1 base_controller.go:67] Waiting for caches to sync for BootstrapTeardownController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991022       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991036       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991048       1 base_controller.go:67] Waiting for caches to sync for ScriptController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991059       1 base_controller.go:67] Waiting for caches to sync for DefragController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991069       1 base_controller.go:67] Waiting for caches to sync for ClusterUpgradeBackupController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991877       1 envvarcontroller.go:188] Starting EnvVarController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991900       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991947       1 base_controller.go:67] Waiting for caches to sync for FSyncController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991951       1 base_controller.go:73] Caches are synced for FSyncController 
2025-11-17T09:30:05.993028883Z I1117 09:30:05.991954       1 base_controller.go:110] Starting #1 XXXXXX of FSyncController controller ...
2025-11-17T09:30:05.993028883Z I1117 09:30:05.992499       1 base_controller.go:67] Waiting for caches to sync for EtcdEndpointsController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.992615       1 base_controller.go:67] Waiting for caches to sync for EtcdStaticResources
2025-11-17T09:30:05.993028883Z I1117 09:30:05.992630       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.992640       1 base_controller.go:67] Waiting for caches to sync for EtcdCertSignerController
2025-11-17T09:30:05.993028883Z I1117 09:30:05.992721       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2025-11-17T09:30:06.008665730Z E1117 09:30:06.008622       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.010871588Z E1117 09:30:06.010826       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.016247663Z E1117 09:30:06.016218       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.016338580Z E1117 09:30:06.016315       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.026933251Z E1117 09:30:06.026909       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.029698428Z E1117 09:30:06.029680       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.048176517Z E1117 09:30:06.048143       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.052705824Z E1117 09:30:06.052682       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.089143186Z I1117 09:30:06.089088       1 base_controller.go:73] Caches are synced for ClusterMemberRemovalController 
2025-11-17T09:30:06.089143186Z I1117 09:30:06.089108       1 base_controller.go:110] Starting #1 XXXXXX of ClusterMemberRemovalController controller ...
2025-11-17T09:30:06.089180624Z I1117 09:30:06.089166       1 base_controller.go:73] Caches are synced for MachineDeletionHooksController 
2025-11-17T09:30:06.089186291Z I1117 09:30:06.089178       1 base_controller.go:110] Starting #1 XXXXXX of MachineDeletionHooksController controller ...
2025-11-17T09:30:06.089226864Z E1117 09:30:06.089206       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.090349901Z I1117 09:30:06.090325       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2025-11-17T09:30:06.090382546Z I1117 09:30:06.090375       1 base_controller.go:110] Starting #1 XXXXXX of MissingStaticPodController controller ...
2025-11-17T09:30:06.091414851Z I1117 09:30:06.091394       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2025-11-17T09:30:06.091414851Z I1117 09:30:06.091404       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateController controller ...
2025-11-17T09:30:06.091429445Z I1117 09:30:06.091421       1 base_controller.go:73] Caches are synced for PruneController 
2025-11-17T09:30:06.091429445Z I1117 09:30:06.091424       1 base_controller.go:110] Starting #1 XXXXXX of PruneController controller ...
2025-11-17T09:30:06.091457670Z I1117 09:30:06.091436       1 base_controller.go:73] Caches are synced for ClusterUpgradeBackupController 
2025-11-17T09:30:06.091463119Z I1117 09:30:06.091456       1 base_controller.go:110] Starting #1 XXXXXX of ClusterUpgradeBackupController controller ...
2025-11-17T09:30:06.091528774Z I1117 09:30:06.091515       1 base_controller.go:73] Caches are synced for InstallerController 
2025-11-17T09:30:06.091528774Z I1117 09:30:06.091521       1 base_controller.go:73] Caches are synced for DefragController 
2025-11-17T09:30:06.091545712Z I1117 09:30:06.091535       1 base_controller.go:110] Starting #1 XXXXXX of DefragController controller ...
2025-11-17T09:30:06.091572535Z I1117 09:30:06.091559       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:30:06.091572535Z I1117 09:30:06.091564       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:30:06.091639044Z I1117 09:30:06.091524       1 base_controller.go:110] Starting #1 XXXXXX of InstallerController controller ...
2025-11-17T09:30:06.091665170Z I1117 09:30:06.091655       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:06.091696924Z I1117 09:30:06.091684       1 base_controller.go:73] Caches are synced for BackingResourceController 
2025-11-17T09:30:06.091696924Z I1117 09:30:06.091694       1 base_controller.go:110] Starting #1 XXXXXX of BackingResourceController controller ...
2025-11-17T09:30:06.091717086Z I1117 09:30:06.091710       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:30:06.091721613Z I1117 09:30:06.091716       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:30:06.091834082Z I1117 09:30:06.091818       1 base_controller.go:73] Caches are synced for BootstrapTeardownController 
2025-11-17T09:30:06.091839350Z I1117 09:30:06.091832       1 base_controller.go:110] Starting #1 XXXXXX of BootstrapTeardownController controller ...
2025-11-17T09:30:06.091879833Z I1117 09:30:06.091869       1 base_controller.go:73] Caches are synced for StatusSyncer_etcd 
2025-11-17T09:30:06.091879833Z I1117 09:30:06.091876       1 base_controller.go:110] Starting #1 XXXXXX of StatusSyncer_etcd controller ...
2025-11-17T09:30:06.091921573Z I1117 09:30:06.091911       1 base_controller.go:73] Caches are synced for ClusterMemberController 
2025-11-17T09:30:06.091921573Z I1117 09:30:06.091918       1 base_controller.go:110] Starting #1 XXXXXX of ClusterMemberController controller ...
2025-11-17T09:30:06.091944959Z I1117 09:30:06.091931       1 base_controller.go:73] Caches are synced for RevisionController 
2025-11-17T09:30:06.091944959Z I1117 09:30:06.091942       1 base_controller.go:110] Starting #1 XXXXXX of RevisionController controller ...
2025-11-17T09:30:06.092033849Z E1117 09:30:06.092015       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.092099820Z I1117 09:30:06.091911       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2025-11-17T09:30:06.092105269Z I1117 09:30:06.092097       1 base_controller.go:110] Starting #1 XXXXXX of LoggingSyncer controller ...
2025-11-17T09:30:06.092156403Z E1117 09:30:06.092146       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.092700586Z I1117 09:30:06.092680       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:06.092806206Z I1117 09:30:06.092796       1 base_controller.go:73] Caches are synced for InstallerStateController 
2025-11-17T09:30:06.092811226Z I1117 09:30:06.092804       1 base_controller.go:110] Starting #1 XXXXXX of InstallerStateController controller ...
2025-11-17T09:30:06.097232333Z E1117 09:30:06.097208       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.097455259Z E1117 09:30:06.097438       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.099006120Z E1117 09:30:06.098981       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.107843834Z E1117 09:30:06.107806       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.110906614Z E1117 09:30:06.110845       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.112391816Z I1117 09:30:06.112364       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:06.115354431Z E1117 09:30:06.115200       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.120501143Z I1117 09:30:06.120470       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:06.120620633Z E1117 09:30:06.120605       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.120977055Z E1117 09:30:06.120962       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.121750599Z I1117 09:30:06.121634       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:06.128613008Z E1117 09:30:06.128581       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.128699404Z I1117 09:30:06.128679       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:06.131627372Z E1117 09:30:06.131596       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.140957237Z E1117 09:30:06.140640       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.140993603Z E1117 09:30:06.140978       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.142483384Z E1117 09:30:06.142451       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.143886108Z E1117 09:30:06.143835       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.151618546Z E1117 09:30:06.151575       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.157433120Z E1117 09:30:06.157375       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.169734993Z E1117 09:30:06.169706       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.180725807Z E1117 09:30:06.180700       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.210021563Z E1117 09:30:06.209968       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.212174247Z E1117 09:30:06.212147       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.312365359Z E1117 09:30:06.312314       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.330465693Z E1117 09:30:06.330424       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.344154110Z E1117 09:30:06.344109       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.371589386Z E1117 09:30:06.371559       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.372640703Z E1117 09:30:06.372604       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.651611766Z E1117 09:30:06.651537       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.667611861Z E1117 09:30:06.667571       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:06.691771126Z I1117 09:30:06.691737       1 base_controller.go:73] Caches are synced for ScriptController 
2025-11-17T09:30:06.691771126Z I1117 09:30:06.691754       1 base_controller.go:110] Starting #1 XXXXXX of ScriptController controller ...
2025-11-17T09:30:06.692056496Z E1117 09:30:06.692030       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.692135527Z I1117 09:30:06.692114       1 envvarcontroller.go:194] caches synced
2025-11-17T09:30:06.692816520Z I1117 09:30:06.692772       1 base_controller.go:73] Caches are synced for TargetConfigController 
2025-11-17T09:30:06.692816520Z I1117 09:30:06.692794       1 base_controller.go:110] Starting #1 XXXXXX of TargetConfigController controller ...
2025-11-17T09:30:06.692816520Z E1117 09:30:06.692802       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.693173811Z E1117 09:30:06.693140       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController missing env var values
2025-11-17T09:30:06.702188275Z E1117 09:30:06.702150       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": missing env var values
2025-11-17T09:30:06.702955730Z E1117 09:30:06.702929       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace "openshift-etcd" not found
2025-11-17T09:30:06.703185679Z E1117 09:30:06.703160       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.703200053Z I1117 09:30:06.703160       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:06.703316035Z E1117 09:30:06.703302       1 base_controller.go:268] DefragController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:06.703407802Z I1117 09:30:06.703374       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:06.716552353Z I1117 09:30:06.715556       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:06.953516458Z E1117 09:30:06.953464       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced
2025-11-17T09:30:07.093067752Z I1117 09:30:07.093010       1 base_controller.go:73] Caches are synced for EtcdStaticResources 
2025-11-17T09:30:07.093067752Z I1117 09:30:07.093032       1 base_controller.go:110] Starting #1 XXXXXX of EtcdStaticResources controller ...
2025-11-17T09:30:07.190980552Z I1117 09:30:07.190839       1 request.go:697] Waited for 1.195671161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/nodes?limit=500&resourceVersion=0
2025-11-17T09:30:07.291513717Z I1117 09:30:07.291451       1 base_controller.go:73] Caches are synced for GuardController 
2025-11-17T09:30:07.291513717Z I1117 09:30:07.291478       1 base_controller.go:110] Starting #1 XXXXXX of GuardController controller ...
2025-11-17T09:30:07.291549469Z I1117 09:30:07.291458       1 base_controller.go:73] Caches are synced for NodeController 
2025-11-17T09:30:07.291557409Z I1117 09:30:07.291546       1 base_controller.go:110] Starting #1 XXXXXX of NodeController controller ...
2025-11-17T09:30:07.291695338Z I1117 09:30:07.291680       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:30:07.292605373Z I1117 09:30:07.292578       1 base_controller.go:73] Caches are synced for EtcdEndpointsController 
2025-11-17T09:30:07.292605373Z I1117 09:30:07.292590       1 base_controller.go:110] Starting #1 XXXXXX of EtcdEndpointsController controller ...
2025-11-17T09:30:07.292869019Z I1117 09:30:07.292848       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:30:07.310575153Z E1117 09:30:07.310538       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:07.344242513Z I1117 09:30:07.344174       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:30:07.344737662Z I1117 09:30:07.344706       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:07.344802468Z I1117 09:30:07.344782       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:07.354238481Z I1117 09:30:07.354193       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available"
2025-11-17T09:30:07.358295337Z I1117 09:30:07.357622       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:07.358848833Z I1117 09:30:07.358813       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:07.372557838Z I1117 09:30:07.371658       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: node lister not synced\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found" to "ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:07.376090956Z I1117 09:30:07.376054       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:07.390671282Z I1117 09:30:07.390632       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:30:07.390698203Z I1117 09:30:07.390674       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:07.411814898Z I1117 09:30:07.411763       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:07.412193108Z I1117 09:30:07.412162       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:07.423552896Z I1117 09:30:07.422443       1 defragcontroller.go:294] etcd member "XXXXXX2" backend store fragmented: 0.01 %, dbSize: 53215232
2025-11-17T09:30:07.423552896Z I1117 09:30:07.422461       1 defragcontroller.go:294] etcd member "XXXXXX1" backend store fragmented: 0.02 %, dbSize: 53104640
2025-11-17T09:30:07.424833155Z I1117 09:30:07.424787       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: getting cache client could not retrieve endpoints: node lister not synced\nEtcdMembersDegraded: No unhealthy members found" to "ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:07.495234052Z I1117 09:30:07.495188       1 base_controller.go:73] Caches are synced for ConfigObserver 
2025-11-17T09:30:07.495234052Z I1117 09:30:07.495204       1 base_controller.go:110] Starting #1 XXXXXX of ConfigObserver controller ...
2025-11-17T09:30:07.502870678Z I1117 09:30:07.502844       1 defragcontroller.go:294] etcd member "XXXXXX2" backend store fragmented: 0.02 %, dbSize: 53272576
2025-11-17T09:30:07.502870678Z I1117 09:30:07.502860       1 defragcontroller.go:294] etcd member "XXXXXX1" backend store fragmented: 0.02 %, dbSize: 53149696
2025-11-17T09:30:07.692177274Z I1117 09:30:07.692111       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-11-17T09:30:07.692177274Z I1117 09:30:07.692141       1 base_controller.go:110] Starting #1 XXXXXX of ResourceSyncController controller ...
2025-11-17T09:30:07.693224616Z I1117 09:30:07.693189       1 base_controller.go:73] Caches are synced for EtcdCertSignerController 
2025-11-17T09:30:07.693224616Z I1117 09:30:07.693210       1 base_controller.go:110] Starting #1 XXXXXX of EtcdCertSignerController controller ...
2025-11-17T09:30:08.190959599Z I1117 09:30:08.190903       1 request.go:697] Waited for 2.097955182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:08.593702722Z E1117 09:30:08.593545       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:08.804526019Z I1117 09:30:08.804479       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:08.807832697Z I1117 09:30:08.807784       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:08.821854425Z I1117 09:30:08.821783       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "ScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nNodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2025-11-17T09:30:08.874981561Z I1117 09:30:08.874934       1 defragcontroller.go:294] etcd member "XXXXXX1" backend store fragmented: 0.01 %, dbSize: 53178368
2025-11-17T09:30:09.191394532Z I1117 09:30:09.191345       1 request.go:697] Waited for 1.896859871s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-XXXXXX1
2025-11-17T09:30:10.191616605Z I1117 09:30:10.191411       1 request.go:697] Waited for 1.387630104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2025-11-17T09:30:11.156782819Z E1117 09:30:11.156730       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:11.194116937Z I1117 09:30:11.193973       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:30:11.194116937Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:30:11.194116937Z  CurrentRevision: (int32) 6,
2025-11-17T09:30:11.194116937Z  TargetRevision: (int32) 0,
2025-11-17T09:30:11.194116937Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:11.194116937Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:11.194116937Z  LastFailedReason: (string) "",
2025-11-17T09:30:11.194116937Z  LastFailedCount: (int) 0,
2025-11-17T09:30:11.194116937Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:11.194116937Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:11.194116937Z }
2025-11-17T09:30:11.194116937Z  because static pod is ready
2025-11-17T09:30:11.206072808Z I1117 09:30:11.206020       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 2 to 6 because static pod is ready
2025-11-17T09:30:11.207904721Z I1117 09:30:11.207867       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:11.208557974Z I1117 09:30:11.208505       1 status_controller.go:213] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:20:48Z","message":"NodeInstallerProgressing: 1 nodes are at revision 4; 1 nodes are at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:22:17Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 4; 1 nodes are at revision 6\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:20:19Z","message":"The etcd backup controller is starting, and will decide if recent backups are available or if a backup is required","reason":"ControllerStarted","status":"Unknown","type":"RecentBackup"}]}}
2025-11-17T09:30:11.219603282Z I1117 09:30:11.218962       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 1 nodes are at revision 4; 1 nodes are at revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 4; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 4; 1 nodes are at revision 6\nEtcdMembersAvailable: 2 members are available"
2025-11-17T09:30:11.391447095Z I1117 09:30:11.391356       1 request.go:697] Waited for 1.397580177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2025-11-17T09:30:12.391609458Z I1117 09:30:12.391469       1 request.go:697] Waited for 1.185445042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-XXXXXX2
2025-11-17T09:30:13.591373300Z I1117 09:30:13.591313       1 request.go:697] Waited for 1.396588578s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-XXXXXX2
2025-11-17T09:30:15.590981946Z I1117 09:30:15.590933       1 request.go:697] Waited for 1.160979314s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2025-11-17T09:30:15.793986074Z I1117 09:30:15.793933       1 installer_controller.go:524] node XXXXXX1 with revision 4 is the oldest and needs new revision 6
2025-11-17T09:30:15.793986074Z I1117 09:30:15.793977       1 installer_controller.go:532] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:30:15.793986074Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:30:15.793986074Z  CurrentRevision: (int32) 4,
2025-11-17T09:30:15.793986074Z  TargetRevision: (int32) 6,
2025-11-17T09:30:15.793986074Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:15.793986074Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:15.793986074Z  LastFailedReason: (string) "",
2025-11-17T09:30:15.793986074Z  LastFailedCount: (int) 0,
2025-11-17T09:30:15.793986074Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:15.793986074Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:15.793986074Z }
2025-11-17T09:30:15.805002308Z I1117 09:30:15.804941       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX1" from revision 4 to 6 because node XXXXXX1 with revision 4 is the oldest
2025-11-17T09:30:15.810015425Z I1117 09:30:15.809976       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:15.872886975Z I1117 09:30:15.872758       1 defragcontroller.go:294] etcd member "XXXXXX2" backend store fragmented: 0.06 %, dbSize: 54325248
2025-11-17T09:30:15.872886975Z I1117 09:30:15.872774       1 defragcontroller.go:294] etcd member "XXXXXX1" backend store fragmented: 0.08 %, dbSize: 54214656
2025-11-17T09:30:16.280351662Z E1117 09:30:16.280296       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:16.990911292Z I1117 09:30:16.990624       1 request.go:697] Waited for 1.184756032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2025-11-17T09:30:17.996017497Z I1117 09:30:17.995960       1 request.go:697] Waited for 1.402033404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2025-11-17T09:30:18.200830451Z I1117 09:30:18.200785       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-XXXXXX1 -n openshift-etcd because it was missing
2025-11-17T09:30:19.191302681Z I1117 09:30:19.191241       1 request.go:697] Waited for 1.187069884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2025-11-17T09:30:19.599325081Z I1117 09:30:19.598809       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:30:20.391169016Z I1117 09:30:20.391122       1 request.go:697] Waited for 1.378974759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-XXXXXX1
2025-11-17T09:30:21.391770628Z I1117 09:30:21.391735       1 request.go:697] Waited for 1.197067668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2025-11-17T09:30:21.994520356Z I1117 09:30:21.994472       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:30:22.590762573Z I1117 09:30:22.590710       1 request.go:697] Waited for 1.190709237s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2025-11-17T09:30:23.992955461Z I1117 09:30:23.992919       1 installer_controller.go:512] "XXXXXX1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2025-11-17T09:30:26.524734796Z E1117 09:30:26.524690       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:30:47.013006632Z E1117 09:30:47.012958       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:31:06.009335636Z E1117 09:31:06.007498       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:31:27.981754369Z E1117 09:31:27.981678       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:31:35.992311844Z W1117 09:31:35.992160       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:31:35.992311844Z I1117 09:31:35.992181       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:31:36.092602943Z W1117 09:31:36.092488       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:31:36.092602943Z I1117 09:31:36.092507       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:31:36.092727074Z W1117 09:31:36.092553       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:31:36.092727074Z I1117 09:31:36.092715       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:31:37.296864821Z W1117 09:31:37.296736       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:31:37.296864821Z I1117 09:31:37.296787       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:31:37.992668784Z I1117 09:31:37.992577       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:31:38.093072663Z I1117 09:31:38.092885       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:31:38.093136223Z I1117 09:31:38.093087       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:31:39.297986324Z I1117 09:31:39.297932       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:31:57.925915744Z E1117 09:31:57.925862       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io openshift-cluster-etcd-operator-lock)
2025-11-17T09:32:06.000993188Z E1117 09:32:06.000856       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2025-11-17T09:32:06.095100785Z E1117 09:32:06.095066       1 base_controller.go:268] InstallerStateController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)
2025-11-17T09:32:08.003963990Z W1117 09:32:08.003911       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:08.003963990Z I1117 09:32:08.003936       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:08.103379887Z W1117 09:32:08.103236       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:08.103379887Z I1117 09:32:08.103253       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:08.107976734Z W1117 09:32:08.107764       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:08.107976734Z I1117 09:32:08.107800       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:09.309271017Z W1117 09:32:09.309197       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:09.309271017Z I1117 09:32:09.309222       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:12.004734099Z I1117 09:32:12.004696       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:12.103963938Z I1117 09:32:12.103887       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:12.108645942Z I1117 09:32:12.108617       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:13.310682882Z I1117 09:32:13.310564       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:13.702001763Z E1117 09:32:13.701948       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps etcd-scripts)
2025-11-17T09:32:13.702141532Z I1117 09:32:13.702096       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:32:42.017319732Z W1117 09:32:42.017185       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:42.017319732Z I1117 09:32:42.017216       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:42.118515839Z W1117 09:32:42.118440       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:42.118515839Z I1117 09:32:42.118459       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:42.120535622Z W1117 09:32:42.120510       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:42.120535622Z I1117 09:32:42.120529       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:42.121101670Z E1117 09:32:42.120793       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: error while canRemoveEtcdBootstrap: giving up getting a cached client after 3 tries
2025-11-17T09:32:42.121806139Z I1117 09:32:42.121782       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:43.151637441Z E1117 09:32:43.151442       1 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"etcd-operator.1878c16e5332357c", GenerateName:"", Namespace:"openshift-etcd-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"14c88512-1544-4457-ad99-ad37b830e151", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"ScriptControllerErrorUpdatingStatus", Message:"rpc error: code = DeadlineExceeded desc = context deadline exceeded", Source:v1.EventSource{Component:"openshift-cluster-etcd-operator-script-controller-scriptcontroller", Host:""}, FirstTimestamp:time.Date(2025, time.November, 17, 9, 32, 13, 701911932, time.Local), LastTimestamp:time.Date(2025, time.November, 17, 9, 32, 13, 701911932, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"openshift-cluster-etcd-operator-script-controller-scriptcontroller", ReportingInstance:""}': 'rpc error: code = DeadlineExceeded desc = context deadline exceeded' (will not retry!)
2025-11-17T09:32:43.320713814Z W1117 09:32:43.320672       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2025-11-17T09:32:43.320763510Z I1117 09:32:43.320756       1 etcdcli_pool.go:157] closing cached client
2025-11-17T09:32:44.902390722Z E1117 09:32:44.902326       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": context deadline exceeded
2025-11-17T09:32:44.902476201Z I1117 09:32:44.902461       1 leaderelection.go:285] failed to renew lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock: timed out waiting for the condition
2025-11-17T09:32:49.135037463Z W1117 09:32:49.135006       1 base_controller.go:232] Updating status of "ClusterMemberController" failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2025-11-17T09:32:49.135092433Z E1117 09:32:49.135083       1 base_controller.go:268] ClusterMemberController reconciliation failed: could not get list of unhealthy members: giving up getting a cached client after 3 tries
2025-11-17T09:32:49.135176437Z I1117 09:32:49.135170       1 etcdcli_pool.go:70] creating a new cached client
2025-11-17T09:32:49.462362272Z W1117 09:32:49.461891       1 leaderelection.go:85] leader election lost
