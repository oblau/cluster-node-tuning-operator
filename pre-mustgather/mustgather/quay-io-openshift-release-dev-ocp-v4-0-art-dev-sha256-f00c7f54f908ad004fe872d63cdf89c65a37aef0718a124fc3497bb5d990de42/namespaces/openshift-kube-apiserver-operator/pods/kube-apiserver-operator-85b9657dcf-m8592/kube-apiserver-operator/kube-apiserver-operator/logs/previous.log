2025-11-17T09:27:20.492893027Z I1117 09:27:20.492739       1 cmd.go:233] Using service-serving-cert provided certificates
2025-11-17T09:27:20.492893027Z I1117 09:27:20.492840       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-11-17T09:27:20.493486291Z I1117 09:27:20.493461       1 observer_polling.go:159] Starting file observer
2025-11-17T09:27:20.512947423Z I1117 09:27:20.512884       1 builder.go:271] kube-apiserver-operator version 4.14.0-202511060117.p2.g9267f45.assembly.stream.el8-9267f45-9267f4543589ccb408d3e62fc0e35708d4b783df
2025-11-17T09:27:21.299517409Z I1117 09:27:21.299447       1 secure_serving.go:57] Forcing use of http/1.1 only
2025-11-17T09:27:21.299517409Z W1117 09:27:21.299474       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:21.299517409Z W1117 09:27:21.299481       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2025-11-17T09:27:21.302012081Z I1117 09:27:21.301987       1 leaderelection.go:245] attempting to acquire leader lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock...
2025-11-17T09:27:21.304224663Z I1117 09:27:21.304199       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2025-11-17T09:27:21.304253899Z I1117 09:27:21.304227       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2025-11-17T09:27:21.304337798Z I1117 09:27:21.304318       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-11-17T09:27:21.304337798Z I1117 09:27:21.304335       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:21.304385798Z I1117 09:27:21.304357       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-11-17T09:27:21.304405043Z I1117 09:27:21.304391       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:21.305519466Z I1117 09:27:21.305494       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2025-11-17T09:27:21.306953308Z I1117 09:27:21.306930       1 secure_serving.go:210] Serving securely on [::]:8443
2025-11-17T09:27:21.307006923Z I1117 09:27:21.306993       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2025-11-17T09:27:21.405298304Z I1117 09:27:21.405205       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2025-11-17T09:27:21.406442686Z I1117 09:27:21.406421       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2025-11-17T09:27:21.406523237Z I1117 09:27:21.406493       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2025-11-17T09:30:08.437481031Z I1117 09:30:08.436659       1 leaderelection.go:255] successfully acquired lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock
2025-11-17T09:30:08.437481031Z I1117 09:30:08.436733       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator-lock", UID:"8eb172ae-13fe-4e56-9977-443c028231bb", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"15747", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-apiserver-operator-85b9657dcf-m8592_0af76b72-c23a-4e94-95a0-917a4716047a became leader
2025-11-17T09:30:08.438097816Z I1117 09:30:08.438065       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2025-11-17T09:30:08.441010087Z I1117 09:30:08.440818       1 starter.go:141] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AdmissionWebhookMatchConditions AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BuildCSIVolumes CSIDriverSharedResource CloudDualStackNodeIPs DynamicResourceAllocation EventedPLEG ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP GCPLabelsTags GatewayAPI InsightsConfigAPI MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MaxUnavailableStatefulSet NetworkLiveMigration NodeSwap OpenShiftPodSecurityAdmission PrivateHostedZoneAWS RetroactiveDefaultStorageClass RouteExternalCertificate SigstoreImageVerification VSphereStaticIPs ValidatingAdmissionPolicy]
2025-11-17T09:30:08.442675995Z I1117 09:30:08.442638       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AlibabaPlatform", "AzureWorkloadIdentity", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "PrivateHostedZoneAWS"}, Disabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AdmissionWebhookMatchConditions", "AutomatedEtcdBackup", "CSIDriverSharedResource", "DynamicResourceAllocation", "EventedPLEG", "ExternalCloudProvider", "ExternalCloudProviderGCP", "GCPLabelsTags", "GatewayAPI", "InsightsConfigAPI", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MaxUnavailableStatefulSet", "NetworkLiveMigration", "NodeSwap", "OpenShiftPodSecurityAdmission", "RetroactiveDefaultStorageClass", "RouteExternalCertificate", "SigstoreImageVerification", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}}
2025-11-17T09:30:08.474545404Z I1117 09:30:08.474504       1 base_controller.go:67] Waiting for caches to sync for SCCReconcileController
2025-11-17T09:30:08.474545404Z I1117 09:30:08.474538       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2025-11-17T09:30:08.474872016Z I1117 09:30:08.474564       1 base_controller.go:67] Waiting for caches to sync for ConnectivityCheckController
2025-11-17T09:30:08.475699774Z I1117 09:30:08.475578       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2025-11-17T09:30:08.475825910Z I1117 09:30:08.475804       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2025-11-17T09:30:08.475869372Z I1117 09:30:08.475851       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-11-17T09:30:08.475869372Z I1117 09:30:08.474599       1 base_controller.go:67] Waiting for caches to sync for auditPolicyController
2025-11-17T09:30:08.475894349Z I1117 09:30:08.474618       1 base_controller.go:67] Waiting for caches to sync for webhookSupportabilityController
2025-11-17T09:30:08.475900700Z I1117 09:30:08.474634       1 base_controller.go:67] Waiting for caches to sync for KubeletVersionSkewController
2025-11-17T09:30:08.475919401Z I1117 09:30:08.474637       1 certrotationcontroller.go:682] Starting CertRotation
2025-11-17T09:30:08.475919401Z I1117 09:30:08.475915       1 certrotationcontroller.go:647] Waiting for CertRotation
2025-11-17T09:30:08.475942762Z I1117 09:30:08.474647       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2025-11-17T09:30:08.475972592Z I1117 09:30:08.474677       1 base_controller.go:67] Waiting for caches to sync for EncryptionConditionController
2025-11-17T09:30:08.475976867Z I1117 09:30:08.474688       1 base_controller.go:67] Waiting for caches to sync for FeatureUpgradeableController
2025-11-17T09:30:08.476001257Z I1117 09:30:08.475974       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-apiserver
2025-11-17T09:30:08.476001257Z I1117 09:30:08.474704       1 base_controller.go:67] Waiting for caches to sync for CertRotationTimeUpgradeableController
2025-11-17T09:30:08.476001257Z I1117 09:30:08.474712       1 base_controller.go:67] Waiting for caches to sync for EncryptionMigrationController
2025-11-17T09:30:08.476001257Z I1117 09:30:08.474721       1 base_controller.go:67] Waiting for caches to sync for EncryptionKeyController
2025-11-17T09:30:08.476001257Z I1117 09:30:08.474721       1 base_controller.go:67] Waiting for caches to sync for EncryptionPruneController
2025-11-17T09:30:08.476008527Z I1117 09:30:08.474735       1 base_controller.go:67] Waiting for caches to sync for PodSecurityReadinessController
2025-11-17T09:30:08.476008527Z I1117 09:30:08.474735       1 base_controller.go:67] Waiting for caches to sync for EncryptionStateController
2025-11-17T09:30:08.476008527Z I1117 09:30:08.474746       1 base_controller.go:67] Waiting for caches to sync for ServiceAccountIssuerController
2025-11-17T09:30:08.476014083Z I1117 09:30:08.474756       1 termination_observer.go:145] Starting TerminationObserver
2025-11-17T09:30:08.476014083Z I1117 09:30:08.474765       1 base_controller.go:67] Waiting for caches to sync for highCPUUsageAlertController
2025-11-17T09:30:08.476018762Z I1117 09:30:08.474774       1 base_controller.go:67] Waiting for caches to sync for EventWatchController
2025-11-17T09:30:08.476484651Z I1117 09:30:08.474788       1 base_controller.go:67] Waiting for caches to sync for BoundSATokenSignerController
2025-11-17T09:30:08.476484651Z I1117 09:30:08.476010       1 base_controller.go:67] Waiting for caches to sync for NodeKubeconfigController
2025-11-17T09:30:08.476723514Z I1117 09:30:08.476703       1 base_controller.go:73] Caches are synced for PodSecurityReadinessController 
2025-11-17T09:30:08.476731539Z I1117 09:30:08.476721       1 base_controller.go:110] Starting #1 XXXXXX of PodSecurityReadinessController controller ...
2025-11-17T09:30:08.476752000Z I1117 09:30:08.476736       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateFallback
2025-11-17T09:30:08.476772623Z I1117 09:30:08.476026       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2025-11-17T09:30:08.476772623Z I1117 09:30:08.476710       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2025-11-17T09:30:08.476795705Z I1117 09:30:08.476779       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2025-11-17T09:30:08.476795705Z I1117 09:30:08.476253       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2025-11-17T09:30:08.476814271Z I1117 09:30:08.476738       1 base_controller.go:67] Waiting for caches to sync for KubeAPIServerStaticResources
2025-11-17T09:30:08.476819165Z I1117 09:30:08.476813       1 base_controller.go:67] Waiting for caches to sync for PruneController
2025-11-17T09:30:08.476830974Z I1117 09:30:08.476758       1 base_controller.go:67] Waiting for caches to sync for NodeController
2025-11-17T09:30:08.476847161Z I1117 09:30:08.476234       1 base_controller.go:67] Waiting for caches to sync for StartupMonitorPodCondition
2025-11-17T09:30:08.476857226Z I1117 09:30:08.476801       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2025-11-17T09:30:08.476857226Z I1117 09:30:08.476848       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2025-11-17T09:30:08.476874980Z I1117 09:30:08.476866       1 base_controller.go:67] Waiting for caches to sync for GuardController
2025-11-17T09:30:08.476880599Z I1117 09:30:08.476867       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2025-11-17T09:30:08.476909571Z I1117 09:30:08.476892       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2025-11-17T09:30:08.575717328Z I1117 09:30:08.575655       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2025-11-17T09:30:08.575717328Z I1117 09:30:08.575676       1 base_controller.go:110] Starting #1 XXXXXX of RemoveStaleConditionsController controller ...
2025-11-17T09:30:08.575717328Z I1117 09:30:08.575702       1 base_controller.go:73] Caches are synced for SCCReconcileController 
2025-11-17T09:30:08.575717328Z I1117 09:30:08.575706       1 base_controller.go:110] Starting #1 XXXXXX of SCCReconcileController controller ...
2025-11-17T09:30:08.576449519Z I1117 09:30:08.576420       1 base_controller.go:73] Caches are synced for FeatureUpgradeableController 
2025-11-17T09:30:08.576449519Z I1117 09:30:08.576432       1 base_controller.go:110] Starting #1 XXXXXX of FeatureUpgradeableController controller ...
2025-11-17T09:30:08.576870624Z E1117 09:30:08.576846       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.576878068Z I1117 09:30:08.576873       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2025-11-17T09:30:08.576883344Z I1117 09:30:08.576878       1 base_controller.go:110] Starting #1 XXXXXX of UnsupportedConfigOverridesController controller ...
2025-11-17T09:30:08.576916181Z I1117 09:30:08.576897       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2025-11-17T09:30:08.576916181Z I1117 09:30:08.576903       1 base_controller.go:110] Starting #1 XXXXXX of LoggingSyncer controller ...
2025-11-17T09:30:08.577188965Z I1117 09:30:08.577157       1 base_controller.go:73] Caches are synced for KubeletVersionSkewController 
2025-11-17T09:30:08.577188965Z I1117 09:30:08.577164       1 base_controller.go:110] Starting #1 XXXXXX of KubeletVersionSkewController controller ...
2025-11-17T09:30:08.577786208Z I1117 09:30:08.577735       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 fd03::1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2025-11-17T09:30:08.577786208Z I1117 09:30:08.577782       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX
2025-11-17T09:30:08.577797695Z I1117 09:30:08.577788       1 internalloadbalancer.go:27] syncing internal loadbalancer hostnames: api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX
2025-11-17T09:30:08.577805400Z I1117 09:30:08.577796       1 certrotationcontroller.go:665] Finished waiting for CertRotation
2025-11-17T09:30:08.577849456Z I1117 09:30:08.577830       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.577849456Z I1117 09:30:08.577846       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2025-11-17T09:30:08.577855947Z I1117 09:30:08.577850       1 base_controller.go:110] Starting #1 XXXXXX of WorkerLatencyProfile controller ...
2025-11-17T09:30:08.577872846Z I1117 09:30:08.577868       1 base_controller.go:73] Caches are synced for ServiceAccountIssuerController 
2025-11-17T09:30:08.577880180Z I1117 09:30:08.577872       1 base_controller.go:110] Starting #1 XXXXXX of ServiceAccountIssuerController controller ...
2025-11-17T09:30:08.577930358Z I1117 09:30:08.577910       1 base_controller.go:73] Caches are synced for NodeController 
2025-11-17T09:30:08.577930358Z I1117 09:30:08.577916       1 base_controller.go:110] Starting #1 XXXXXX of NodeController controller ...
2025-11-17T09:30:08.579211309Z I1117 09:30:08.579161       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 fd03::1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2025-11-17T09:30:08.579220523Z I1117 09:30:08.579213       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX
2025-11-17T09:30:08.579235619Z I1117 09:30:08.579226       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579260454Z I1117 09:30:08.579245       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579260454Z I1117 09:30:08.579257       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579294035Z I1117 09:30:08.579278       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579356168Z I1117 09:30:08.579341       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579361185Z I1117 09:30:08.579357       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579376573Z I1117 09:30:08.579367       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579382083Z I1117 09:30:08.579378       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579397596Z I1117 09:30:08.579388       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579401830Z I1117 09:30:08.579399       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579553440Z I1117 09:30:08.579524       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2025-11-17T09:30:08.579559786Z I1117 09:30:08.579550       1 base_controller.go:73] Caches are synced for PruneController 
2025-11-17T09:30:08.579579726Z I1117 09:30:08.579565       1 base_controller.go:110] Starting #1 XXXXXX of PruneController controller ...
2025-11-17T09:30:08.579609871Z I1117 09:30:08.579595       1 base_controller.go:73] Caches are synced for CertRotationTimeUpgradeableController 
2025-11-17T09:30:08.579609871Z I1117 09:30:08.579604       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationTimeUpgradeableController controller ...
2025-11-17T09:30:08.579639898Z I1117 09:30:08.579628       1 base_controller.go:73] Caches are synced for highCPUUsageAlertController 
2025-11-17T09:30:08.579639898Z I1117 09:30:08.579634       1 base_controller.go:110] Starting #1 XXXXXX of highCPUUsageAlertController controller ...
2025-11-17T09:30:08.579659421Z I1117 09:30:08.579647       1 base_controller.go:73] Caches are synced for EventWatchController 
2025-11-17T09:30:08.579659421Z I1117 09:30:08.579653       1 base_controller.go:110] Starting #1 XXXXXX of EventWatchController controller ...
2025-11-17T09:30:08.579964370Z I1117 09:30:08.579942       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:08.582721758Z E1117 09:30:08.582683       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.593610643Z E1117 09:30:08.593412       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.613642658Z E1117 09:30:08.613596       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.653957640Z E1117 09:30:08.653887       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.734859555Z E1117 09:30:08.734761       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.776281112Z I1117 09:30:08.776069       1 base_controller.go:73] Caches are synced for webhookSupportabilityController 
2025-11-17T09:30:08.776281112Z I1117 09:30:08.776094       1 base_controller.go:110] Starting #1 XXXXXX of webhookSupportabilityController controller ...
2025-11-17T09:30:08.876828082Z I1117 09:30:08.876782       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-apiserver 
2025-11-17T09:30:08.876828082Z I1117 09:30:08.876801       1 base_controller.go:110] Starting #1 XXXXXX of StatusSyncer_kube-apiserver controller ...
2025-11-17T09:30:08.896923537Z E1117 09:30:08.896878       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:08.899886275Z W1117 09:30:08.899784       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:09.217542323Z E1117 09:30:09.217485       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:09.276215211Z I1117 09:30:09.276159       1 base_controller.go:73] Caches are synced for auditPolicyController 
2025-11-17T09:30:09.276215211Z I1117 09:30:09.276184       1 base_controller.go:110] Starting #1 XXXXXX of auditPolicyController controller ...
2025-11-17T09:30:09.276617802Z I1117 09:30:09.276592       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "auditPolicyController" resync interval is set to 10s which might lead to client request throttling
2025-11-17T09:30:09.666579720Z I1117 09:30:09.666534       1 request.go:696] Waited for 1.190996882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/secrets?limit=500&resourceVersion=0
2025-11-17T09:30:09.678002614Z I1117 09:30:09.677885       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:09.678002614Z I1117 09:30:09.677905       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:09.857944387Z E1117 09:30:09.857905       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:09.876556641Z I1117 09:30:09.876423       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2025-11-17T09:30:09.876556641Z I1117 09:30:09.876479       1 base_controller.go:110] Starting #1 XXXXXX of MissingStaticPodController controller ...
2025-11-17T09:30:09.877547563Z I1117 09:30:09.877521       1 base_controller.go:73] Caches are synced for GuardController 
2025-11-17T09:30:09.877547563Z I1117 09:30:09.877535       1 base_controller.go:110] Starting #1 XXXXXX of GuardController controller ...
2025-11-17T09:30:09.877556253Z I1117 09:30:09.877544       1 base_controller.go:73] Caches are synced for StartupMonitorPodCondition 
2025-11-17T09:30:09.877562138Z I1117 09:30:09.877557       1 base_controller.go:110] Starting #1 XXXXXX of StartupMonitorPodCondition controller ...
2025-11-17T09:30:09.877643413Z I1117 09:30:09.877615       1 base_controller.go:73] Caches are synced for InstallerController 
2025-11-17T09:30:09.877643413Z I1117 09:30:09.877637       1 base_controller.go:110] Starting #1 XXXXXX of InstallerController controller ...
2025-11-17T09:30:09.877675500Z I1117 09:30:09.877518       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2025-11-17T09:30:09.877680295Z I1117 09:30:09.877673       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateController controller ...
2025-11-17T09:30:09.877685707Z I1117 09:30:09.877671       1 base_controller.go:73] Caches are synced for StaticPodStateFallback 
2025-11-17T09:30:09.877705452Z I1117 09:30:09.877689       1 base_controller.go:110] Starting #1 XXXXXX of StaticPodStateFallback controller ...
2025-11-17T09:30:09.877981665Z I1117 09:30:09.877964       1 base_controller.go:73] Caches are synced for InstallerStateController 
2025-11-17T09:30:09.877981665Z I1117 09:30:09.877975       1 base_controller.go:110] Starting #1 XXXXXX of InstallerStateController controller ...
2025-11-17T09:30:09.878275687Z I1117 09:30:09.878236       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:09.892191741Z I1117 09:30:09.892167       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:09.893149685Z E1117 09:30:09.893129       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:09.893257702Z I1117 09:30:09.893223       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:22:28Z","message":"GuardControllerDegraded: Missing operand on node XXXXXX2\nInstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:09.893660118Z I1117 09:30:09.893637       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:09.893818062Z E1117 09:30:09.893799       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:09.899152631Z I1117 09:30:09.899103       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:09.899311456Z E1117 09:30:09.899280       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:09.904929497Z I1117 09:30:09.901676       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node XXXXXX2" to "GuardControllerDegraded: Missing operand on node XXXXXX2\nInstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]"
2025-11-17T09:30:09.906247585Z W1117 09:30:09.906044       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:09.920367527Z I1117 09:30:09.920315       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:09.920514434Z E1117 09:30:09.920478       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:09.961858386Z I1117 09:30:09.961823       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:09.961923375Z E1117 09:30:09.961905       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:10.044016096Z E1117 09:30:10.043915       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]
2025-11-17T09:30:10.044016096Z I1117 09:30:10.043941       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3
2025-11-17T09:30:10.076840372Z I1117 09:30:10.076735       1 base_controller.go:73] Caches are synced for NodeKubeconfigController 
2025-11-17T09:30:10.076840372Z I1117 09:30:10.076773       1 base_controller.go:110] Starting #1 XXXXXX of NodeKubeconfigController controller ...
2025-11-17T09:30:10.076946947Z I1117 09:30:10.076899       1 base_controller.go:73] Caches are synced for BoundSATokenSignerController 
2025-11-17T09:30:10.076946947Z I1117 09:30:10.076932       1 base_controller.go:110] Starting #1 XXXXXX of BoundSATokenSignerController controller ...
2025-11-17T09:30:10.077085935Z I1117 09:30:10.077008       1 base_controller.go:73] Caches are synced for RevisionController 
2025-11-17T09:30:10.077085935Z I1117 09:30:10.077051       1 base_controller.go:110] Starting #1 XXXXXX of RevisionController controller ...
2025-11-17T09:30:10.079058365Z I1117 09:30:10.078956       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required secret/localhost-recovery-client-token has changed"
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080246       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080260       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080261       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080270       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080277       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080291       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080301       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080310       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080323       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080326       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080331       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080335       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080336       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080340       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082118216Z I1117 09:30:10.080277       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082118216Z I1117 09:30:10.081944       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.082422131Z I1117 09:30:10.082394       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.082422131Z I1117 09:30:10.082408       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.276988951Z I1117 09:30:10.276910       1 base_controller.go:73] Caches are synced for ConfigObserver 
2025-11-17T09:30:10.276988951Z I1117 09:30:10.276926       1 base_controller.go:110] Starting #1 XXXXXX of ConfigObserver controller ...
2025-11-17T09:30:10.277524407Z I1117 09:30:10.277475       1 base_controller.go:73] Caches are synced for EncryptionConditionController 
2025-11-17T09:30:10.277524407Z I1117 09:30:10.277506       1 base_controller.go:110] Starting #1 XXXXXX of EncryptionConditionController controller ...
2025-11-17T09:30:10.277524407Z I1117 09:30:10.277508       1 base_controller.go:73] Caches are synced for EncryptionKeyController 
2025-11-17T09:30:10.277536741Z I1117 09:30:10.277521       1 base_controller.go:110] Starting #1 XXXXXX of EncryptionKeyController controller ...
2025-11-17T09:30:10.277552121Z I1117 09:30:10.277541       1 base_controller.go:73] Caches are synced for EncryptionStateController 
2025-11-17T09:30:10.277552121Z I1117 09:30:10.277549       1 base_controller.go:110] Starting #1 XXXXXX of EncryptionStateController controller ...
2025-11-17T09:30:10.277589153Z I1117 09:30:10.277571       1 base_controller.go:73] Caches are synced for EncryptionPruneController 
2025-11-17T09:30:10.277589153Z I1117 09:30:10.277581       1 base_controller.go:110] Starting #1 XXXXXX of EncryptionPruneController controller ...
2025-11-17T09:30:10.277665822Z I1117 09:30:10.277648       1 base_controller.go:73] Caches are synced for EncryptionMigrationController 
2025-11-17T09:30:10.277705471Z I1117 09:30:10.277681       1 base_controller.go:110] Starting #1 XXXXXX of EncryptionMigrationController controller ...
2025-11-17T09:30:10.279848028Z I1117 09:30:10.279817       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.279848028Z I1117 09:30:10.279833       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.279848028Z I1117 09:30:10.279840       1 base_controller.go:73] Caches are synced for CertRotationController 
2025-11-17T09:30:10.279865399Z I1117 09:30:10.279851       1 base_controller.go:110] Starting #1 XXXXXX of CertRotationController controller ...
2025-11-17T09:30:10.667011448Z I1117 09:30:10.666957       1 request.go:696] Waited for 2.191105232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/endpoints?limit=500&resourceVersion=0
2025-11-17T09:30:10.875749371Z I1117 09:30:10.875691       1 base_controller.go:73] Caches are synced for TargetConfigController 
2025-11-17T09:30:10.875749371Z I1117 09:30:10.875711       1 base_controller.go:110] Starting #1 XXXXXX of TargetConfigController controller ...
2025-11-17T09:30:10.876876376Z I1117 09:30:10.876853       1 base_controller.go:73] Caches are synced for KubeAPIServerStaticResources 
2025-11-17T09:30:10.876876376Z I1117 09:30:10.876870       1 base_controller.go:110] Starting #1 XXXXXX of KubeAPIServerStaticResources controller ...
2025-11-17T09:30:10.876947837Z I1117 09:30:10.876929       1 base_controller.go:73] Caches are synced for BackingResourceController 
2025-11-17T09:30:10.876973667Z I1117 09:30:10.876966       1 base_controller.go:110] Starting #1 XXXXXX of BackingResourceController controller ...
2025-11-17T09:30:11.076128183Z I1117 09:30:11.076069       1 base_controller.go:73] Caches are synced for ConnectivityCheckController 
2025-11-17T09:30:11.076128183Z I1117 09:30:11.076090       1 base_controller.go:110] Starting #1 XXXXXX of ConnectivityCheckController controller ...
2025-11-17T09:30:11.076526246Z I1117 09:30:11.076483       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:11.138509173Z E1117 09:30:11.138446       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:11.476863612Z I1117 09:30:11.476665       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-11-17T09:30:11.476863612Z I1117 09:30:11.476705       1 base_controller.go:110] Starting #1 XXXXXX of ResourceSyncController controller ...
2025-11-17T09:30:11.668305633Z I1117 09:30:11.668120       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:11.866727386Z I1117 09:30:11.866633       1 request.go:696] Waited for 1.988964001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2025-11-17T09:30:11.911750582Z W1117 09:30:11.911702       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:12.873264005Z I1117 09:30:12.872910       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:12.915417995Z W1117 09:30:12.915373       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:13.065908119Z I1117 09:30:13.065839       1 request.go:696] Waited for 2.860304541s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:13.699324935Z E1117 09:30:13.698970       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:13.872604573Z I1117 09:30:13.872544       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-kube-apiserver:
2025-11-17T09:30:13.872604573Z cause by changes in data.service-account-002.pub
2025-11-17T09:30:14.266009261Z I1117 09:30:14.265971       1 request.go:696] Waited for 2.196240922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:14.672193322Z I1117 09:30:14.672109       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:14.941991479Z I1117 09:30:14.939593       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:14.941991479Z I1117 09:30:14.939766       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:15.266539841Z I1117 09:30:15.266489       1 request.go:696] Waited for 1.996845968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2025-11-17T09:30:16.272190306Z I1117 09:30:16.272099       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:16.465699921Z I1117 09:30:16.465661       1 request.go:696] Waited for 1.590080925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2025-11-17T09:30:17.465849950Z I1117 09:30:17.465804       1 request.go:696] Waited for 1.795952729s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2025-11-17T09:30:17.735984691Z I1117 09:30:17.735783       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:17.738839432Z I1117 09:30:17.738804       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:18.072731081Z I1117 09:30:18.072689       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:18.469429799Z I1117 09:30:18.469365       1 request.go:696] Waited for 1.601373307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-3-XXXXXX2
2025-11-17T09:30:18.820131918Z E1117 09:30:18.819906       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:19.477914309Z I1117 09:30:19.477868       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-XXXXXX2 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:19.516951300Z I1117 09:30:19.516895       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:19.518277411Z I1117 09:30:19.518240       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"InstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:19.518998677Z I1117 09:30:19.518978       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:19.534270991Z I1117 09:30:19.532124       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("InstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]\nNodeControllerDegraded: All XXXXXX nodes are ready")
2025-11-17T09:30:19.671716851Z I1117 09:30:19.665641       1 request.go:696] Waited for 1.593088736s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2025-11-17T09:30:19.684912735Z I1117 09:30:19.683316       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:20.070159720Z I1117 09:30:20.070114       1 installer_controller.go:500] "XXXXXX2" moving to (v1.NodeStatus) {
2025-11-17T09:30:20.070159720Z  NodeName: (string) (len=7) "XXXXXX2",
2025-11-17T09:30:20.070159720Z  CurrentRevision: (int32) 3,
2025-11-17T09:30:20.070159720Z  TargetRevision: (int32) 0,
2025-11-17T09:30:20.070159720Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:20.070159720Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:20.070159720Z  LastFailedReason: (string) "",
2025-11-17T09:30:20.070159720Z  LastFailedCount: (int) 0,
2025-11-17T09:30:20.070159720Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:20.070159720Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:20.070159720Z }
2025-11-17T09:30:20.070159720Z  because static pod is ready
2025-11-17T09:30:20.084929042Z I1117 09:30:20.084885       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:20.086264350Z I1117 09:30:20.086231       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"InstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:20.092015270Z I1117 09:30:20.087809       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:20.092015270Z I1117 09:30:20.089208       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "XXXXXX2" from revision 0 to 3 because static pod is ready
2025-11-17T09:30:20.098466535Z I1117 09:30:20.098424       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3",Available message changed from "StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 0; 1 nodes are at revision 2; 0 nodes have achieved new revision 3" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3"
2025-11-17T09:30:20.103554358Z I1117 09:30:20.103514       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:20.104037400Z I1117 09:30:20.104004       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:20.107859192Z I1117 09:30:20.107809       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:20.112266230Z I1117 09:30:20.111714       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, secrets: etcd-client-3,localhost-recovery-client-token-3,localhost-recovery-serving-certkey-3]\nNodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:30:20.866174141Z I1117 09:30:20.866030       1 request.go:696] Waited for 1.598306747s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:21.866616048Z I1117 09:30:21.866564       1 request.go:696] Waited for 2.183455968s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2025-11-17T09:30:21.876928451Z I1117 09:30:21.876867       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:23.066180836Z I1117 09:30:23.066029       1 request.go:696] Waited for 2.196253396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:24.066573248Z I1117 09:30:24.066526       1 request.go:696] Waited for 2.191350525s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2025-11-17T09:30:24.071919261Z I1117 09:30:24.071889       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:25.265702508Z I1117 09:30:25.265642       1 request.go:696] Waited for 2.196762007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:25.437322353Z I1117 09:30:25.436177       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:25.437322353Z I1117 09:30:25.436513       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:26.072605665Z I1117 09:30:26.072542       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:26.266269350Z I1117 09:30:26.266218       1 request.go:696] Waited for 1.992773405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2025-11-17T09:30:27.465859946Z I1117 09:30:27.465808       1 request.go:696] Waited for 1.992658396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2025-11-17T09:30:28.072516004Z I1117 09:30:28.072451       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:28.666059055Z I1117 09:30:28.666006       1 request.go:696] Waited for 1.976159052s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2025-11-17T09:30:29.061326594Z E1117 09:30:29.060652       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:29.481744851Z I1117 09:30:29.481691       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-XXXXXX2 -n openshift-kube-apiserver because it changed
2025-11-17T09:30:29.666405343Z I1117 09:30:29.666112       1 request.go:696] Waited for 1.593641746s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2025-11-17T09:30:29.676977561Z I1117 09:30:29.674530       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:30.668447682Z I1117 09:30:30.668389       1 request.go:696] Waited for 1.599297816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2025-11-17T09:30:31.674235073Z I1117 09:30:31.674170       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:31.866866264Z I1117 09:30:31.866752       1 request.go:696] Waited for 2.081812043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2025-11-17T09:30:32.268790178Z I1117 09:30:32.268740       1 installer_controller.go:524] node XXXXXX1 with revision 2 is the oldest and needs new revision 3
2025-11-17T09:30:32.268834523Z I1117 09:30:32.268787       1 installer_controller.go:532] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:30:32.268834523Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:30:32.268834523Z  CurrentRevision: (int32) 2,
2025-11-17T09:30:32.268834523Z  TargetRevision: (int32) 3,
2025-11-17T09:30:32.268834523Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:32.268834523Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:32.268834523Z  LastFailedReason: (string) "",
2025-11-17T09:30:32.268834523Z  LastFailedCount: (int) 0,
2025-11-17T09:30:32.268834523Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:32.268834523Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:32.268834523Z }
2025-11-17T09:30:32.283474859Z I1117 09:30:32.283411       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "XXXXXX1" from revision 2 to 3 because node XXXXXX1 with revision 2 is the oldest
2025-11-17T09:30:32.285716883Z I1117 09:30:32.285675       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:32.286191217Z I1117 09:30:32.286154       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:33.065884078Z I1117 09:30:33.065823       1 request.go:696] Waited for 1.996878792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:33.916829397Z W1117 09:30:33.915656       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:34.066142169Z I1117 09:30:34.066090       1 request.go:696] Waited for 1.782221937s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:34.917789753Z W1117 09:30:34.917746       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:35.265956853Z I1117 09:30:35.265905       1 request.go:696] Waited for 1.794353058s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2025-11-17T09:30:35.271062646Z I1117 09:30:35.270993       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:36.465835829Z I1117 09:30:36.465787       1 request.go:696] Waited for 1.596930041s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:36.871837044Z I1117 09:30:36.871784       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:36.930773904Z W1117 09:30:36.929624       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:37.466296514Z I1117 09:30:37.466231       1 request.go:696] Waited for 1.596254186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-3-XXXXXX1
2025-11-17T09:30:37.933026991Z W1117 09:30:37.932959       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:38.072679185Z I1117 09:30:38.072628       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-4 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:38.085317557Z I1117 09:30:38.085248       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 3 created because required secret/localhost-recovery-client-token has changed
2025-11-17T09:30:38.088091840Z I1117 09:30:38.088069       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:38.089070363Z I1117 09:30:38.089040       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required secret/localhost-recovery-client-token has changed,required configmap/sa-token-signing-certs has changed"
2025-11-17T09:30:38.092454398Z I1117 09:30:38.092405       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:38.472374835Z I1117 09:30:38.471344       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-XXXXXX1 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:39.266189227Z I1117 09:30:39.266087       1 request.go:696] Waited for 1.177686724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:39.470603431Z I1117 09:30:39.470550       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/revision-status-4 -n openshift-kube-apiserver:
2025-11-17T09:30:39.470603431Z cause by changes in data.reason
2025-11-17T09:30:40.048877840Z W1117 09:30:40.048837       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:40.266469080Z I1117 09:30:40.266431       1 request.go:696] Waited for 1.795285338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-3-XXXXXX1
2025-11-17T09:30:40.268730808Z I1117 09:30:40.268685       1 installer_controller.go:512] "XXXXXX1" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2025-11-17T09:30:40.283018421Z I1117 09:30:40.282950       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:40.283447766Z I1117 09:30:40.283416       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:40.284806314Z I1117 09:30:40.284769       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:40.297364399Z I1117 09:30:40.296552       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3" to "NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4"
2025-11-17T09:30:41.051718758Z W1117 09:30:41.051638       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.225.112:9443: connect: connection refused
2025-11-17T09:30:41.266615229Z I1117 09:30:41.266554       1 request.go:696] Waited for 1.998077187s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX2
2025-11-17T09:30:41.471680663Z W1117 09:30:41.471628       1 staticpod.go:38] revision 4 is unexpectedly already the XXXXXX available revision. This is a possible race!
2025-11-17T09:30:41.483856460Z E1117 09:30:41.483806       1 base_controller.go:268] RevisionController reconciliation failed: conflicting XXXXXXAvailableRevision 4
2025-11-17T09:30:41.485358968Z I1117 09:30:41.485303       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:41.486199944Z I1117 09:30:41.486152       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:41.486437130Z I1117 09:30:41.486395       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 4\nNodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:41.496819740Z I1117 09:30:41.496757       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All XXXXXX nodes are ready" to "RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 4\nNodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:30:41.505884949Z I1117 09:30:41.505825       1 status_controller.go:215] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2025-11-17T09:30:19Z","message":"NodeControllerDegraded: All XXXXXX nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2025-11-17T09:22:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-17T09:24:05Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 2; 1 nodes are at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2025-11-17T09:20:27Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2025-11-17T09:22:42Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2025-11-17T09:30:41.506537365Z I1117 09:30:41.506057       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:41.507896135Z I1117 09:30:41.507394       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:41.516430479Z I1117 09:30:41.515718       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "RevisionControllerDegraded: conflicting XXXXXXAvailableRevision 4\nNodeControllerDegraded: All XXXXXX nodes are ready" to "NodeControllerDegraded: All XXXXXX nodes are ready"
2025-11-17T09:30:42.466471869Z I1117 09:30:42.466418       1 request.go:696] Waited for 2.18233906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2025-11-17T09:30:43.055575802Z W1117 09:30:43.055528       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:43.413567315Z I1117 09:30:43.413518       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:43.466466003Z I1117 09:30:43.466421       1 request.go:696] Waited for 2.193683783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:44.058366495Z W1117 09:30:44.058314       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.168.164:8443: connect: connection refused
2025-11-17T09:30:44.665905436Z I1117 09:30:44.665856       1 request.go:696] Waited for 1.995968675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:45.665932151Z I1117 09:30:45.665891       1 request.go:696] Waited for 1.59647767s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-XXXXXX1
2025-11-17T09:30:46.872800522Z I1117 09:30:46.872739       1 installer_controller.go:500] "XXXXXX1" moving to (v1.NodeStatus) {
2025-11-17T09:30:46.872800522Z  NodeName: (string) (len=7) "XXXXXX1",
2025-11-17T09:30:46.872800522Z  CurrentRevision: (int32) 2,
2025-11-17T09:30:46.872800522Z  TargetRevision: (int32) 4,
2025-11-17T09:30:46.872800522Z  LastFailedRevision: (int32) 0,
2025-11-17T09:30:46.872800522Z  LastFailedTime: (*v1.Time)(<nil>),
2025-11-17T09:30:46.872800522Z  LastFailedReason: (string) "",
2025-11-17T09:30:46.872800522Z  LastFailedCount: (int) 0,
2025-11-17T09:30:46.872800522Z  LastFallbackCount: (int) 0,
2025-11-17T09:30:46.872800522Z  LastFailedRevisionErrors: ([]string) <nil>
2025-11-17T09:30:46.872800522Z }
2025-11-17T09:30:46.872800522Z  because new revision pending
2025-11-17T09:30:46.887112844Z I1117 09:30:46.887067       1 prune_controller.go:269] Nothing to prune
2025-11-17T09:30:46.891267884Z I1117 09:30:46.891232       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.14.59) to be completed.
2025-11-17T09:30:48.066027879Z I1117 09:30:48.065965       1 request.go:696] Waited for 1.194014417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2025-11-17T09:30:49.268350953Z I1117 09:30:49.267415       1 request.go:696] Waited for 1.999438934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2025-11-17T09:30:49.541631707Z E1117 09:30:49.541428       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:30:50.466216681Z I1117 09:30:50.466008       1 request.go:696] Waited for 1.183200273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2025-11-17T09:30:51.665942736Z I1117 09:30:51.665821       1 request.go:696] Waited for 1.591188719s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2025-11-17T09:30:52.666466313Z I1117 09:30:52.666405       1 request.go:696] Waited for 1.198492353s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2025-11-17T09:30:52.674609571Z I1117 09:30:52.674560       1 event.go:298] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"afd91980-c903-4d2a-bb1b-0cca1c941837", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-XXXXXX1 -n openshift-kube-apiserver because it was missing
2025-11-17T09:30:53.865597348Z I1117 09:30:53.865549       1 request.go:696] Waited for 1.190584731s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-XXXXXX1
2025-11-17T09:30:57.115504359Z W1117 09:30:57.110485       1 reflector.go:456] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: watch of *v1.Event ended with: Internal error occurred: etcdserver: no leader
2025-11-17T09:31:30.502249127Z E1117 09:31:30.502193       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:31:53.267648019Z E1117 09:31:53.267578       1 guard_controller.go:339] Unable to apply pod kube-apiserver-guard-XXXXXX1 changes: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-apiserver-guard-XXXXXX1)
2025-11-17T09:31:53.668709900Z E1117 09:31:53.668657       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)
2025-11-17T09:31:54.068360860Z E1117 09:31:54.068236       1 base_controller.go:268] InstallerStateController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)
2025-11-17T09:31:58.659408650Z W1117 09:31:58.659340       1 reflector.go:533] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Event: the server was unable to return a response in the time allotted, but may still be processing the request (get events)
2025-11-17T09:31:58.659461099Z I1117 09:31:58.659416       1 trace.go:236] Trace[1364658899]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (17-Nov-2025 09:30:58.655) (total time: 60004ms):
2025-11-17T09:31:58.659461099Z Trace[1364658899]: ---"Objects listed" error:the server was unable to return a response in the time allotted, but may still be processing the request (get events) 60004ms (09:31:58.659)
2025-11-17T09:31:58.659461099Z Trace[1364658899]: [1m0.004179747s] [1m0.004179747s] END
2025-11-17T09:31:58.659461099Z E1117 09:31:58.659439       1 reflector.go:148] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Event: failed to list *v1.Event: the server was unable to return a response in the time allotted, but may still be processing the request (get events)
2025-11-17T09:32:00.457137725Z E1117 09:32:00.457056       1 leaderelection.go:327] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io kube-apiserver-operator-lock)
2025-11-17T09:32:00.477839848Z E1117 09:32:00.477756       1 base_controller.go:268] InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-4-XXXXXX1)
2025-11-17T09:32:06.297182470Z E1117 09:32:06.297133       1 base_controller.go:268] auditPolicyController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-audit-policies)
2025-11-17T09:32:47.456660918Z E1117 09:32:47.456559       1 leaderelection.go:327] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": context deadline exceeded
2025-11-17T09:32:47.456660918Z I1117 09:32:47.456620       1 leaderelection.go:280] failed to renew lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock: timed out waiting for the condition
2025-11-17T09:32:52.031367463Z I1117 09:32:52.028824       1 trace.go:236] Trace[913176705]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (17-Nov-2025 09:32:00.722) (total time: 51306ms):
2025-11-17T09:32:52.031367463Z Trace[913176705]: ---"Objects listed" error:<nil> 51306ms (09:32:52.028)
2025-11-17T09:32:52.031367463Z Trace[913176705]: [51.306575996s] [51.306575996s] END
2025-11-17T09:32:52.102316133Z W1117 09:32:52.101332       1 reflector.go:533] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.102316133Z E1117 09:32:52.101380       1 reflector.go:148] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=18961": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.117315230Z W1117 09:32:52.116950       1 reflector.go:533] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.RoleBinding: Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings?resourceVersion=18963": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.117315230Z E1117 09:32:52.116989       1 reflector.go:148] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.RoleBinding: failed to list *v1.RoleBinding: Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings?resourceVersion=18963": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.182315947Z W1117 09:32:52.181342       1 reflector.go:533] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets?resourceVersion=18921": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.186312296Z E1117 09:32:52.182346       1 reflector.go:148] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets?resourceVersion=18921": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.379119018Z W1117 09:32:52.379068       1 reflector.go:533] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/secrets?resourceVersion=18921": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.379119018Z E1117 09:32:52.379110       1 reflector.go:148] k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/secrets?resourceVersion=18921": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.422591960Z E1117 09:32:52.422488       1 base_controller.go:268] SCCReconcileController reconciliation failed: securitycontextconstraints.security.openshift.io "key" not found
2025-11-17T09:32:52.458489319Z E1117 09:32:52.458382       1 leaderelection.go:303] Failed to release lock: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2025-11-17T09:32:52.458507577Z W1117 09:32:52.458493       1 leaderelection.go:85] leader election lost
