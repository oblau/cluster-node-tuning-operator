---
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 8d2315b8bdc08e25c668c03cc16332de
      kubernetes.io/config.mirror: 8d2315b8bdc08e25c668c03cc16332de
      kubernetes.io/config.seen: "2025-11-17T09:32:19.678125802Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:33:54Z"
    labels:
      app: kni-infra-coredns
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"bc15ced4-edf1-4c10-8cd9-fecd74736a61"}: {}
        f:spec:
          f:containers:
            k:{"name":"coredns"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
            k:{"name":"coredns-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-coredns"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nm-resolv"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:54Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::20"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: coredns-XXXXXX0
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX0
      uid: bc15ced4-edf1-4c10-8cd9-fecd74736a61
    resourceVersion: "22233"
    uid: 6dfdd8b2-3446-4898-ac38-f504ca2d6f31
  spec:
    containers:
    - args:
      - --conf
      - /etc/coredns/Corefile
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 18080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - corednsmonitor
      - /var/lib/kubelet/kubeconfig
      - /config/Corefile.tmpl
      - /etc/coredns/Corefile
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: coredns-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /var/lib/kubelet/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/coredns
      - --resolvconf-path
      - /var/run/NetworkManager/resolv.conf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-coredns
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/coredns
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfig
    - hostPath:
        path: /etc/coredns
        type: ""
      name: conf-dir
    - hostPath:
        path: /var/run/NetworkManager
        type: ""
      name: nm-resolv
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0aa069fba91a9073d28a773dceb4db95bb54beb05c69e5e1229c7e0ede05beda
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    - containerID: cri-o://9e82ba223bf7b9f1c626d470b0f452d106d93de63edf671a954078b81ee4554a
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: coredns-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://5f7c19552179b2bf3dd2d4bf65ca681020f4b7e2cc8a70b0a19fe6d2d894ef54
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-coredns
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://5f7c19552179b2bf3dd2d4bf65ca681020f4b7e2cc8a70b0a19fe6d2d894ef54
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::20
    qosClass: Burstable
    startTime: "2025-11-17T09:32:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 998e92cee023a8200c9275e075e5894f
      kubernetes.io/config.mirror: 998e92cee023a8200c9275e075e5894f
      kubernetes.io/config.seen: "2025-11-17T09:08:22.886498487Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:09:35Z"
    labels:
      app: kni-infra-coredns
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"08d8653a-e1d4-4358-b485-d849df97cbd8"}: {}
        f:spec:
          f:containers:
            k:{"name":"coredns"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
            k:{"name":"coredns-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-coredns"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nm-resolv"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:09:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::21"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:09:42Z"
    name: coredns-XXXXXX1
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX1
      uid: 08d8653a-e1d4-4358-b485-d849df97cbd8
    resourceVersion: "3132"
    uid: 6c552d5a-848b-4110-871c-e6b8924c79df
  spec:
    containers:
    - args:
      - --conf
      - /etc/coredns/Corefile
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 18080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - corednsmonitor
      - /var/lib/kubelet/kubeconfig
      - /config/Corefile.tmpl
      - /etc/coredns/Corefile
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: coredns-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /var/lib/kubelet/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/coredns
      - --resolvconf-path
      - /var/run/NetworkManager/resolv.conf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-coredns
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/coredns
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfig
    - hostPath:
        path: /etc/coredns
        type: ""
      name: conf-dir
    - hostPath:
        path: /var/run/NetworkManager
        type: ""
      name: nm-resolv
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:25Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://09d43f34a61fea8720af9b8888c193e6e752e44f891a0059e2e91e8f0c5076dc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:31Z"
    - containerID: cri-o://da7fe55679f97139583f7a5b25b8732d9740a909fdebb9e360a1dfb3aecf53c1
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: coredns-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:31Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://c20a95c1c1016ed05ca9d93a0f83f946ed239e4d55d92208c334320a02d86c2c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-coredns
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://c20a95c1c1016ed05ca9d93a0f83f946ed239e4d55d92208c334320a02d86c2c
          exitCode: 0
          finishedAt: "2025-11-17T09:08:25Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:25Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::21
    qosClass: Burstable
    startTime: "2025-11-17T09:08:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 4d1b725121721eea6ec69f884618baab
      kubernetes.io/config.mirror: 4d1b725121721eea6ec69f884618baab
      kubernetes.io/config.seen: "2025-11-17T09:08:25.052079650Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:09:42Z"
    labels:
      app: kni-infra-coredns
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"9bbf3978-9a24-4194-97bd-19975c5a4042"}: {}
        f:spec:
          f:containers:
            k:{"name":"coredns"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
            k:{"name":"coredns-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-coredns"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nm-resolv"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:09:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::22"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:09:45Z"
    name: coredns-XXXXXX2
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX2
      uid: 9bbf3978-9a24-4194-97bd-19975c5a4042
    resourceVersion: "3135"
    uid: dbe17cc1-a350-4f01-9564-3de8e4b49a5c
  spec:
    containers:
    - args:
      - --conf
      - /etc/coredns/Corefile
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 18080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - corednsmonitor
      - /var/lib/kubelet/kubeconfig
      - /config/Corefile.tmpl
      - /etc/coredns/Corefile
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: coredns-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /var/lib/kubelet/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/coredns
      - --resolvconf-path
      - /var/run/NetworkManager/resolv.conf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-coredns
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX2
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/coredns
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfig
    - hostPath:
        path: /etc/coredns
        type: ""
      name: conf-dir
    - hostPath:
        path: /var/run/NetworkManager
        type: ""
      name: nm-resolv
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:28Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://608b40d4f2a63bc6a2e2b03155224584280f39f2589dd8dc78f5d5574c595070
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:33Z"
    - containerID: cri-o://9a74c28cc32fadb2119818c5ec24b41cccf245b7a07f6969d5a9883fe6cc8cbe
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: coredns-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:33Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://148155b10c83f9f99eaec5b926de1ff198085f669540e4a6a5b1dbc2f2454576
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-coredns
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://148155b10c83f9f99eaec5b926de1ff198085f669540e4a6a5b1dbc2f2454576
          exitCode: 0
          finishedAt: "2025-11-17T09:08:27Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:27Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::22
    qosClass: Burstable
    startTime: "2025-11-17T09:08:25Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 25dcfaf4e9dc34b96bf6da885ba1ecde
      kubernetes.io/config.mirror: 25dcfaf4e9dc34b96bf6da885ba1ecde
      kubernetes.io/config.seen: "2025-11-17T09:32:19.875283546Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:36:36Z"
    labels:
      app: kni-infra-coredns
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"be542f6b-71a2-46af-9c87-f2120b48ad2f"}: {}
        f:spec:
          f:containers:
            k:{"name":"coredns"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
            k:{"name":"coredns-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-coredns"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nm-resolv"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:36Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::2"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: coredns-XXXXXX0
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX0
      uid: be542f6b-71a2-46af-9c87-f2120b48ad2f
    resourceVersion: "22242"
    uid: 0ff6586e-e382-4c6f-a5c5-fa5d519dd3b0
  spec:
    containers:
    - args:
      - --conf
      - /etc/coredns/Corefile
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 18080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - corednsmonitor
      - /var/lib/kubelet/kubeconfig
      - /config/Corefile.tmpl
      - /etc/coredns/Corefile
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: coredns-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /var/lib/kubelet/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/coredns
      - --resolvconf-path
      - /var/run/NetworkManager/resolv.conf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-coredns
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/coredns
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfig
    - hostPath:
        path: /etc/coredns
        type: ""
      name: conf-dir
    - hostPath:
        path: /var/run/NetworkManager
        type: ""
      name: nm-resolv
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://38ab0811e3dcf22aa4ec7643b14da1f8c1916980419b98b4cc56aff13803d40e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    - containerID: cri-o://5e8fb3fdc896c44eed2f9d7c586ff25198984a80a01efb2f1f217a87f3628f43
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: coredns-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    hostIP: XXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://e4b4df777cb298eb6cb2856486f9b2af74c8c1d50aa036c8eaf2af5d4e227f29
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-coredns
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://e4b4df777cb298eb6cb2856486f9b2af74c8c1d50aa036c8eaf2af5d4e227f29
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXX
    - ip: 2620:52:0:2e1a::2
    qosClass: Burstable
    startTime: "2025-11-17T09:32:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 47df9adf42f0cf871be2389238d63bd9
      kubernetes.io/config.mirror: 47df9adf42f0cf871be2389238d63bd9
      kubernetes.io/config.seen: "2025-11-17T09:32:19.691872753Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:36:34Z"
    labels:
      app: kni-infra-coredns
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"82931ca4-5958-4718-ae08-c14b5ced3530"}: {}
        f:spec:
          f:containers:
            k:{"name":"coredns"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
            k:{"name":"coredns-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-coredns"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/NetworkManager"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nm-resolv"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:34Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::3"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: coredns-XXXXXX1
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX1
      uid: 82931ca4-5958-4718-ae08-c14b5ced3530
    resourceVersion: "22238"
    uid: b6530bae-e1f8-465e-b498-6c5265b56cde
  spec:
    containers:
    - args:
      - --conf
      - /etc/coredns/Corefile
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 18080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - corednsmonitor
      - /var/lib/kubelet/kubeconfig
      - /config/Corefile.tmpl
      - /etc/coredns/Corefile
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: coredns-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /var/lib/kubelet/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/coredns
      - --resolvconf-path
      - /var/run/NetworkManager/resolv.conf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-coredns
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /etc/coredns
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/NetworkManager
        mountPropagation: HostToContainer
        name: nm-resolv
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/coredns
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfig
    - hostPath:
        path: /etc/coredns
        type: ""
      name: conf-dir
    - hostPath:
        path: /var/run/NetworkManager
        type: ""
      name: nm-resolv
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://64d4aeb52ef83c25ceda708f1e9d14efbb20af92bb16bbe577ba44a5526932d6
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0dc628de8b8f6899659a0da11b21ba81d4cb9f73684f3f502bee47e06c5dbe36
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    - containerID: cri-o://655f70bedad8f3ce17ef8bd2015a61a92adc78e291e34dc23dbb9a48793a6bcb
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: coredns-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:36Z"
    hostIP: XXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://0787510042aeeb36457f56f68ecb8e5fcc3516db381261dc8b535e7112ac256d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-coredns
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://0787510042aeeb36457f56f68ecb8e5fcc3516db381261dc8b535e7112ac256d
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXX
    - ip: 2620:52:0:2e1a::3
    qosClass: Burstable
    startTime: "2025-11-17T09:32:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 20d5fd846732318521a1ce8aeb2ef0a0
      kubernetes.io/config.mirror: 20d5fd846732318521a1ce8aeb2ef0a0
      kubernetes.io/config.seen: "2025-11-17T09:32:19.678130245Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:34:45Z"
    labels:
      app: kni-infra-api-lb
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"bc15ced4-edf1-4c10-8cd9-fecd74736a61"}: {}
        f:spec:
          f:containers:
            k:{"name":"haproxy"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"haproxy-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"verify-api-int-resolvable"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:34:45Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::20"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: haproxy-XXXXXX0
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX0
      uid: bc15ced4-edf1-4c10-8cd9-fecd74736a61
    resourceVersion: "22229"
    uid: f173d0c3-979a-4fe3-aa77-391c3150425d
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        verify_old_haproxy_ps_being_deleted()
        {
          local prev_pids

          prev_pids="$1"
          sleep $OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
          cur_pids=$(pidof haproxy)

          for val in $prev_pids; do
              if [[ $cur_pids =~ (^|[[:space:]])"$val"($|[[:space:]]) ]] ; then
                 kill $val
              fi
          done
        }

        reload_haproxy()
        {
          old_pids=$(pidof haproxy)
          if [ -n "$old_pids" ]; then
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid -x /var/lib/haproxy/run/haproxy.sock -sf $old_pids &
              #There seems to be some cases where HAProxy doesn't drain properly.
              #To handle that case, SIGTERM signal being sent to old HAProxy processes which haven't terminated.
              verify_old_haproxy_ps_being_deleted "$old_pids"  &
          else
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client send: $line"  >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_haproxy
            fi
          done
        }
        set -ex
        declare -r haproxy_sock="/var/run/haproxy/haproxy-XXXXXX.sock"
        declare -r haproxy_log_sock="/var/run/haproxy/haproxy-log.sock"
        export -f msg_handler
        export -f reload_haproxy
        export -f verify_old_haproxy_ps_being_deleted
        rm -f "$haproxy_sock" "$haproxy_log_sock"
        socat UNIX-RECV:${haproxy_log_sock} STDOUT &
        if [ -s "/etc/haproxy/haproxy.cfg" ]; then
            /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
        fi
        socat UNIX-LISTEN:${haproxy_sock},fork system:'bash -c msg_handler'
      env:
      - name: OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
        value: "120"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /haproxy_ready
          port: 9444
          scheme: HTTP
        initialDelaySeconds: 50
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: haproxy
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
    - command:
      - monitor
      - /var/lib/kubelet/kubeconfig
      - /config/haproxy.cfg.tmpl
      - /etc/haproxy/haproxy.cfg
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: haproxy-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /bin/bash
      - -c
      - |
        /usr/bin/curl -o /dev/null -kLfs https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/healthz
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: verify-api-int-resolvable
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    nodeName: XXXXXX0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/haproxy
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /etc/haproxy
        type: ""
      name: conf-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:33:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:33:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:33:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ad2746ec81ef4774632a90da75180324ee8878332685755d0dd597a36bbf4b63
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      lastState: {}
      name: haproxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:33:21Z"
    - containerID: cri-o://41ec53517772cd93d1202fde08025b97bacb99cd759db10f1b2b940687b33bf5
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: haproxy-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:33:21Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://50e08ec2b3dcf3fba92b7b521cdbe3cce3a59733963a3b83f2dc37905677e456
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: verify-api-int-resolvable
      ready: true
      restartCount: 3
      state:
        terminated:
          containerID: cri-o://50e08ec2b3dcf3fba92b7b521cdbe3cce3a59733963a3b83f2dc37905677e456
          exitCode: 0
          finishedAt: "2025-11-17T09:33:08Z"
          reason: Completed
          startedAt: "2025-11-17T09:33:08Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::20
    qosClass: Burstable
    startTime: "2025-11-17T09:32:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 70b0f9b18b1f799fc35b135d9cd1a379
      kubernetes.io/config.mirror: 70b0f9b18b1f799fc35b135d9cd1a379
      kubernetes.io/config.seen: "2025-11-17T09:08:22.886502593Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:10:00Z"
    labels:
      app: kni-infra-api-lb
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"08d8653a-e1d4-4358-b485-d849df97cbd8"}: {}
        f:spec:
          f:containers:
            k:{"name":"haproxy"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"haproxy-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"verify-api-int-resolvable"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:10:00Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::21"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:10:02Z"
    name: haproxy-XXXXXX1
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX1
      uid: 08d8653a-e1d4-4358-b485-d849df97cbd8
    resourceVersion: "3185"
    uid: 6acfb212-7adc-4134-94cc-86218c7fee06
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        verify_old_haproxy_ps_being_deleted()
        {
          local prev_pids

          prev_pids="$1"
          sleep $OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
          cur_pids=$(pidof haproxy)

          for val in $prev_pids; do
              if [[ $cur_pids =~ (^|[[:space:]])"$val"($|[[:space:]]) ]] ; then
                 kill $val
              fi
          done
        }

        reload_haproxy()
        {
          old_pids=$(pidof haproxy)
          if [ -n "$old_pids" ]; then
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid -x /var/lib/haproxy/run/haproxy.sock -sf $old_pids &
              #There seems to be some cases where HAProxy doesn't drain properly.
              #To handle that case, SIGTERM signal being sent to old HAProxy processes which haven't terminated.
              verify_old_haproxy_ps_being_deleted "$old_pids"  &
          else
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client send: $line"  >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_haproxy
            fi
          done
        }
        set -ex
        declare -r haproxy_sock="/var/run/haproxy/haproxy-XXXXXX.sock"
        declare -r haproxy_log_sock="/var/run/haproxy/haproxy-log.sock"
        export -f msg_handler
        export -f reload_haproxy
        export -f verify_old_haproxy_ps_being_deleted
        rm -f "$haproxy_sock" "$haproxy_log_sock"
        socat UNIX-RECV:${haproxy_log_sock} STDOUT &
        if [ -s "/etc/haproxy/haproxy.cfg" ]; then
            /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
        fi
        socat UNIX-LISTEN:${haproxy_sock},fork system:'bash -c msg_handler'
      env:
      - name: OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
        value: "120"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /haproxy_ready
          port: 9444
          scheme: HTTP
        initialDelaySeconds: 50
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: haproxy
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
    - command:
      - monitor
      - /var/lib/kubelet/kubeconfig
      - /config/haproxy.cfg.tmpl
      - /etc/haproxy/haproxy.cfg
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: haproxy-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /bin/bash
      - -c
      - |
        /usr/bin/curl -o /dev/null -kLfs https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/healthz
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: verify-api-int-resolvable
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    nodeName: XXXXXX1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/haproxy
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /etc/haproxy
        type: ""
      name: conf-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:44Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:44Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://c12885344edfc777f957beb6c7fbb743ffdceb664019c9f8b697ec38d03e1cfc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      lastState: {}
      name: haproxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:44Z"
    - containerID: cri-o://9707b53592cf99c8ab51eded3ce959361f29fa48119cbd84ff0c1252ce9fb9d5
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: haproxy-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:44Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://077a0db55dd14f899048744d845466057b62d11e0e80cc83a6fbb8ff56948ef4
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: verify-api-int-resolvable
      ready: true
      restartCount: 2
      state:
        terminated:
          containerID: cri-o://077a0db55dd14f899048744d845466057b62d11e0e80cc83a6fbb8ff56948ef4
          exitCode: 0
          finishedAt: "2025-11-17T09:08:38Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:38Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::21
    qosClass: Burstable
    startTime: "2025-11-17T09:08:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: b6da899513c0c09e91463a89b04859ee
      kubernetes.io/config.mirror: b6da899513c0c09e91463a89b04859ee
      kubernetes.io/config.seen: "2025-11-17T09:08:25.052094892Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:09:50Z"
    labels:
      app: kni-infra-api-lb
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"9bbf3978-9a24-4194-97bd-19975c5a4042"}: {}
        f:spec:
          f:containers:
            k:{"name":"haproxy"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"haproxy-monitor"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/haproxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"verify-api-int-resolvable"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:09:50Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::22"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:09:55Z"
    name: haproxy-XXXXXX2
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX2
      uid: 9bbf3978-9a24-4194-97bd-19975c5a4042
    resourceVersion: "3167"
    uid: 98b9da83-be45-412d-9be6-2ff2ab4ddd26
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        verify_old_haproxy_ps_being_deleted()
        {
          local prev_pids

          prev_pids="$1"
          sleep $OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
          cur_pids=$(pidof haproxy)

          for val in $prev_pids; do
              if [[ $cur_pids =~ (^|[[:space:]])"$val"($|[[:space:]]) ]] ; then
                 kill $val
              fi
          done
        }

        reload_haproxy()
        {
          old_pids=$(pidof haproxy)
          if [ -n "$old_pids" ]; then
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid -x /var/lib/haproxy/run/haproxy.sock -sf $old_pids &
              #There seems to be some cases where HAProxy doesn't drain properly.
              #To handle that case, SIGTERM signal being sent to old HAProxy processes which haven't terminated.
              verify_old_haproxy_ps_being_deleted "$old_pids"  &
          else
              /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client send: $line"  >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_haproxy
            fi
          done
        }
        set -ex
        declare -r haproxy_sock="/var/run/haproxy/haproxy-XXXXXX.sock"
        declare -r haproxy_log_sock="/var/run/haproxy/haproxy-log.sock"
        export -f msg_handler
        export -f reload_haproxy
        export -f verify_old_haproxy_ps_being_deleted
        rm -f "$haproxy_sock" "$haproxy_log_sock"
        socat UNIX-RECV:${haproxy_log_sock} STDOUT &
        if [ -s "/etc/haproxy/haproxy.cfg" ]; then
            /usr/sbin/haproxy -W -db -f /etc/haproxy/haproxy.cfg  -p /var/lib/haproxy/run/haproxy.pid &
        fi
        socat UNIX-LISTEN:${haproxy_sock},fork system:'bash -c msg_handler'
      env:
      - name: OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT
        value: "120"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /haproxy_ready
          port: 9444
          scheme: HTTP
        initialDelaySeconds: 50
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: haproxy
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
    - command:
      - monitor
      - /var/lib/kubelet/kubeconfig
      - /config/haproxy.cfg.tmpl
      - /etc/haproxy/haproxy.cfg
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: haproxy-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/haproxy
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/haproxy
        name: run-dir
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /bin/bash
      - -c
      - |
        /usr/bin/curl -o /dev/null -kLfs https://api-int.hlxcl51.XXXXXXXXXXXXXXXXXXXXXXX:6443/healthz
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: verify-api-int-resolvable
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
    nodeName: XXXXXX2
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/haproxy
        type: ""
      name: resource-dir
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /etc/haproxy
        type: ""
      name: conf-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://543efedd0a4041d150af8764c8c7ce6f95ad31ac7f5f04969e812976477a97bb
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0edb715030d631711ac59ca73dc7f9083080f937f5675f5e45503e40b1e8aa5d
      lastState: {}
      name: haproxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:48Z"
    - containerID: cri-o://1070d03efc504b131ec96eb7f0647f4e57c9052a89fabd3c2e7bb224f830d771
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: haproxy-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:48Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://0f494df9b4eb579de7404c1b81d0a10338a542302a6191b91854c18e462e8f60
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: verify-api-int-resolvable
      ready: true
      restartCount: 2
      state:
        terminated:
          containerID: cri-o://0f494df9b4eb579de7404c1b81d0a10338a542302a6191b91854c18e462e8f60
          exitCode: 0
          finishedAt: "2025-11-17T09:08:43Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:43Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::22
    qosClass: Burstable
    startTime: "2025-11-17T09:08:25Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7ddcdaa6d90a12c8b207139f6e1c0be5
      kubernetes.io/config.mirror: 7ddcdaa6d90a12c8b207139f6e1c0be5
      kubernetes.io/config.seen: "2025-11-17T09:32:19.678133337Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:33:51Z"
    labels:
      app: kni-infra-vrrp
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"bc15ced4-edf1-4c10-8cd9-fecd74736a61"}: {}
        f:spec:
          f:containers:
            k:{"name":"keepalived"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NSS_SDB_USE_CACHE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
                f:failureThreshold: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"keepalived-monitor"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"ENABLE_UNICAST"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"IS_BOOTSTRAP"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-keepalived"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/kubernetes"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"script-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:51Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::20"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: keepalived-XXXXXX0
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX0
      uid: bc15ced4-edf1-4c10-8cd9-fecd74736a61
    resourceVersion: "22232"
    uid: 71434f20-e59d-449a-835f-fea2dcf3fba1
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        sigterm_handler()
        {
          if pid=$(pgrep -o keepalived); then
            kill -s SIGTERM "$pid"
          fi
        }

        reload_keepalived()
        {
          if pid=$(pgrep -o keepalived); then
              kill -s SIGHUP "$pid"
          else
              /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client sent: $line" >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_keepalived
            fi
          done
        }

        remove_vip()
        {
          address=$1
          interface=$(ip -o a | awk "/\s${address}\// {print \$2}")
          cidr=$(ip -o a | awk "/\s${address}\// {print \$4}")
          if [ -n "$interface" ]; then
              ip a del $cidr dev $interface
          fi
        }

        set -ex
        # Ensure that we don't have stale VIPs configured
        # See https://bugzilla.redhat.com/show_bug.cgi?id=1931505
        remove_vip "XXXXXXXXXX0"
        remove_vip "2620:52:0:2e1a::10"
        remove_vip "XXXXXXXXXX1"
        remove_vip "2620:52:0:2e1a::11"
        declare -r keepalived_sock="/var/run/keepalived/keepalived.sock"
        export -f msg_handler
        export -f reload_keepalived
        export -f sigterm_handler

        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
           sleep infinity
           exit 0
        fi

        trap sigterm_handler SIGTERM
        if [ -s "/etc/keepalived/keepalived.conf" ]; then
            /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
        fi

        rm -f "$keepalived_sock"
        socat UNIX-LISTEN:${keepalived_sock},fork system:'bash -c msg_handler'
      env:
      - name: NSS_SDB_USE_CACHE
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            [ ! -s "/etc/keepalived/keepalived.conf" ] || (echo "" > /tmp/keepalived.data && kill -s SIGUSR1 "$(pgrep -o keepalived)" && for i in $(seq 5); do grep -q "VRRP Instance" /tmp/keepalived.data && exit 0 || sleep 1; done && exit 1)
        failureThreshold: 3
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: keepalived
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
            sleep infinity
            exit 0
        fi
        api_vips=XXXXXXXXXX0,2620:52:0:2e1a::10
        ingress_vips=XXXXXXXXXX1,2620:52:0:2e1a::11
        dynkeepalived /var/lib/kubelet/kubeconfig /config/keepalived.conf.tmpl /etc/keepalived/keepalived.conf --api-vips "${api_vips}" --ingress-vips "${ingress_vips}"
      env:
      - name: ENABLE_UNICAST
        value: "yes"
      - name: IS_BOOTSTRAP
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: keepalived-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /etc/kubernetes/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/keepalived
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-keepalived
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: script-dir
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived
        type: ""
      name: resource-dir
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived/scripts
        type: ""
      name: script-dir
    - hostPath:
        path: /etc/kubernetes
        type: ""
      name: kubeconfig
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - hostPath:
        path: /etc/keepalived
        type: ""
      name: conf-dir
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://4f0e715f76a35ea4a293b83b5be0eb0c9e822c84ea613f325d94fdb94f44505a
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      lastState: {}
      name: keepalived
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    - containerID: cri-o://c1d6287c956f8220643adf348c2c730ff2cf28148f990544d86b310d07e3353b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: keepalived-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://12812776fb2f3c610a924bf214374eec332e306f1879cc5ac3df5cbf53efdb5d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-keepalived
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://12812776fb2f3c610a924bf214374eec332e306f1879cc5ac3df5cbf53efdb5d
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::20
    qosClass: Burstable
    startTime: "2025-11-17T09:32:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: a8279f19ae48e9aa507bc1396c86fbfa
      kubernetes.io/config.mirror: a8279f19ae48e9aa507bc1396c86fbfa
      kubernetes.io/config.seen: "2025-11-17T09:08:22.886503236Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:09:40Z"
    labels:
      app: kni-infra-vrrp
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"08d8653a-e1d4-4358-b485-d849df97cbd8"}: {}
        f:spec:
          f:containers:
            k:{"name":"keepalived"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NSS_SDB_USE_CACHE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
                f:failureThreshold: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"keepalived-monitor"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"ENABLE_UNICAST"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"IS_BOOTSTRAP"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-keepalived"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/kubernetes"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"script-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:09:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::21"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:09:42Z"
    name: keepalived-XXXXXX1
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX1
      uid: 08d8653a-e1d4-4358-b485-d849df97cbd8
    resourceVersion: "3133"
    uid: b758935b-19ae-4d18-b7a6-97935cd5a462
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        sigterm_handler()
        {
          if pid=$(pgrep -o keepalived); then
            kill -s SIGTERM "$pid"
          fi
        }

        reload_keepalived()
        {
          if pid=$(pgrep -o keepalived); then
              kill -s SIGHUP "$pid"
          else
              /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client sent: $line" >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_keepalived
            fi
          done
        }

        remove_vip()
        {
          address=$1
          interface=$(ip -o a | awk "/\s${address}\// {print \$2}")
          cidr=$(ip -o a | awk "/\s${address}\// {print \$4}")
          if [ -n "$interface" ]; then
              ip a del $cidr dev $interface
          fi
        }

        set -ex
        # Ensure that we don't have stale VIPs configured
        # See https://bugzilla.redhat.com/show_bug.cgi?id=1931505
        remove_vip "XXXXXXXXXX0"
        remove_vip "2620:52:0:2e1a::10"
        remove_vip "XXXXXXXXXX1"
        remove_vip "2620:52:0:2e1a::11"
        declare -r keepalived_sock="/var/run/keepalived/keepalived.sock"
        export -f msg_handler
        export -f reload_keepalived
        export -f sigterm_handler

        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
           sleep infinity
           exit 0
        fi

        trap sigterm_handler SIGTERM
        if [ -s "/etc/keepalived/keepalived.conf" ]; then
            /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
        fi

        rm -f "$keepalived_sock"
        socat UNIX-LISTEN:${keepalived_sock},fork system:'bash -c msg_handler'
      env:
      - name: NSS_SDB_USE_CACHE
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            [ ! -s "/etc/keepalived/keepalived.conf" ] || (echo "" > /tmp/keepalived.data && kill -s SIGUSR1 "$(pgrep -o keepalived)" && for i in $(seq 5); do grep -q "VRRP Instance" /tmp/keepalived.data && exit 0 || sleep 1; done && exit 1)
        failureThreshold: 3
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: keepalived
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
            sleep infinity
            exit 0
        fi
        api_vips=XXXXXXXXXX0,2620:52:0:2e1a::10
        ingress_vips=XXXXXXXXXX1,2620:52:0:2e1a::11
        dynkeepalived /var/lib/kubelet/kubeconfig /config/keepalived.conf.tmpl /etc/keepalived/keepalived.conf --api-vips "${api_vips}" --ingress-vips "${ingress_vips}"
      env:
      - name: ENABLE_UNICAST
        value: "yes"
      - name: IS_BOOTSTRAP
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: keepalived-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /etc/kubernetes/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/keepalived
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-keepalived
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: script-dir
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived
        type: ""
      name: resource-dir
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived/scripts
        type: ""
      name: script-dir
    - hostPath:
        path: /etc/kubernetes
        type: ""
      name: kubeconfig
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - hostPath:
        path: /etc/keepalived
        type: ""
      name: conf-dir
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:25Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0fda80382d0cfed9317fa9551091ecc14b4587767c11255344a875853aa19f10
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      lastState: {}
      name: keepalived
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:31Z"
    - containerID: cri-o://e67aea2fee02c2cdacfcecc24de6a59b459d031679dcfcba77a48de64e0dbe01
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: keepalived-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:31Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://f6551ad9fd2fdeec6bbdc28757de3cec2c6bd4f4f4b36d2e9f3f29a480b23b3c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-keepalived
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://f6551ad9fd2fdeec6bbdc28757de3cec2c6bd4f4f4b36d2e9f3f29a480b23b3c
          exitCode: 0
          finishedAt: "2025-11-17T09:08:25Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:25Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::21
    qosClass: Burstable
    startTime: "2025-11-17T09:08:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 06eef85e32949d79a6c9330101db28fb
      kubernetes.io/config.mirror: 06eef85e32949d79a6c9330101db28fb
      kubernetes.io/config.seen: "2025-11-17T09:08:25.052095585Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:09:37Z"
    labels:
      app: kni-infra-vrrp
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"9bbf3978-9a24-4194-97bd-19975c5a4042"}: {}
        f:spec:
          f:containers:
            k:{"name":"keepalived"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NSS_SDB_USE_CACHE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
                f:failureThreshold: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"keepalived-monitor"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"ENABLE_UNICAST"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"IS_BOOTSTRAP"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-keepalived"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/kubernetes"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"script-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:09:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::22"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:09:45Z"
    name: keepalived-XXXXXX2
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX2
      uid: 9bbf3978-9a24-4194-97bd-19975c5a4042
    resourceVersion: "3136"
    uid: 420034f8-60d0-4a5d-8627-6961a93413ae
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        sigterm_handler()
        {
          if pid=$(pgrep -o keepalived); then
            kill -s SIGTERM "$pid"
          fi
        }

        reload_keepalived()
        {
          if pid=$(pgrep -o keepalived); then
              kill -s SIGHUP "$pid"
          else
              /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client sent: $line" >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_keepalived
            fi
          done
        }

        remove_vip()
        {
          address=$1
          interface=$(ip -o a | awk "/\s${address}\// {print \$2}")
          cidr=$(ip -o a | awk "/\s${address}\// {print \$4}")
          if [ -n "$interface" ]; then
              ip a del $cidr dev $interface
          fi
        }

        set -ex
        # Ensure that we don't have stale VIPs configured
        # See https://bugzilla.redhat.com/show_bug.cgi?id=1931505
        remove_vip "XXXXXXXXXX0"
        remove_vip "2620:52:0:2e1a::10"
        remove_vip "XXXXXXXXXX1"
        remove_vip "2620:52:0:2e1a::11"
        declare -r keepalived_sock="/var/run/keepalived/keepalived.sock"
        export -f msg_handler
        export -f reload_keepalived
        export -f sigterm_handler

        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
           sleep infinity
           exit 0
        fi

        trap sigterm_handler SIGTERM
        if [ -s "/etc/keepalived/keepalived.conf" ]; then
            /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
        fi

        rm -f "$keepalived_sock"
        socat UNIX-LISTEN:${keepalived_sock},fork system:'bash -c msg_handler'
      env:
      - name: NSS_SDB_USE_CACHE
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            [ ! -s "/etc/keepalived/keepalived.conf" ] || (echo "" > /tmp/keepalived.data && kill -s SIGUSR1 "$(pgrep -o keepalived)" && for i in $(seq 5); do grep -q "VRRP Instance" /tmp/keepalived.data && exit 0 || sleep 1; done && exit 1)
        failureThreshold: 3
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: keepalived
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
            sleep infinity
            exit 0
        fi
        api_vips=XXXXXXXXXX0,2620:52:0:2e1a::10
        ingress_vips=XXXXXXXXXX1,2620:52:0:2e1a::11
        dynkeepalived /var/lib/kubelet/kubeconfig /config/keepalived.conf.tmpl /etc/keepalived/keepalived.conf --api-vips "${api_vips}" --ingress-vips "${ingress_vips}"
      env:
      - name: ENABLE_UNICAST
        value: "yes"
      - name: IS_BOOTSTRAP
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: keepalived-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /etc/kubernetes/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/keepalived
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-keepalived
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: script-dir
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX2
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived
        type: ""
      name: resource-dir
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived/scripts
        type: ""
      name: script-dir
    - hostPath:
        path: /etc/kubernetes
        type: ""
      name: kubeconfig
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - hostPath:
        path: /etc/keepalived
        type: ""
      name: conf-dir
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:28Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:08:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://fa1d283f91a04afaca6f082d7494a19e7be28ff5f98ff54821dbd7068f507275
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      lastState: {}
      name: keepalived
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:33Z"
    - containerID: cri-o://c34eecba93b6c21e75bc0c751265772b592479b47aadb46c01583f167f83e14e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: keepalived-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:08:33Z"
    hostIP: XXXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://baeb6dd615c9c47679aa1b8c63f1e5c36a6749b6d327a5fcb253e82f965030a3
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-keepalived
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://baeb6dd615c9c47679aa1b8c63f1e5c36a6749b6d327a5fcb253e82f965030a3
          exitCode: 0
          finishedAt: "2025-11-17T09:08:27Z"
          reason: Completed
          startedAt: "2025-11-17T09:08:27Z"
    phase: Running
    podIP: XXXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXXX
    - ip: 2620:52:0:2e1a::22
    qosClass: Burstable
    startTime: "2025-11-17T09:08:25Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7d0a14b6f5553ab3c0079363a15356c6
      kubernetes.io/config.mirror: 7d0a14b6f5553ab3c0079363a15356c6
      kubernetes.io/config.seen: "2025-11-17T09:32:19.875282194Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:33:56Z"
    labels:
      app: kni-infra-vrrp
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"be542f6b-71a2-46af-9c87-f2120b48ad2f"}: {}
        f:spec:
          f:containers:
            k:{"name":"keepalived"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NSS_SDB_USE_CACHE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
                f:failureThreshold: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"keepalived-monitor"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"ENABLE_UNICAST"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"IS_BOOTSTRAP"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-keepalived"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/kubernetes"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"script-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:56Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::2"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: keepalived-XXXXXX0
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX0
      uid: be542f6b-71a2-46af-9c87-f2120b48ad2f
    resourceVersion: "22243"
    uid: 9aeb74f5-5aa6-4952-b272-eb0a51ec8e25
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        sigterm_handler()
        {
          if pid=$(pgrep -o keepalived); then
            kill -s SIGTERM "$pid"
          fi
        }

        reload_keepalived()
        {
          if pid=$(pgrep -o keepalived); then
              kill -s SIGHUP "$pid"
          else
              /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client sent: $line" >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_keepalived
            fi
          done
        }

        remove_vip()
        {
          address=$1
          interface=$(ip -o a | awk "/\s${address}\// {print \$2}")
          cidr=$(ip -o a | awk "/\s${address}\// {print \$4}")
          if [ -n "$interface" ]; then
              ip a del $cidr dev $interface
          fi
        }

        set -ex
        # Ensure that we don't have stale VIPs configured
        # See https://bugzilla.redhat.com/show_bug.cgi?id=1931505
        remove_vip "XXXXXXXXXX0"
        remove_vip "2620:52:0:2e1a::10"
        remove_vip "XXXXXXXXXX1"
        remove_vip "2620:52:0:2e1a::11"
        declare -r keepalived_sock="/var/run/keepalived/keepalived.sock"
        export -f msg_handler
        export -f reload_keepalived
        export -f sigterm_handler

        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
           sleep infinity
           exit 0
        fi

        trap sigterm_handler SIGTERM
        if [ -s "/etc/keepalived/keepalived.conf" ]; then
            /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
        fi

        rm -f "$keepalived_sock"
        socat UNIX-LISTEN:${keepalived_sock},fork system:'bash -c msg_handler'
      env:
      - name: NSS_SDB_USE_CACHE
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            [ ! -s "/etc/keepalived/keepalived.conf" ] || (echo "" > /tmp/keepalived.data && kill -s SIGUSR1 "$(pgrep -o keepalived)" && for i in $(seq 5); do grep -q "VRRP Instance" /tmp/keepalived.data && exit 0 || sleep 1; done && exit 1)
        failureThreshold: 3
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: keepalived
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
            sleep infinity
            exit 0
        fi
        api_vips=XXXXXXXXXX0,2620:52:0:2e1a::10
        ingress_vips=XXXXXXXXXX1,2620:52:0:2e1a::11
        dynkeepalived /var/lib/kubelet/kubeconfig /config/keepalived.conf.tmpl /etc/keepalived/keepalived.conf --api-vips "${api_vips}" --ingress-vips "${ingress_vips}"
      env:
      - name: ENABLE_UNICAST
        value: "yes"
      - name: IS_BOOTSTRAP
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: keepalived-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /etc/kubernetes/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/keepalived
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-keepalived
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: script-dir
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX0
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived
        type: ""
      name: resource-dir
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived/scripts
        type: ""
      name: script-dir
    - hostPath:
        path: /etc/kubernetes
        type: ""
      name: kubeconfig
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - hostPath:
        path: /etc/keepalived
        type: ""
      name: conf-dir
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0f556735d94e1de227417d8f40e06b44604313a7df4a8416d24f74de04f2cc84
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      lastState: {}
      name: keepalived
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    - containerID: cri-o://e27609be7c6ad1c0c0423691e028d5068aee180aaa0ba4071391f354baaf415e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: keepalived-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    hostIP: XXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://49f2e5d5d9009cc0a26adfe3a867bf328e0e9d54eda7340389788d3f482b581d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-keepalived
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://49f2e5d5d9009cc0a26adfe3a867bf328e0e9d54eda7340389788d3f482b581d
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXX
    - ip: 2620:52:0:2e1a::2
    qosClass: Burstable
    startTime: "2025-11-17T09:32:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 5a0be7a0e9840acbbc996cb96d46e78a
      kubernetes.io/config.mirror: 5a0be7a0e9840acbbc996cb96d46e78a
      kubernetes.io/config.seen: "2025-11-17T09:32:19.691867954Z"
      kubernetes.io/config.source: file
      openshift.io/scc: privileged
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    creationTimestamp: "2025-11-17T09:36:39Z"
    labels:
      app: kni-infra-vrrp
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubernetes.io/config.hash: {}
            f:kubernetes.io/config.mirror: {}
            f:kubernetes.io/config.seen: {}
            f:kubernetes.io/config.source: {}
            f:target.workload.openshift.io/management: {}
          f:labels:
            .: {}
            f:app: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"82931ca4-5958-4718-ae08-c14b5ced3530"}: {}
        f:spec:
          f:containers:
            k:{"name":"keepalived"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NSS_SDB_USE_CACHE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
                f:failureThreshold: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"keepalived-monitor"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"ENABLE_UNICAST"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"IS_BOOTSTRAP"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/host"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:initContainers:
            .: {}
            k:{"name":"render-config-keepalived"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/keepalived"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/etc/kubernetes"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/run/nodeip-configuration"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
          f:nodeName: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"chroot-host"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"conf-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfig"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubeconfigvarlib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"nodeip-configuration"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"resource-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"run-dir"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"script-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"XXXXXXXXXX"}:
              .: {}
              f:ip: {}
            k:{"ip":"2620:52:0:2e1a::3"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-11-17T09:36:59Z"
    name: keepalived-XXXXXX1
    namespace: openshift-kni-infra
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: XXXXXX1
      uid: 82931ca4-5958-4718-ae08-c14b5ced3530
    resourceVersion: "22237"
    uid: bb0cd9f5-08db-4ce8-806e-b263db388489
  spec:
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        sigterm_handler()
        {
          if pid=$(pgrep -o keepalived); then
            kill -s SIGTERM "$pid"
          fi
        }

        reload_keepalived()
        {
          if pid=$(pgrep -o keepalived); then
              kill -s SIGHUP "$pid"
          else
              /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
          fi
        }

        msg_handler()
        {
          while read -r line; do
            echo "The client sent: $line" >&2
            # currently only 'reload' msg is supported
            if [ "$line" = reload ]; then
                reload_keepalived
            fi
          done
        }

        remove_vip()
        {
          address=$1
          interface=$(ip -o a | awk "/\s${address}\// {print \$2}")
          cidr=$(ip -o a | awk "/\s${address}\// {print \$4}")
          if [ -n "$interface" ]; then
              ip a del $cidr dev $interface
          fi
        }

        set -ex
        # Ensure that we don't have stale VIPs configured
        # See https://bugzilla.redhat.com/show_bug.cgi?id=1931505
        remove_vip "XXXXXXXXXX0"
        remove_vip "2620:52:0:2e1a::10"
        remove_vip "XXXXXXXXXX1"
        remove_vip "2620:52:0:2e1a::11"
        declare -r keepalived_sock="/var/run/keepalived/keepalived.sock"
        export -f msg_handler
        export -f reload_keepalived
        export -f sigterm_handler

        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
           sleep infinity
           exit 0
        fi

        trap sigterm_handler SIGTERM
        if [ -s "/etc/keepalived/keepalived.conf" ]; then
            /usr/sbin/keepalived -f /etc/keepalived/keepalived.conf --dont-fork --vrrp --log-detail --log-console &
        fi

        rm -f "$keepalived_sock"
        socat UNIX-LISTEN:${keepalived_sock},fork system:'bash -c msg_handler'
      env:
      - name: NSS_SDB_USE_CACHE
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            [ ! -s "/etc/keepalived/keepalived.conf" ] || (echo "" > /tmp/keepalived.data && kill -s SIGUSR1 "$(pgrep -o keepalived)" && for i in $(seq 5); do grep -q "VRRP Instance" /tmp/keepalived.data && exit 0 || sleep 1; done && exit 1)
        failureThreshold: 3
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: keepalived
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    - command:
      - /bin/bash
      - -c
      - |
        #/bin/bash
        # in remote XXXXXX case sleep forever
        if [ -f "/run/nodeip-configuration/remote-XXXXXX" ]; then
            sleep infinity
            exit 0
        fi
        api_vips=XXXXXXXXXX0,2620:52:0:2e1a::10
        ingress_vips=XXXXXXXXXX1,2620:52:0:2e1a::11
        dynkeepalived /var/lib/kubelet/kubeconfig /config/keepalived.conf.tmpl /etc/keepalived/keepalived.conf --api-vips "${api_vips}" --ingress-vips "${ingress_vips}"
      env:
      - name: ENABLE_UNICAST
        value: "yes"
      - name: IS_BOOTSTRAP
        value: "no"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: keepalived-monitor
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /config
        mountPropagation: HostToContainer
        name: resource-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: HostToContainer
        name: kubeconfigvarlib
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /var/run/keepalived
        name: run-dir
      - mountPath: /host
        mountPropagation: HostToContainer
        name: chroot-host
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - runtimecfg
      - render
      - /etc/kubernetes/kubeconfig
      - --api-vips
      - XXXXXXXXXX0,2620:52:0:2e1a::10
      - --ingress-vips
      - XXXXXXXXXX1,2620:52:0:2e1a::11
      - /config
      - --out-dir
      - /etc/keepalived
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imagePullPolicy: IfNotPresent
      name: render-config-keepalived
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        mountPropagation: HostToContainer
        name: kubeconfig
      - mountPath: /config
        mountPropagation: HostToContainer
        name: script-dir
      - mountPath: /etc/keepalived
        mountPropagation: HostToContainer
        name: conf-dir
      - mountPath: /run/nodeip-configuration
        mountPropagation: HostToContainer
        name: nodeip-configuration
    nodeName: XXXXXX1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived
        type: ""
      name: resource-dir
    - hostPath:
        path: /etc/kubernetes/static-pod-resources/keepalived/scripts
        type: ""
      name: script-dir
    - hostPath:
        path: /etc/kubernetes
        type: ""
      name: kubeconfig
    - hostPath:
        path: /var/lib/kubelet
        type: ""
      name: kubeconfigvarlib
    - hostPath:
        path: /etc/keepalived
        type: ""
      name: conf-dir
    - emptyDir: {}
      name: run-dir
    - hostPath:
        path: /
        type: ""
      name: chroot-host
    - hostPath:
        path: /run/nodeip-configuration
        type: ""
      name: nodeip-configuration
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-11-17T09:32:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0a95700d7110cfd1328fe85d1c3329df79961afbbf69c356277aa72c1f761d03
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:41a6c259299f7019a4b737c86e0c785ae99119710064c2513778df37be2a4894
      lastState: {}
      name: keepalived
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    - containerID: cri-o://1eee9f6d5baffa0a257bc30e401bcaaa05298fd4a0afc55b2402c73adfa3266b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: keepalived-monitor
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-11-17T09:32:38Z"
    hostIP: XXXXXXXXXX
    initContainerStatuses:
    - containerID: cri-o://f8d9c452c5df91cc176f823b5e6e0686e31ff9923a1f7a5a5c06b2476515bde8
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:86702c0acd55053ff2e5c2072d86f82109142b1d0d7c8701919f5c06489d1ffe
      lastState: {}
      name: render-config-keepalived
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://f8d9c452c5df91cc176f823b5e6e0686e31ff9923a1f7a5a5c06b2476515bde8
          exitCode: 0
          finishedAt: "2025-11-17T09:32:22Z"
          reason: Completed
          startedAt: "2025-11-17T09:32:22Z"
    phase: Running
    podIP: XXXXXXXXXX
    podIPs:
    - ip: XXXXXXXXXX
    - ip: 2620:52:0:2e1a::3
    qosClass: Burstable
    startTime: "2025-11-17T09:32:19Z"
kind: PodList
metadata:
  resourceVersion: "32547"
