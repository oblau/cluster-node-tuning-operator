---
apiVersion: v1
items:
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:50Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "13009"
    uid: 655eefd0-7f87-472b-876b-d4a6328e434c
  kind: Event
  lastTimestamp: "2025-11-17T09:23:50Z"
  message: XXXXXX1_9ef9fecb-7694-409c-8b09-3172456f0293 became leader
  metadata:
    creationTimestamp: "2025-11-17T09:23:50Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:23:50Z"
    name: cert-regeneration-controller-lock.1878c0f91b003369
    namespace: openshift-kube-apiserver
    resourceVersion: "13010"
    uid: 1394402a-732c-4b2c-a6e6-b65b3cda52ba
  reason: LeaderElection
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:32:57Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "19060"
    uid: 655eefd0-7f87-472b-876b-d4a6328e434c
  kind: Event
  lastTimestamp: "2025-11-17T09:32:57Z"
  message: XXXXXX1_af419f22-77b7-459d-ab01-4be98ea48bc2 became leader
  metadata:
    creationTimestamp: "2025-11-17T09:32:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:32:57Z"
    name: cert-regeneration-controller-lock.1878c178685ad162
    namespace: openshift-kube-apiserver
    resourceVersion: "19062"
    uid: 3bcbd0e2-2a6a-473a-90f5-ae5b1a722bf4
  reason: LeaderElection
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:34:23Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "20759"
    uid: 655eefd0-7f87-472b-876b-d4a6328e434c
  kind: Event
  lastTimestamp: "2025-11-17T09:34:23Z"
  message: XXXXXX2_26e4dad2-534b-4ae4-81ec-7ef85afdf002 became leader
  metadata:
    creationTimestamp: "2025-11-17T09:34:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:34:23Z"
    name: cert-regeneration-controller-lock.1878c18c6ec45ee6
    namespace: openshift-kube-apiserver
    resourceVersion: "20760"
    uid: 6ca8e3a9-0e18-4939-818d-1289d972eb12
  reason: LeaderElection
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:57Z"
  involvedObject:
    apiVersion: coordination.k8s.io/v1
    kind: Lease
    name: cert-regeneration-controller-lock
    namespace: openshift-kube-apiserver
    resourceVersion: "28788"
    uid: 655eefd0-7f87-472b-876b-d4a6328e434c
  kind: Event
  lastTimestamp: "2025-11-17T09:42:57Z"
  message: XXXXXX0_84302778-c930-487e-b737-e1cb41a38b71 became leader
  metadata:
    creationTimestamp: "2025-11-17T09:42:57Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:42:57Z"
    name: cert-regeneration-controller-lock.1878c20446098127
    namespace: openshift-kube-apiserver
    resourceVersion: "28790"
    uid: 2f0ac287-6df0-49a6-b10c-73ec77ceeaff
  reason: LeaderElection
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:03Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12348"
    uid: d5047d2c-67f3-49af-87f4-277c0a15839f
  kind: Event
  lastTimestamp: "2025-11-17T09:23:03Z"
  message: Add eth0 [10.128.0.35/23 fd02:0:0:1::23/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:23:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:23:03Z"
    name: installer-2-XXXXXX1.1878c0ee5190670d
    namespace: openshift-kube-apiserver
    resourceVersion: "12378"
    uid: 8518a705-2739-4a49-a5cb-327e20025215
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12345"
    uid: d5047d2c-67f3-49af-87f4-277c0a15839f
  kind: Event
  lastTimestamp: "2025-11-17T09:23:03Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:03Z"
    name: installer-2-XXXXXX1.1878c0ee530bddf8
    namespace: openshift-kube-apiserver
    resourceVersion: "12380"
    uid: ebf8c2c6-28a6-41da-9472-d2d983d16060
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12345"
    uid: d5047d2c-67f3-49af-87f4-277c0a15839f
  kind: Event
  lastTimestamp: "2025-11-17T09:23:04Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:23:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:04Z"
    name: installer-2-XXXXXX1.1878c0ee6e96e224
    namespace: openshift-kube-apiserver
    resourceVersion: "12382"
    uid: 3943893b-6bfb-4eae-a1a8-914be5debefa
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:04Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-2-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12345"
    uid: d5047d2c-67f3-49af-87f4-277c0a15839f
  kind: Event
  lastTimestamp: "2025-11-17T09:23:04Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:23:04Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:04Z"
    name: installer-2-XXXXXX1.1878c0ee7012e8d7
    namespace: openshift-kube-apiserver
    resourceVersion: "12383"
    uid: 62b3b4e2-c34b-4cdc-911b-09fe0bf147d4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:41Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-2-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: d5047d2c-67f3-49af-87f4-277c0a15839f
  kind: Event
  lastTimestamp: "2025-11-17T09:23:41Z"
  message: Successfully installed revision 2
  metadata:
    creationTimestamp: "2025-11-17T09:23:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:23:42Z"
    name: installer-2-XXXXXX1.1878c0f728cfbea5
    namespace: openshift-kube-apiserver
    resourceVersion: "12772"
    uid: dbe0fd46-d8b9-47a5-b250-80e0d403577f
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:41Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18320"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:30:41Z"
  message: Add eth0 [10.128.0.48/23 fd02:0:0:1::30/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:30:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:30:41Z"
    name: installer-3-XXXXXX1.1878c158c3515e7e
    namespace: openshift-kube-apiserver
    resourceVersion: "18444"
    uid: 7332be54-40f1-49af-8cb3-76f75d188df7
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18317"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:30:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:30:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:41Z"
    name: installer-3-XXXXXX1.1878c158c4c689ce
    namespace: openshift-kube-apiserver
    resourceVersion: "18446"
    uid: e64a27d4-c4b4-4ccd-acdb-b21c9dcf3d3a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18317"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:30:41Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:30:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:41Z"
    name: installer-3-XXXXXX1.1878c158da923f1a
    namespace: openshift-kube-apiserver
    resourceVersion: "18471"
    uid: c6942ed3-0e3f-4197-8565-b0072097509e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18317"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:30:41Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:30:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:41Z"
    name: installer-3-XXXXXX1.1878c158db926379
    namespace: openshift-kube-apiserver
    resourceVersion: "18474"
    uid: f80cecb6-2743-4d4c-acf2-d92fa612317a
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:46Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18317"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:30:46Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2025-11-17T09:30:46Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:46Z"
    name: installer-3-XXXXXX1.1878c15a1bdd0f0d
    namespace: openshift-kube-apiserver
    resourceVersion: "18547"
    uid: 423291c5-cc95-40e7-a783-520b353978f5
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:32:12Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18317"
    uid: 0882b149-d090-4a47-9635-d625c4fe3fc1
  kind: Event
  lastTimestamp: "2025-11-17T09:32:12Z"
  message: 'error killing pod: failed to "KillPodSandbox" for "0882b149-d090-4a47-9635-d625c4fe3fc1"
    with KillPodSandboxError: "rpc error: code = Unknown desc = failed to destroy
    network for pod sandbox k8s_installer-3-XXXXXX1_openshift-kube-apiserver_0882b149-d090-4a47-9635-d625c4fe3fc1_0(ac91ab38d9627a6aec7ccfc5f81e54c36da298ae51661698f5d4670ef0f7909e):
    error removing pod openshift-kube-apiserver_installer-3-XXXXXX1 from CNI network
    \"multus-cni-network\": plugin type=\"multus-shim\" name=\"multus-cni-network\"
    failed (delete): netplugin failed with no error message: signal: killed: failed
    to remove netns path: unlinkat /var/run/netns/5e58fbdc-5056-433b-ba70-d4abbb45c58b:
    device or resource busy"'
  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: installer-3-XXXXXX1.1878c16defdd69f7
    namespace: openshift-kube-apiserver
    resourceVersion: "19393"
    uid: 80deac15-0c0f-433c-8627-609a19414df5
  reason: FailedKillPod
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:36Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "13723"
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:24:36Z"
  message: Add eth0 [10.129.0.51/23 fd02:0:0:2::33/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:24:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:24:36Z"
    name: installer-3-XXXXXX2.1878c103e3565adf
    namespace: openshift-kube-apiserver
    resourceVersion: "13747"
    uid: eff49317-3f78-4910-becc-fd6b933ac5b0
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "13720"
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:24:36Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:24:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:24:36Z"
    name: installer-3-XXXXXX2.1878c103e4a04f4d
    namespace: openshift-kube-apiserver
    resourceVersion: "13751"
    uid: 298dc708-4b8f-4b46-ba92-ef274c4204bd
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "13720"
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:24:36Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:24:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:24:36Z"
    name: installer-3-XXXXXX2.1878c103fa20e256
    namespace: openshift-kube-apiserver
    resourceVersion: "13760"
    uid: 2c2c67c1-276b-4c43-a93f-91cada345921
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:24:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "13720"
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:24:37Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:24:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:24:37Z"
    name: installer-3-XXXXXX2.1878c103fe38b4cf
    namespace: openshift-kube-apiserver
    resourceVersion: "13762"
    uid: 9a7c470b-18a2-4364-b23f-1a75cec63b79
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:14Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:25:14Z"
  message: Successfully installed revision 3
  metadata:
    creationTimestamp: "2025-11-17T09:25:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:25:14Z"
    name: installer-3-XXXXXX2.1878c10cbf560a4d
    namespace: openshift-kube-apiserver
    resourceVersion: "14080"
    uid: dd9ae9e8-67b4-467e-a449-031308aed974
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:26:16Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-3-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "13720"
    uid: 1f1d1505-0786-406b-84b4-4d690bedf572
  kind: Event
  lastTimestamp: "2025-11-17T09:26:16Z"
  message: 'error killing pod: failed to "KillPodSandbox" for "1f1d1505-0786-406b-84b4-4d690bedf572"
    with KillPodSandboxError: "rpc error: code = Unknown desc = failed to destroy
    network for pod sandbox k8s_installer-3-XXXXXX2_openshift-kube-apiserver_1f1d1505-0786-406b-84b4-4d690bedf572_0(af754a08e1a2b90cab18d6bc3e1f77a025033ba1bbfde1228b05d609a0b5278f):
    error removing pod openshift-kube-apiserver_installer-3-XXXXXX2 from CNI network
    \"multus-cni-network\": plugin type=\"multus-shim\" name=\"multus-cni-network\"
    failed (delete): netplugin failed with no error message: signal: killed: failed
    to remove netns path: unlinkat /var/run/netns/e65d3c80-dea4-4cbe-95cc-74f25fc81bba:
    device or resource busy"'
  metadata:
    creationTimestamp: "2025-11-17T09:27:15Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:15Z"
    name: installer-3-XXXXXX2.1878c11b10f2c5de
    namespace: openshift-kube-apiserver
    resourceVersion: "14282"
    uid: ae795ba2-e9ec-4a83-aef8-04c4072ed417
  reason: FailedKillPod
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 18
  eventTime: null
  firstTimestamp: "2025-11-17T09:37:20Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "22557"
    uid: 1405c2de-8dda-4557-ac79-55c440f82930
  kind: Event
  lastTimestamp: "2025-11-17T09:37:53Z"
  message: 'network is not ready: container runtime network not ready: NetworkReady=false
    reason:NetworkPluginNotReady message:Network plugin returns error: No CNI configuration
    file in /etc/kubernetes/cni/net.d/. Has your network provider started?'
  metadata:
    creationTimestamp: "2025-11-17T09:37:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:37:53Z"
    name: installer-4-XXXXXX0.1878c1b5ba6016b1
    namespace: openshift-kube-apiserver
    resourceVersion: "23034"
    uid: 9819462f-8c68-4179-b2c0-32f9fb26f88e
  reason: NetworkNotReady
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Warning
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2025-11-17T09:37:20Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "22557"
    uid: 1405c2de-8dda-4557-ac79-55c440f82930
  kind: Event
  lastTimestamp: "2025-11-17T09:37:52Z"
  message: 'MountVolume.SetUp failed for volume "kube-api-access" : object "openshift-kube-apiserver"/"kube-root-ca.crt"
    not registered'
  metadata:
    creationTimestamp: "2025-11-17T09:37:20Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:37:52Z"
    name: installer-4-XXXXXX0.1878c1b5c5137b89
    namespace: openshift-kube-apiserver
    resourceVersion: "22998"
    uid: 10a63c10-154b-4fad-853b-9825e8f4e968
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:38:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "23345"
    uid: 1405c2de-8dda-4557-ac79-55c440f82930
  kind: Event
  lastTimestamp: "2025-11-17T09:38:26Z"
  message: Add eth0 [10.130.0.10/23 fd02:0:0:3::a/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:38:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:38:26Z"
    name: installer-4-XXXXXX0.1878c1c52a067c31
    namespace: openshift-kube-apiserver
    resourceVersion: "23725"
    uid: 09b717e2-a01b-4c7d-a5df-9ecfc9a02f78
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:55Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18960"
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:32:52Z"
  message: Add eth0 [10.128.0.51/23 fd02:0:0:1::33/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:33:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:33:03Z"
    name: installer-4-XXXXXX1.1878c15c060d8e00
    namespace: openshift-kube-apiserver
    resourceVersion: "19299"
    uid: 10426168-914f-420b-a026-90b57fa34dd6
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:32:49Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18957"
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:32:49Z"
  message: |-
    Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create pod network sandbox k8s_installer-4-XXXXXX1_openshift-kube-apiserver_362aff68-ea34-4d61-9e0d-5f067172655f_0(9c42ee9c644eeef2d5353dfffa974a1acedcef53077439229b6ed05c798c4d04): error adding pod openshift-kube-apiserver_installer-4-XXXXXX1 to CNI network "multus-cni-network": plugin type="multus-shim" name="multus-cni-network" failed (add): CmdAdd (shim): CNI request failed with status 400: '&{ContainerID:9c42ee9c644eeef2d5353dfffa974a1acedcef53077439229b6ed05c798c4d04 Netns:/var/run/netns/82767eaf-4661-443a-a3f6-cd12bd514e33 IfName:eth0 Args:IgnoreUnknown=1;K8S_POD_NAMESPACE=openshift-kube-apiserver;K8S_POD_NAME=installer-4-XXXXXX1;K8S_POD_INFRA_CONTAINER_ID=9c42ee9c644eeef2d5353dfffa974a1acedcef53077439229b6ed05c798c4d04;K8S_POD_UID=362aff68-ea34-4d61-9e0d-5f067172655f Path: StdinData:[123 34 98 105 110 68 105 114 34 58 34 47 118 97 114 47 108 105 98 47 99 110 105 47 98 105 110 34 44 34 99 104 114 111 111 116 68 105 114 34 58 34 47 104 111 115 116 114 111 111 116 34 44 34 99 108 117 115 116 101 114 78 101 116 119 111 114 107 34 58 34 47 104 111 115 116 47 114 117 110 47 109 117 108 116 117 115 47 99 110 105 47 110 101 116 46 100 47 49 48 45 111 118 110 45 107 117 98 101 114 110 101 116 101 115 46 99 111 110 102 34 44 34 99 110 105 67 111 110 102 105 103 68 105 114 34 58 34 47 104 111 115 116 47 101 116 99 47 99 110 105 47 110 101 116 46 100 34 44 34 99 110 105 86 101 114 115 105 111 110 34 58 34 48 46 51 46 49 34 44 34 100 97 101 109 111 110 83 111 99 107 101 116 68 105 114 34 58 34 47 114 117 110 47 109 117 108 116 117 115 47 115 111 99 107 101 116 34 44 34 103 108 111 98 97 108 78 97 109 101 115 112 97 99 101 115 34 58 34 100 101 102 97 117 108 116 44 111 112 101 110 115 104 105 102 116 45 109 117 108 116 117 115 44 111 112 101 110 115 104 105 102 116 45 115 114 105 111 118 45 110 101 116 119 111 114 107 45 111 112 101 114 97 116 111 114 34 44 34 108 111 103 76 101 118 101 108 34 58 34 118 101 114 98 111 115 101 34 44 34 108 111 103 84 111 83 116 100 101 114 114 34 58 116 114 117 101 44 34 109 117 108 116 117 115 65 117 116 111 99 111 110 102 105 103 68 105 114 34 58 34 47 104 111 115 116 47 114 117 110 47 109 117 108 116 117 115 47 99 110 105 47 110 101 116 46 100 34 44 34 109 117 108 116 117 115 67 111 110 102 105 103 70 105 108 101 34 58 34 97 117 116 111 34 44 34 110 97 109 101 34 58 34 109 117 108 116 117 115 45 99 110 105 45 110 101 116 119 111 114 107 34 44 34 110 97 109 101 115 112 97 99 101 73 115 111 108 97 116 105 111 110 34 58 116 114 117 101 44 34 112 101 114 78 111 100 101 67 101 114 116 105 102 105 99 97 116 101 34 58 123 34 98 111 111 116 115 116 114 97 112 75 117 98 101 99 111 110 102 105 103 34 58 34 47 118 97 114 47 108 105 98 47 107 117 98 101 108 101 116 47 107 117 98 101 99 111 110 102 105 103 34 44 34 99 101 114 116 68 105 114 34 58 34 47 101 116 99 47 99 110 105 47 109 117 108 116 117 115 47 99 101 114 116 115 34 44 34 99 101 114 116 68 117 114 97 116 105 111 110 34 58 34 50 52 104 34 44 34 101 110 97 98 108 101 100 34 58 116 114 117 101 125 44 34 115 111 99 107 101 116 68 105 114 34 58 34 47 104 111 115 116 47 114 117 110 47 109 117 108 116 117 115 47 115 111 99 107 101 116 34 44 34 116 121 112 101 34 58 34 109 117 108 116 117 115 45 115 104 105 109 34 125]} ContainerID:"9c42ee9c644eeef2d5353dfffa974a1acedcef53077439229b6ed05c798c4d04" Netns:"/var/run/netns/82767eaf-4661-443a-a3f6-cd12bd514e33" IfName:"eth0" Args:"IgnoreUnknown=1;K8S_POD_NAMESPACE=openshift-kube-apiserver;K8S_POD_NAME=installer-4-XXXXXX1;K8S_POD_INFRA_CONTAINER_ID=9c42ee9c644eeef2d5353dfffa974a1acedcef53077439229b6ed05c798c4d04;K8S_POD_UID=362aff68-ea34-4d61-9e0d-5f067172655f" Path:"" ERRORED: error configuring pod [openshift-kube-apiserver/installer-4-XXXXXX1] networking: Multus: [openshift-kube-apiserver/installer-4-XXXXXX1/362aff68-ea34-4d61-9e0d-5f067172655f]: error setting the networks status, pod was already deleted: SetPodNetworkStatusAnnotation: failed to query the pod installer-4-XXXXXX1 in out of cluster comm: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-4-XXXXXX1)
    '
  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: installer-4-XXXXXX1.1878c176b25b69dd
    namespace: openshift-kube-apiserver
    resourceVersion: "19416"
    uid: 26f1aeda-f880-440b-a1c7-fadd47047886
  reason: FailedCreatePodSandBox
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18957"
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:33:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: installer-4-XXXXXX1.1878c17970680ee9
    namespace: openshift-kube-apiserver
    resourceVersion: "19430"
    uid: 845011c6-3345-457b-abf7-e508672ad3a1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18957"
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:33:01Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: installer-4-XXXXXX1.1878c17987049fbe
    namespace: openshift-kube-apiserver
    resourceVersion: "19431"
    uid: ccb70fc4-6ebe-46e0-9e6c-7d680bccbe71
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "18957"
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:33:01Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: installer-4-XXXXXX1.1878c17989e8846f
    namespace: openshift-kube-apiserver
    resourceVersion: "19432"
    uid: 64ca93b3-28fb-4466-9a44-6eeea3aa21cc
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:49Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-4-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 362aff68-ea34-4d61-9e0d-5f067172655f
  kind: Event
  lastTimestamp: "2025-11-17T09:33:49Z"
  message: Successfully installed revision 4
  metadata:
    creationTimestamp: "2025-11-17T09:33:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:33:49Z"
    name: installer-4-XXXXXX1.1878c1849bc1d0a7
    namespace: openshift-kube-apiserver
    resourceVersion: "20357"
    uid: 7f2978d8-0670-468e-b65b-71e7e5586507
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:16Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-5-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "25509"
    uid: 833a3570-a70b-416f-9e36-077043b3f8d6
  kind: Event
  lastTimestamp: "2025-11-17T09:39:16Z"
  message: Add eth0 [10.130.0.21/23 fd02:0:0:3::15/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:39:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:39:16Z"
    name: installer-5-XXXXXX0.1878c1d0a9d105ea
    namespace: openshift-kube-apiserver
    resourceVersion: "25579"
    uid: f4189c62-cdae-4134-a7cb-bc5ae9e0e59f
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:16Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "25503"
    uid: 833a3570-a70b-416f-9e36-077043b3f8d6
  kind: Event
  lastTimestamp: "2025-11-17T09:39:16Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:39:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:16Z"
    name: installer-5-XXXXXX0.1878c1d0ab47c718
    namespace: openshift-kube-apiserver
    resourceVersion: "25582"
    uid: 8259a71e-f2b9-43aa-b303-50e666dd7d51
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:16Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "25503"
    uid: 833a3570-a70b-416f-9e36-077043b3f8d6
  kind: Event
  lastTimestamp: "2025-11-17T09:39:16Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:39:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:16Z"
    name: installer-5-XXXXXX0.1878c1d0be67d0f6
    namespace: openshift-kube-apiserver
    resourceVersion: "25584"
    uid: 8a3f311f-6d92-4fd1-aae8-f0399d97100e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:16Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "25503"
    uid: 833a3570-a70b-416f-9e36-077043b3f8d6
  kind: Event
  lastTimestamp: "2025-11-17T09:39:16Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:39:16Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:16Z"
    name: installer-5-XXXXXX0.1878c1d0bf45c02b
    namespace: openshift-kube-apiserver
    resourceVersion: "25585"
    uid: 125576c2-b65b-4aaa-9ef2-1c409555b47b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-5-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "25503"
    uid: 833a3570-a70b-416f-9e36-077043b3f8d6
  kind: Event
  lastTimestamp: "2025-11-17T09:39:30Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2025-11-17T09:39:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:30Z"
    name: installer-5-XXXXXX0.1878c1d3fb476124
    namespace: openshift-kube-apiserver
    resourceVersion: "25882"
    uid: 0cf1c0e8-fdc3-44f2-87b3-1a0c4597136e
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:40Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-6-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "26067"
    uid: 57a7601b-4350-4598-acf4-bfac291dfdad
  kind: Event
  lastTimestamp: "2025-11-17T09:39:40Z"
  message: Add eth0 [10.130.0.26/23 fd02:0:0:3::1a/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:39:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:39:40Z"
    name: installer-6-XXXXXX0.1878c1d668c9d822
    namespace: openshift-kube-apiserver
    resourceVersion: "26106"
    uid: 12249a2c-c369-4000-a01d-a379c4223744
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "26064"
    uid: 57a7601b-4350-4598-acf4-bfac291dfdad
  kind: Event
  lastTimestamp: "2025-11-17T09:39:40Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:39:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:40Z"
    name: installer-6-XXXXXX0.1878c1d66aa71c17
    namespace: openshift-kube-apiserver
    resourceVersion: "26113"
    uid: 79521ecb-3f31-4895-b2fc-4fa9cfad8063
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "26064"
    uid: 57a7601b-4350-4598-acf4-bfac291dfdad
  kind: Event
  lastTimestamp: "2025-11-17T09:39:41Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:39:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:41Z"
    name: installer-6-XXXXXX0.1878c1d6842d02bb
    namespace: openshift-kube-apiserver
    resourceVersion: "26127"
    uid: 39bf92f1-94ca-4ae7-8181-25bf03108058
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:39:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "26064"
    uid: 57a7601b-4350-4598-acf4-bfac291dfdad
  kind: Event
  lastTimestamp: "2025-11-17T09:39:41Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:39:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:39:41Z"
    name: installer-6-XXXXXX0.1878c1d6854e63c6
    namespace: openshift-kube-apiserver
    resourceVersion: "26128"
    uid: 34eb9d47-84c4-4fdb-bfc8-2d93542c37e1
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-6-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "26064"
    uid: 57a7601b-4350-4598-acf4-bfac291dfdad
  kind: Event
  lastTimestamp: "2025-11-17T09:40:14Z"
  message: Stopping container installer
  metadata:
    creationTimestamp: "2025-11-17T09:40:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:40:14Z"
    name: installer-6-XXXXXX0.1878c1de2debe2b4
    namespace: openshift-kube-apiserver
    resourceVersion: "27000"
    uid: cfd28591-dc69-44ce-8e99-3333dd2fa899
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27067"
    uid: 3ae63562-b7eb-40d5-8e1e-7b8e061c1af1
  kind: Event
  lastTimestamp: "2025-11-17T09:40:22Z"
  message: Add eth0 [10.130.0.30/23 fd02:0:0:3::1e/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:40:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:40:22Z"
    name: installer-7-XXXXXX0.1878c1e004e0cc30
    namespace: openshift-kube-apiserver
    resourceVersion: "27098"
    uid: c3f5756c-feaf-460b-ad45-30092fcb7b7f
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27064"
    uid: 3ae63562-b7eb-40d5-8e1e-7b8e061c1af1
  kind: Event
  lastTimestamp: "2025-11-17T09:40:22Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:40:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:40:22Z"
    name: installer-7-XXXXXX0.1878c1e007a522d1
    namespace: openshift-kube-apiserver
    resourceVersion: "27100"
    uid: dbb3fdcd-a1e5-4a94-a4e3-a21cc03c6fcf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27064"
    uid: 3ae63562-b7eb-40d5-8e1e-7b8e061c1af1
  kind: Event
  lastTimestamp: "2025-11-17T09:40:22Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:40:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:40:22Z"
    name: installer-7-XXXXXX0.1878c1e01d6941f9
    namespace: openshift-kube-apiserver
    resourceVersion: "27107"
    uid: ba8ae6a9-182d-403c-9f29-5fcb3b577359
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:40:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27064"
    uid: 3ae63562-b7eb-40d5-8e1e-7b8e061c1af1
  kind: Event
  lastTimestamp: "2025-11-17T09:40:22Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:40:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:40:22Z"
    name: installer-7-XXXXXX0.1878c1e01e7fd4b3
    namespace: openshift-kube-apiserver
    resourceVersion: "27108"
    uid: 6ef4b34e-700f-4285-9843-ce2e68d7ab3b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:00Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: 3ae63562-b7eb-40d5-8e1e-7b8e061c1af1
  kind: Event
  lastTimestamp: "2025-11-17T09:41:00Z"
  message: Successfully installed revision 7
  metadata:
    creationTimestamp: "2025-11-17T09:41:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:41:00Z"
    name: installer-7-XXXXXX0.1878c1e8dd8e71c6
    namespace: openshift-kube-apiserver
    resourceVersion: "27583"
    uid: e75d2169-5bba-4ed5-a956-f4ceb5ef0d31
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:02Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "29563"
    uid: dd778436-0f7e-4d38-b49e-1ed82c397133
  kind: Event
  lastTimestamp: "2025-11-17T09:45:02Z"
  message: Add eth0 [10.128.0.74/23 fd02:0:0:1::4a/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:45:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:45:02Z"
    name: installer-7-XXXXXX1.1878c2215b1e2fb4
    namespace: openshift-kube-apiserver
    resourceVersion: "29585"
    uid: 9df6b3ba-b494-4ca3-94d8-dda6994d2999
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:02Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "29560"
    uid: dd778436-0f7e-4d38-b49e-1ed82c397133
  kind: Event
  lastTimestamp: "2025-11-17T09:45:02Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:45:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:02Z"
    name: installer-7-XXXXXX1.1878c2215ca7e616
    namespace: openshift-kube-apiserver
    resourceVersion: "29587"
    uid: 5575d309-ee1e-40f8-a7a7-fcb006ca96a5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "29560"
    uid: dd778436-0f7e-4d38-b49e-1ed82c397133
  kind: Event
  lastTimestamp: "2025-11-17T09:45:03Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:45:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:03Z"
    name: installer-7-XXXXXX1.1878c2217b548930
    namespace: openshift-kube-apiserver
    resourceVersion: "29591"
    uid: e373cc79-203d-4fe8-8164-a17fb8cbf5bd
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:03Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "29560"
    uid: dd778436-0f7e-4d38-b49e-1ed82c397133
  kind: Event
  lastTimestamp: "2025-11-17T09:45:03Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:45:03Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:03Z"
    name: installer-7-XXXXXX1.1878c2217cb327d6
    namespace: openshift-kube-apiserver
    resourceVersion: "29593"
    uid: a45a0a85-03c8-4e52-888d-db529685233f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: dd778436-0f7e-4d38-b49e-1ed82c397133
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Successfully installed revision 7
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: installer-7-XXXXXX1.1878c22a37bedd8d
    namespace: openshift-kube-apiserver
    resourceVersion: "29837"
    uid: 71ae97b6-3442-44be-b12b-f28c006c3583
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:56Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "28240"
    uid: f1d14f45-3db6-4283-a756-c7af44b4bf8e
  kind: Event
  lastTimestamp: "2025-11-17T09:41:56Z"
  message: Add eth0 [10.129.0.79/23 fd02:0:0:2::4f/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:41:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:41:56Z"
    name: installer-7-XXXXXX2.1878c1f5f42f4fda
    namespace: openshift-kube-apiserver
    resourceVersion: "28253"
    uid: b840956e-a614-415d-a106-c5b68d0373ea
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "28237"
    uid: f1d14f45-3db6-4283-a756-c7af44b4bf8e
  kind: Event
  lastTimestamp: "2025-11-17T09:41:56Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:56Z"
    name: installer-7-XXXXXX2.1878c1f5f5cf156f
    namespace: openshift-kube-apiserver
    resourceVersion: "28255"
    uid: 9b40fccb-6c55-41fb-a7a6-17e4da5b17fd
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "28237"
    uid: f1d14f45-3db6-4283-a756-c7af44b4bf8e
  kind: Event
  lastTimestamp: "2025-11-17T09:41:56Z"
  message: Created container installer
  metadata:
    creationTimestamp: "2025-11-17T09:41:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:56Z"
    name: installer-7-XXXXXX2.1878c1f61167c6a1
    namespace: openshift-kube-apiserver
    resourceVersion: "28262"
    uid: 694fdc86-16e4-4993-8c54-d170c7fbd7f4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:56Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{installer}
    kind: Pod
    name: installer-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "28237"
    uid: f1d14f45-3db6-4283-a756-c7af44b4bf8e
  kind: Event
  lastTimestamp: "2025-11-17T09:41:56Z"
  message: Started container installer
  metadata:
    creationTimestamp: "2025-11-17T09:41:56Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:56Z"
    name: installer-7-XXXXXX2.1878c1f612843b68
    namespace: openshift-kube-apiserver
    resourceVersion: "28264"
    uid: b66f4e91-7e97-417b-806e-f675a25d9b2d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:34Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: installer-7-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: f1d14f45-3db6-4283-a756-c7af44b4bf8e
  kind: Event
  lastTimestamp: "2025-11-17T09:42:34Z"
  message: Successfully installed revision 7
  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:42:34Z"
    name: installer-7-XXXXXX2.1878c1fed385705c
    namespace: openshift-kube-apiserver
    resourceVersion: "28611"
    uid: bfc5dfca-8758-41cc-82fd-d97e7202b54a
  reason: StaticPodInstallerCompleted
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: static-pod-installer
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:07Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27650"
    uid: cac4c486-64f2-4727-822e-6798f9d44618
  kind: Event
  lastTimestamp: "2025-11-17T09:41:07Z"
  message: Add eth0 [10.130.0.33/23 fd02:0:0:3::21/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:41:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:41:07Z"
    name: kube-apiserver-guard-XXXXXX0.1878c1eab6c939cb
    namespace: openshift-kube-apiserver
    resourceVersion: "27677"
    uid: c2cfca00-d07c-47cc-95ce-73b3464057a3
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27646"
    uid: cac4c486-64f2-4727-822e-6798f9d44618
  kind: Event
  lastTimestamp: "2025-11-17T09:41:07Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:07Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:07Z"
    name: kube-apiserver-guard-XXXXXX0.1878c1eab7fcb514
    namespace: openshift-kube-apiserver
    resourceVersion: "27681"
    uid: b0f5a3a8-659c-4dca-88f3-383c20e06906
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27646"
    uid: cac4c486-64f2-4727-822e-6798f9d44618
  kind: Event
  lastTimestamp: "2025-11-17T09:41:08Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2025-11-17T09:41:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:08Z"
    name: kube-apiserver-guard-XXXXXX0.1878c1eabf242e45
    namespace: openshift-kube-apiserver
    resourceVersion: "27685"
    uid: 96c8762f-00da-4954-bd7f-bccadb874d01
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:08Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "27646"
    uid: cac4c486-64f2-4727-822e-6798f9d44618
  kind: Event
  lastTimestamp: "2025-11-17T09:41:08Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2025-11-17T09:41:08Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:08Z"
    name: kube-apiserver-guard-XXXXXX0.1878c1eac0154805
    namespace: openshift-kube-apiserver
    resourceVersion: "27686"
    uid: 177290ab-517c-4e3e-9296-ba86d8613f91
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:49Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12889"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:23:49Z"
  message: Add eth0 [10.128.0.38/23 fd02:0:0:1::26/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:23:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:23:49Z"
    name: kube-apiserver-guard-XXXXXX1.1878c0f8e447c597
    namespace: openshift-kube-apiserver
    resourceVersion: "12962"
    uid: 3b7cd650-b038-49de-b795-1a10a3648b93
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:49Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:23:49Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:49Z"
    name: kube-apiserver-guard-XXXXXX1.1878c0f8e58a91f0
    namespace: openshift-kube-apiserver
    resourceVersion: "12964"
    uid: ac325d72-2cf5-4b04-8f04-630bed3ee920
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:49Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:23:49Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2025-11-17T09:23:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:49Z"
    name: kube-apiserver-guard-XXXXXX1.1878c0f8ed2f68a9
    namespace: openshift-kube-apiserver
    resourceVersion: "12965"
    uid: df69ef4c-d1bf-445b-8049-aafb9a8fc92b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:49Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:23:49Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2025-11-17T09:23:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:49Z"
    name: kube-apiserver-guard-XXXXXX1.1878c0f8ee1944a0
    namespace: openshift-kube-apiserver
    resourceVersion: "12966"
    uid: 61f88df5-fd47-423d-84a0-0b7108db4169
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 8
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:26:17Z"
  message: "Readiness probe error: Get \"https://XXXXXXXXXXX:6443/readyz\": net/http:
    request canceled (Client.Timeout exceeded while awaiting headers)\nbody: \n"
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-guard-XXXXXX1.1878c10fb0775819
    namespace: openshift-kube-apiserver
    resourceVersion: "14748"
    uid: ba9d0a66-b63b-45e0-b502-1434afa16a04
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 8
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:26:17Z"
  message: 'Readiness probe failed: Get "https://XXXXXXXXXXX:6443/readyz": net/http:
    request canceled (Client.Timeout exceeded while awaiting headers)'
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-guard-XXXXXX1.1878c10fb077dd99
    namespace: openshift-kube-apiserver
    resourceVersion: "14749"
    uid: 243ea322-529b-4b09-8ed7-f016b28b34c7
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:25:52Z"
  message: "Readiness probe error: Get \"https://XXXXXXXXXXX:6443/readyz\": context
    deadline exceeded\nbody: \n"
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-guard-XXXXXX1.1878c11204c11fed
    namespace: openshift-kube-apiserver
    resourceVersion: "14725"
    uid: ccabee85-8952-4a7f-b169-b4ac9a817f6a
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:37Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:25:52Z"
  message: 'Readiness probe failed: Get "https://XXXXXXXXXXX:6443/readyz": context
    deadline exceeded'
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-guard-XXXXXX1.1878c11204c1bfa3
    namespace: openshift-kube-apiserver
    resourceVersion: "14726"
    uid: c1da9b4a-edcc-4a65-9533-e6c00bb3abef
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:26:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:26:07Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-guard-XXXXXX1.1878c119019c4381
    namespace: openshift-kube-apiserver
    resourceVersion: "14744"
    uid: 4097221c-e99f-467a-b860-b6bf5eae6a0d
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 40
  eventTime: null
  firstTimestamp: "2025-11-17T09:26:07Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:45:42Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:42Z"
    name: kube-apiserver-guard-XXXXXX1.1878c119019cb25e
    namespace: openshift-kube-apiserver
    resourceVersion: "29846"
    uid: af430dbd-8c8e-49c0-8204-97f1aea257cb
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 5
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "12884"
    uid: 49a440fa-cb37-4137-9a1b-02ef07095cf8
  kind: Event
  lastTimestamp: "2025-11-17T09:45:42Z"
  message: |+
    (combined from similar events): Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:33:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:42Z"
    name: kube-apiserver-guard-XXXXXX1.1878c1854506edf3
    namespace: openshift-kube-apiserver
    resourceVersion: "29845"
    uid: 166c393c-2f9c-4c0a-bf32-3567dbdb7f6a
  reason: ProbeError
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:21Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15966"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:30:21Z"
  message: Add eth0 [10.129.0.58/23 fd02:0:0:2::3a/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:30:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:30:21Z"
    name: kube-apiserver-guard-XXXXXX2.1878c154488ebd4f
    namespace: openshift-kube-apiserver
    resourceVersion: "16000"
    uid: 9e8ee67f-eb3f-449a-88ff-c72dc2db4898
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:21Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:30:21Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:30:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:21Z"
    name: kube-apiserver-guard-XXXXXX2.1878c1544b1bf088
    namespace: openshift-kube-apiserver
    resourceVersion: "16005"
    uid: 3f855ed5-9348-44d7-86d1-ac5d30e74afa
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:30:22Z"
  message: Created container guard
  metadata:
    creationTimestamp: "2025-11-17T09:30:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:22Z"
    name: kube-apiserver-guard-XXXXXX2.1878c15454fe6d6c
    namespace: openshift-kube-apiserver
    resourceVersion: "16006"
    uid: 66244ab1-87c4-44a3-9d37-06a20196abb7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:30:22Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:30:22Z"
  message: Started container guard
  metadata:
    creationTimestamp: "2025-11-17T09:30:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:30:22Z"
    name: kube-apiserver-guard-XXXXXX2.1878c154562e7158
    namespace: openshift-kube-apiserver
    resourceVersion: "16007"
    uid: ceb78282-c195-4e81-abb5-ee3985f5d79d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:31:54Z"
  message: "Readiness probe error: Get \"https://XXXXXXXXXXX:6443/readyz\": net/http:
    request canceled (Client.Timeout exceeded while awaiting headers)\nbody: \n"
  metadata:
    creationTimestamp: "2025-11-17T09:33:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-apiserver-guard-XXXXXX2.1878c15f72158d7d
    namespace: openshift-kube-apiserver
    resourceVersion: "19237"
    uid: d13b6c9d-aa63-4500-acd0-aefcf851a689
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 7
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:09Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:31:54Z"
  message: 'Readiness probe failed: Get "https://XXXXXXXXXXX:6443/readyz": net/http:
    request canceled (Client.Timeout exceeded while awaiting headers)'
  metadata:
    creationTimestamp: "2025-11-17T09:33:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-apiserver-guard-XXXXXX2.1878c15f721648b8
    namespace: openshift-kube-apiserver
    resourceVersion: "19238"
    uid: acce7bf7-65c5-4397-b38f-6aed8cb75651
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:35:24Z"
  message: "Readiness probe error: Get \"https://XXXXXXXXXXX:6443/readyz\": context
    deadline exceeded\nbody: \n"
  metadata:
    creationTimestamp: "2025-11-17T09:33:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:23Z"
    name: kube-apiserver-guard-XXXXXX2.1878c1609c2261d1
    namespace: openshift-kube-apiserver
    resourceVersion: "21471"
    uid: 81d66a12-ecc6-4ae4-a4fa-b9afd533dbc1
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:14Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:31:44Z"
  message: 'Readiness probe failed: Get "https://XXXXXXXXXXX:6443/readyz": context
    deadline exceeded'
  metadata:
    creationTimestamp: "2025-11-17T09:33:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-apiserver-guard-XXXXXX2.1878c1609c2306d2
    namespace: openshift-kube-apiserver
    resourceVersion: "19234"
    uid: 372f1c92-9006-4c11-8e93-e43e2a0b0656
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:31:24Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:33:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-apiserver-guard-XXXXXX2.1878c162f114e190
    namespace: openshift-kube-apiserver
    resourceVersion: "19202"
    uid: 9b4d883c-abd8-40b0-a51e-f403591879ab
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:31:24Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2025-11-17T09:33:02Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:02Z"
    name: kube-apiserver-guard-XXXXXX2.1878c162f1155c15
    namespace: openshift-kube-apiserver
    resourceVersion: "19203"
    uid: 81fd7586-82d8-41d6-85c7-ee952eb6aa8f
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:32:49Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{guard}
    kind: Pod
    name: kube-apiserver-guard-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "15959"
    uid: d715cefd-d89a-4f6b-8356-a7313956fc8b
  kind: Event
  lastTimestamp: "2025-11-17T09:42:34Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [-]shutdown failed: reason withheld
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:42:34Z"
    name: kube-apiserver-guard-XXXXXX2.1878c176bad8099e
    namespace: openshift-kube-apiserver
    resourceVersion: "28614"
    uid: 9a1c4251-8534-4f41-a2d3-0405366eb26b
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-11-17T09:20:28Z"
  involvedObject:
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    name: kube-apiserver-guard-pdb
    namespace: openshift-kube-apiserver
    resourceVersion: "6988"
    uid: 296957f9-f4a6-4127-b36b-4c70944f13a8
  kind: Event
  lastTimestamp: "2025-11-17T09:20:28Z"
  message: No matching pods found
  metadata:
    creationTimestamp: "2025-11-17T09:20:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-11-17T09:20:28Z"
    name: kube-apiserver-guard-pdb.1878c0ca156409a8
    namespace: openshift-kube-apiserver
    resourceVersion: "6993"
    uid: 29914987-b34c-4cba-8ccf-f5e848e1519d
  reason: NoPods
  reportingComponent: controllermanager
  reportingInstance: ""
  source:
    component: controllermanager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:00Z"
    name: kube-apiserver-XXXXXX0.1878c1e8f1c565b5
    namespace: openshift-kube-apiserver
    resourceVersion: "27584"
    uid: 3d5ee82e-2c4a-4b70-b3db-9053c4cded46
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:00Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:41:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:00Z"
    name: kube-apiserver-XXXXXX0.1878c1e8fac72090
    namespace: openshift-kube-apiserver
    resourceVersion: "27585"
    uid: c1198c11-6963-4083-a097-2864f4869c0c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:00Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:41:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:00Z"
    name: kube-apiserver-XXXXXX0.1878c1e8fbc4bf2a
    namespace: openshift-kube-apiserver
    resourceVersion: "27586"
    uid: 61b5efd6-8eee-4d3a-89f7-b537f9945f27
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e92047fe5d
    namespace: openshift-kube-apiserver
    resourceVersion: "27594"
    uid: 368998e7-5e25-4c3e-af01-49a3f66e9b61
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e92a5ab7f8
    namespace: openshift-kube-apiserver
    resourceVersion: "27599"
    uid: 4ad95f26-ff68-4a87-9d0d-d09ef061ef39
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e92b4980de
    namespace: openshift-kube-apiserver
    resourceVersion: "27600"
    uid: 0123d809-504a-4bd9-8bdd-681516cd53c2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e92b55250e
    namespace: openshift-kube-apiserver
    resourceVersion: "27601"
    uid: 878d007f-3d87-4b10-b258-289f906ff852
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e932f95fe1
    namespace: openshift-kube-apiserver
    resourceVersion: "27602"
    uid: ac25adc4-730d-495f-a434-b513dbd1fcf7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e933e00e49
    namespace: openshift-kube-apiserver
    resourceVersion: "27603"
    uid: 64b1865b-7b8d-459b-9091-4f1434fc1b49
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e933f015d3
    namespace: openshift-kube-apiserver
    resourceVersion: "27604"
    uid: cc28ab21-03d1-4eae-b1d2-e129c0dc3741
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e93b2b08c4
    namespace: openshift-kube-apiserver
    resourceVersion: "27605"
    uid: bc3db26b-c4c9-4dfb-9428-7aaa7ca11bf0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e93c0ec012
    namespace: openshift-kube-apiserver
    resourceVersion: "27606"
    uid: daf0b9d8-8e6f-4586-a781-bec65e80915e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e93c1cd712
    namespace: openshift-kube-apiserver
    resourceVersion: "27607"
    uid: ea7ebea0-2edf-4c66-98e8-3e0786a28c50
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e9438ea602
    namespace: openshift-kube-apiserver
    resourceVersion: "27608"
    uid: ee1415e9-88bb-4bbe-bae1-5a8b0d78b62d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e9446524af
    namespace: openshift-kube-apiserver
    resourceVersion: "27609"
    uid: 62c2ab67-5902-4e48-ac84-16c5f4116eb6
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e9447417e9
    namespace: openshift-kube-apiserver
    resourceVersion: "27610"
    uid: 2ce8fa99-0864-4813-aa3a-03d5026a4a93
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e94c11eb09
    namespace: openshift-kube-apiserver
    resourceVersion: "27611"
    uid: e26a9867-95ae-4fc5-b659-980740195e03
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:41:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
    uid: c7dd9c0e2a21771bf80b70bae4f102a6
  kind: Event
  lastTimestamp: "2025-11-17T09:41:01Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:41:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:41:01Z"
    name: kube-apiserver-XXXXXX0.1878c1e94d05c1ad
    namespace: openshift-kube-apiserver
    resourceVersion: "27612"
    uid: 7513baf8-5e17-474f-8bd8-fdcc60f40955
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX0
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:41:04Z"
    name: kube-apiserver-XXXXXX0.1878c1e9f319425a
    namespace: openshift-kube-apiserver
    resourceVersion: "27629"
    uid: 59d1a125-3bd2-4778-b8a4-5d047d26a815
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX0
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:42Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:42Z"
    name: kube-apiserver-XXXXXX1.1878c0f73c9bba98
    namespace: openshift-kube-apiserver
    resourceVersion: "12783"
    uid: 5d691eb9-e790-4871-b6db-e12a7b9bd733
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:42Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:23:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:42Z"
    name: kube-apiserver-XXXXXX1.1878c0f745a60700
    namespace: openshift-kube-apiserver
    resourceVersion: "12784"
    uid: 7a59a182-d7ae-4080-8e88-6669638cd8ba
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:42Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:23:42Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:42Z"
    name: kube-apiserver-XXXXXX1.1878c0f746791f64
    namespace: openshift-kube-apiserver
    resourceVersion: "12785"
    uid: 99ebf705-cdd7-4938-a147-326e63633b2b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f7745d27de
    namespace: openshift-kube-apiserver
    resourceVersion: "12791"
    uid: 2b0994a4-6ff6-40ad-9c46-4d82a11d4084
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f7823fdb27
    namespace: openshift-kube-apiserver
    resourceVersion: "12796"
    uid: eeb5a8e3-c45d-4bb7-87bd-b7609c205f00
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f78388534f
    namespace: openshift-kube-apiserver
    resourceVersion: "12797"
    uid: 50f39f8f-5a80-4fa9-9247-2fab3765f4ce
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f7839562be
    namespace: openshift-kube-apiserver
    resourceVersion: "12798"
    uid: 4429d2bf-2d26-4a71-9285-d3cdfff53a15
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f78b853de5
    namespace: openshift-kube-apiserver
    resourceVersion: "12800"
    uid: c46c8502-7770-4e5d-a53c-25ec324912bf
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f78c6c6229
    namespace: openshift-kube-apiserver
    resourceVersion: "12801"
    uid: 1c9dde30-1dfb-4f2c-80b3-f53654f19052
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f78c7547da
    namespace: openshift-kube-apiserver
    resourceVersion: "12802"
    uid: 219f1eb6-d827-43dd-8c6f-f3a875bf74f8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f793d26f5c
    namespace: openshift-kube-apiserver
    resourceVersion: "12804"
    uid: c42d3b6f-2919-499b-9efe-9f5643265234
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f794b798b5
    namespace: openshift-kube-apiserver
    resourceVersion: "12805"
    uid: b671bd66-37e3-463a-9198-f428d74abf88
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f794c1cc53
    namespace: openshift-kube-apiserver
    resourceVersion: "12806"
    uid: dd3f7999-b35f-4411-88de-e8593195c143
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f79d2e07cf
    namespace: openshift-kube-apiserver
    resourceVersion: "12807"
    uid: 0fe9de41-7b9a-40d6-8c27-637cbd39f58d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f79e236c47
    namespace: openshift-kube-apiserver
    resourceVersion: "12808"
    uid: 0b3ba463-d28f-467e-855b-957e9adb75df
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:43Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:23:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:43Z"
    name: kube-apiserver-XXXXXX1.1878c0f79e40002c
    namespace: openshift-kube-apiserver
    resourceVersion: "12809"
    uid: df386876-d238-4ccf-aa03-bd03b8c0df13
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:44Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:23:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:44Z"
    name: kube-apiserver-XXXXXX1.1878c0f7a7bdde0c
    namespace: openshift-kube-apiserver
    resourceVersion: "12812"
    uid: b31d8a7e-012c-424b-9d47-78d7e399bcca
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:23:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:23:44Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:23:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:23:44Z"
    name: kube-apiserver-XXXXXX1.1878c0f7a8dc4427
    namespace: openshift-kube-apiserver
    resourceVersion: "12813"
    uid: fbd6592c-72ec-47e4-af56-5e4326085494
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:23:46Z"
    name: kube-apiserver-XXXXXX1.1878c0f844629d29
    namespace: openshift-kube-apiserver
    resourceVersion: "12880"
    uid: 293faf47-bc14-4d22-bbc2-725aa2126daa
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:25:31Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [+]shutdown ok
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-XXXXXX1.1878c1109d1aec60
    namespace: openshift-kube-apiserver
    resourceVersion: "14695"
    uid: 0a182921-27e2-4c3d-86de-42089085c93d
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:25:31Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-XXXXXX1.1878c1109d1ba619
    namespace: openshift-kube-apiserver
    resourceVersion: "14696"
    uid: af38b9bd-e0b4-4637-945e-4e7d5fdaabb3
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:32Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:25:32Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [-]etcd-readiness failed: reason withheld
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [+]shutdown ok
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:27:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:23Z"
    name: kube-apiserver-XXXXXX1.1878c110d95ce2b9
    namespace: openshift-kube-apiserver
    resourceVersion: "14699"
    uid: 01e9c683-d2c3-4c05-be41-196f010803c7
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 1m10s finished
  metadata:
    creationTimestamp: "2025-11-17T09:27:14Z"
    name: kube-apiserver-XXXXXX1.1878c128990952a0
    namespace: openshift-kube-apiserver
    resourceVersion: "14252"
    uid: 8bf1a5c4-9999-4b6d-aab8-e76faa1a6750
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2025-11-17T09:27:14Z"
    name: kube-apiserver-XXXXXX1.1878c128998df368
    namespace: openshift-kube-apiserver
    resourceVersion: "14253"
    uid: 79904f0c-9667-4813-b3ec-7f34f90a2e61
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:27:15Z"
    name: kube-apiserver-XXXXXX1.1878c128eaa8fb7e
    namespace: openshift-kube-apiserver
    resourceVersion: "14322"
    uid: f3321042-7ab9-43d4-9954-7fd2d94c20c3
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:27:17Z"
    name: kube-apiserver-XXXXXX1.1878c12961e715d7
    namespace: openshift-kube-apiserver
    resourceVersion: "14554"
    uid: 63e1e3a3-41b2-401b-a3a6-d35afd82f9c4
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:27:27Z"
    name: kube-apiserver-XXXXXX1.1878c12b9edd1112
    namespace: openshift-kube-apiserver
    resourceVersion: "14805"
    uid: e4c63b71-8334-4ab6-a95b-cf4aa11e0b75
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:31:06Z"
  message: |+
    Readiness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [+]etcd-readiness ok
    [+]api-openshift-apiserver-available ok
    [+]api-openshift-oauth-apiserver-available ok
    [+]informer-sync ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    [+]shutdown ok
    readyz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:33:05Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:05Z"
    name: kube-apiserver-XXXXXX1.1878c15e9cd063e9
    namespace: openshift-kube-apiserver
    resourceVersion: "19353"
    uid: 0420e833-9048-4349-a5e4-9e8982733b13
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2025-11-17T09:32:47Z"
    name: kube-apiserver-XXXXXX1.1878c17621a0c33c
    namespace: openshift-kube-apiserver
    resourceVersion: "18980"
    uid: da08a749-8f15-4283-a44f-5e1e8234d11d
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:32:52Z"
    name: kube-apiserver-XXXXXX1.1878c17740f56058
    namespace: openshift-kube-apiserver
    resourceVersion: "19038"
    uid: ef458634-534a-464e-aa67-7fde0f0ca21a
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:32:53Z"
    name: kube-apiserver-XXXXXX1.1878c177813e1080
    namespace: openshift-kube-apiserver
    resourceVersion: "19042"
    uid: edcf2818-68d1-4bc2-8d38-23b744ff877c
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:33:00Z"
    name: kube-apiserver-XXXXXX1.1878c17945a290c1
    namespace: openshift-kube-apiserver
    resourceVersion: "19119"
    uid: 5b4b1284-f276-4bfa-8ec7-d125d0601749
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:33:49Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: 32080a7ec005920b5f0ae25128e61693
  kind: Event
  lastTimestamp: "2025-11-17T09:33:49Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:33:49Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:49Z"
    name: kube-apiserver-XXXXXX1.1878c1849bcc9a8d
    namespace: openshift-kube-apiserver
    resourceVersion: "20347"
    uid: b028c722-dc85-4961-b110-501a3358d1ec
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2025-11-17T09:33:49Z"
    name: kube-apiserver-XXXXXX1.1878c1849c826ff5
    namespace: openshift-kube-apiserver
    resourceVersion: "20349"
    uid: a1d28df7-3e4c-4d89-932f-f7f6c431b8d3
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2025-11-17T09:33:49Z"
    name: kube-apiserver-XXXXXX1.1878c1849d6e1489
    namespace: openshift-kube-apiserver
    resourceVersion: "20353"
    uid: 5821339d-79a4-4265-89a7-7e43ca994276
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:36:01Z"
    name: kube-apiserver-XXXXXX1.1878c1a35a5679ed
    namespace: openshift-kube-apiserver
    resourceVersion: "21069"
    uid: 2f656b6c-686a-4fff-9fda-00596eafa212
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:36:02Z"
    name: kube-apiserver-XXXXXX1.1878c1a398a75559
    namespace: openshift-kube-apiserver
    resourceVersion: "21122"
    uid: 3992c32b-d660-4d29-892b-9faecd666664
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:12Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a5e6476b78
    namespace: openshift-kube-apiserver
    resourceVersion: "21530"
    uid: c6ac5831-b13e-44b5-851f-266a58b44197
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:12Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a5f0edf8f8
    namespace: openshift-kube-apiserver
    resourceVersion: "21531"
    uid: a9fa737c-6415-40fc-9487-9354082550f4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:12Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:12Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a5f23d8ac3
    namespace: openshift-kube-apiserver
    resourceVersion: "21532"
    uid: 531d3f33-0c4d-489b-9f3f-755711b1bc72
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a682847a3c
    namespace: openshift-kube-apiserver
    resourceVersion: "21533"
    uid: 7005af6a-115e-4cd8-83ea-bde7a15c9539
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a68d2856d0
    namespace: openshift-kube-apiserver
    resourceVersion: "21534"
    uid: acd943f2-27f0-4eca-ada3-9cec1e01834b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a68e7335eb
    namespace: openshift-kube-apiserver
    resourceVersion: "21535"
    uid: 7d36607a-f225-421b-a95c-aa41364742d5
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a68e81db48
    namespace: openshift-kube-apiserver
    resourceVersion: "21536"
    uid: b8f894ab-36ba-4707-8ef7-6ded5bbd7bab
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a696146865
    namespace: openshift-kube-apiserver
    resourceVersion: "21537"
    uid: e6a53b37-013f-43d9-b323-1384e4ade882
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a69713e584
    namespace: openshift-kube-apiserver
    resourceVersion: "21538"
    uid: 1eea3779-eacd-4039-bb1e-cf37f47d9872
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6971e4f70
    namespace: openshift-kube-apiserver
    resourceVersion: "21539"
    uid: 4fffb52c-26d1-4453-8e10-4946353432f8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a69ee40573
    namespace: openshift-kube-apiserver
    resourceVersion: "21540"
    uid: 55d58158-344b-4a0e-b0a3-9d03a15c8239
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a69fcbfe81
    namespace: openshift-kube-apiserver
    resourceVersion: "21541"
    uid: ee413085-dd2e-4b7f-a80d-d41b68fd4eb2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a69fd8158f
    namespace: openshift-kube-apiserver
    resourceVersion: "21542"
    uid: fe2b5d39-47ef-4878-aa94-33cdaa7388fa
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6a9bb7c50
    namespace: openshift-kube-apiserver
    resourceVersion: "21543"
    uid: 94167fa7-771a-4228-912d-1a895fddcba4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6aaae3cd7
    namespace: openshift-kube-apiserver
    resourceVersion: "21544"
    uid: e1843ab5-13b1-4daf-9aa2-6650f6916057
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6aabd284c
    namespace: openshift-kube-apiserver
    resourceVersion: "21545"
    uid: 72697c14-a695-48cb-b77a-fbeb456d055e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6b1f8bcf0
    namespace: openshift-kube-apiserver
    resourceVersion: "21546"
    uid: 7e7ae0c3-2eb6-4c38-b401-ff9cf25ea96c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:15Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:15Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a6b2e21ce5
    namespace: openshift-kube-apiserver
    resourceVersion: "21547"
    uid: b419f2bc-0d62-4f90-89a2-f1c38a97e6f4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:17Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:17Z"
  message: |+
    Startup probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [+]etcd ok
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [-]poststarthook/rbac/bootstrap-roles failed: reason withheld
    [-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    healthz check failed

  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a70f9d9a56
    namespace: openshift-kube-apiserver
    resourceVersion: "21548"
    uid: 55ee2ebd-3640-4be6-960a-f6f5058381d9
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:17Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:36:17Z"
  message: 'Startup probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2025-11-17T09:36:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:36:25Z"
    name: kube-apiserver-XXXXXX1.1878c1a70f9e02a4
    namespace: openshift-kube-apiserver
    resourceVersion: "21549"
    uid: f2f4193e-9c60-4f95-a32f-0e4588272a5f
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:36:18Z"
    name: kube-apiserver-XXXXXX1.1878c1a75636678d
    namespace: openshift-kube-apiserver
    resourceVersion: "21337"
    uid: 3b641078-c4bc-4030-bbe4-4db22b003d3e
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a37ca38b5
    namespace: openshift-kube-apiserver
    resourceVersion: "29821"
    uid: ad061942-4683-4106-92d6-b17621744822
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a37ca9cb3
    namespace: openshift-kube-apiserver
    resourceVersion: "29822"
    uid: 76baf79f-dbf1-464f-8d77-87269e360dd8
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Stopping container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a37caadf2
    namespace: openshift-kube-apiserver
    resourceVersion: "29825"
    uid: 181b338f-b3da-4f7a-bcf5-ff4fd6ae2191
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Stopping container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a37cb5a90
    namespace: openshift-kube-apiserver
    resourceVersion: "29826"
    uid: 0d414c76-40d7-4b24-87c6-b5b15e6903c2
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:45:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e5f03e12d74c33bdba3d6061c0cfbc50
  kind: Event
  lastTimestamp: "2025-11-17T09:45:40Z"
  message: Stopping container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a37cb76b9
    namespace: openshift-kube-apiserver
    resourceVersion: "29828"
    uid: 79f1698c-0af4-4304-88c4-faad3667876a
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a387fe49e
    namespace: openshift-kube-apiserver
    resourceVersion: "29824"
    uid: 71d7178a-7671-4731-bc67-1bcadb5aa119
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2025-11-17T09:45:40Z"
    name: kube-apiserver-XXXXXX1.1878c22a39aac11c
    namespace: openshift-kube-apiserver
    resourceVersion: "29830"
    uid: 0df7ce11-750d-473b-bb01-8573724643f9
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 1m10s finished
  metadata:
    creationTimestamp: "2025-11-17T09:46:50Z"
    name: kube-apiserver-XXXXXX1.1878c23a853a2f9b
    namespace: openshift-kube-apiserver
    resourceVersion: "30265"
    uid: b36108cd-87e1-456e-a59f-bbb8f51b1427
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2025-11-17T09:46:50Z"
    name: kube-apiserver-XXXXXX1.1878c23a8579d1be
    namespace: openshift-kube-apiserver
    resourceVersion: "30266"
    uid: 0b4c7b0d-e27c-4310-9aff-3d7293fd8e28
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:46:50Z"
    name: kube-apiserver-XXXXXX1.1878c23a858347af
    namespace: openshift-kube-apiserver
    resourceVersion: "30267"
    uid: 030b4d4c-abbe-4599-b1d0-89255213258a
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:46:52Z"
    name: kube-apiserver-XXXXXX1.1878c23afcc402ef
    namespace: openshift-kube-apiserver
    resourceVersion: "30282"
    uid: 9cc6f5c1-32fc-41a1-9347-0a9eac249d1b
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23caf5917b1
    namespace: openshift-kube-apiserver
    resourceVersion: "30388"
    uid: 6534972a-c24f-4af6-9379-b2402e0476bf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23cbd525861
    namespace: openshift-kube-apiserver
    resourceVersion: "30389"
    uid: f762a75a-64d6-439b-972c-819dc6a8fe20
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23cbebe05f4
    namespace: openshift-kube-apiserver
    resourceVersion: "30390"
    uid: f1a4b11e-afa1-480e-ad90-de70d9f077a3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23cd7828cb4
    namespace: openshift-kube-apiserver
    resourceVersion: "30393"
    uid: f866294e-0138-484f-9f7d-46dec38526b6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23ce3a483a2
    namespace: openshift-kube-apiserver
    resourceVersion: "30397"
    uid: cbfdf6d2-d6e7-4d60-9405-f8fa4d5e3ffc
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23ce5027323
    namespace: openshift-kube-apiserver
    resourceVersion: "30398"
    uid: 79618304-2989-44b1-b5b2-06469eac0bb9
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:00Z"
    name: kube-apiserver-XXXXXX1.1878c23ce51c0427
    namespace: openshift-kube-apiserver
    resourceVersion: "30400"
    uid: bbdbc5ec-1366-4bac-80c2-986592fd2755
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cf0b14db2
    namespace: openshift-kube-apiserver
    resourceVersion: "30401"
    uid: 348d1eda-8ec4-4f1a-914c-0ce714aed596
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cf1bb8551
    namespace: openshift-kube-apiserver
    resourceVersion: "30402"
    uid: 055e9dc5-5cb3-4a63-a640-976f539c5bf3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cf1cc3a61
    namespace: openshift-kube-apiserver
    resourceVersion: "30403"
    uid: 8de9f402-ebbd-4a3c-bd97-4a9d582ae16f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cfd877d71
    namespace: openshift-kube-apiserver
    resourceVersion: "30405"
    uid: 521e8a3a-d2b0-4f4c-98da-8f87e43f5584
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cfef93740
    namespace: openshift-kube-apiserver
    resourceVersion: "30406"
    uid: da086f1b-93f9-4e49-a690-6e6eb4cf2ffe
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23cff041136
    namespace: openshift-kube-apiserver
    resourceVersion: "30407"
    uid: cd38ee9f-58cc-4bfb-a060-62548c2d9b6c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23d0a9f934d
    namespace: openshift-kube-apiserver
    resourceVersion: "30408"
    uid: 5f585fdb-b1a0-4dd0-bff0-5421118944fe
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23d0c022f86
    namespace: openshift-kube-apiserver
    resourceVersion: "30409"
    uid: a5c7a6f9-7e29-4a7b-b7a8-2f889c16826d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23d0c0d3dde
    namespace: openshift-kube-apiserver
    resourceVersion: "30410"
    uid: 82edd70c-039e-45d0-ab5b-2611a096e3b6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23d19b5e7c0
    namespace: openshift-kube-apiserver
    resourceVersion: "30411"
    uid: d36d10ff-6ac0-434d-a708-b0bfd2272e4c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
    uid: e2bfad9a12dba72480ce1ab3cd08bde2
  kind: Event
  lastTimestamp: "2025-11-17T09:47:01Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:47:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:01Z"
    name: kube-apiserver-XXXXXX1.1878c23d1bb28e67
    namespace: openshift-kube-apiserver
    resourceVersion: "30413"
    uid: 288e2fb7-e750-451b-82ff-e64c45694c27
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX1
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:47:04Z"
    name: kube-apiserver-XXXXXX1.1878c23daf225150
    namespace: openshift-kube-apiserver
    resourceVersion: "30426"
    uid: 6d1fa742-60d6-45f3-ac58-9246b7b081a8
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX1
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:27Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c10fc831f442
    namespace: openshift-kube-apiserver
    resourceVersion: "14141"
    uid: acaea5ba-3c9d-484f-9f64-4c8a93d66577
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:27Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c10fd2ab6267
    namespace: openshift-kube-apiserver
    resourceVersion: "14142"
    uid: 423bdcbc-4d6f-448d-9e22-682da29aaff9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:27Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c10fd3c66232
    namespace: openshift-kube-apiserver
    resourceVersion: "14143"
    uid: a47d2a85-db09-451b-8408-0ee1e7250dbc
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c112ee83be08
    namespace: openshift-kube-apiserver
    resourceVersion: "14161"
    uid: e5dd254f-9d96-4d27-9e4b-bb557639adfb
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c112f9092fb4
    namespace: openshift-kube-apiserver
    resourceVersion: "14168"
    uid: 9537dda7-05f0-4245-b8aa-8ea40a9798f0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c112fa0fcd41
    namespace: openshift-kube-apiserver
    resourceVersion: "14170"
    uid: a1d1d3cd-9977-4633-b8b5-4bce59491f16
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c112fa1caa64
    namespace: openshift-kube-apiserver
    resourceVersion: "14171"
    uid: b06cbb35-77ea-44a2-b053-e2fbadb575d0
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11302f5d240
    namespace: openshift-kube-apiserver
    resourceVersion: "14172"
    uid: 36786426-2ca2-4502-b0de-12c7f45627ae
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11303d9734d
    namespace: openshift-kube-apiserver
    resourceVersion: "14174"
    uid: 79981d20-ec96-4375-9b58-a154b02520a8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11303e91be4
    namespace: openshift-kube-apiserver
    resourceVersion: "14175"
    uid: a27a3828-787e-477e-8afe-e4711d6e36bd
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c1130dbf2ae3
    namespace: openshift-kube-apiserver
    resourceVersion: "14177"
    uid: 7ec61739-dfc7-4136-a35c-b6fdd1bb1cfe
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c1130ecdeb39
    namespace: openshift-kube-apiserver
    resourceVersion: "14179"
    uid: 3f619607-3390-4652-86f1-f528b6ede7b7
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c1130edb6746
    namespace: openshift-kube-apiserver
    resourceVersion: "14180"
    uid: 857d0bca-f83d-4058-8325-593c55ff4aea
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11316f6f1e2
    namespace: openshift-kube-apiserver
    resourceVersion: "14181"
    uid: 1ffbd0af-841c-4a37-a89a-5839a8c52e4f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11317e534c6
    namespace: openshift-kube-apiserver
    resourceVersion: "14183"
    uid: f6623b75-84d7-4821-895a-4db24b3581b2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11317f1a30c
    namespace: openshift-kube-apiserver
    resourceVersion: "14184"
    uid: e0d6aba0-878a-49d6-aaad-d7332128dbd3
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:41Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c1131fc56cfa
    namespace: openshift-kube-apiserver
    resourceVersion: "14185"
    uid: 92e194b5-5e53-4e7d-ae99-72f57bd4a7f4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:42Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:42Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11321af882a
    namespace: openshift-kube-apiserver
    resourceVersion: "14187"
    uid: 0b63c453-6396-4569-91c9-3eecb56cf2ff
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 4
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:57Z"
  message: |+
    Startup probe error: HTTP probe failed with statuscode: 403
    body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}

  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11372ef053f
    namespace: openshift-kube-apiserver
    resourceVersion: "14206"
    uid: 2ca09d2e-a93c-48ea-be7b-eeccf773f4b3
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-11-17T09:25:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:25:52Z"
  message: 'Startup probe failed: HTTP probe failed with statuscode: 403'
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c11372efc19e
    namespace: openshift-kube-apiserver
    resourceVersion: "14202"
    uid: a8de42dd-e1e3-47cb-b2c7-b7e41af36336
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:27:13Z"
    name: kube-apiserver-XXXXXX2.1878c1288612f14f
    namespace: openshift-kube-apiserver
    resourceVersion: "14225"
    uid: bc441c9d-03ea-47fc-880d-564730b80624
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:31:06Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:31:06Z"
  message: |+
    Liveness probe error: HTTP probe failed with statuscode: 500
    body: [+]ping ok
    [+]log ok
    [-]etcd failed: reason withheld
    [+]poststarthook/quota.openshift.io-clusterquotamapping ok
    [+]poststarthook/openshift.io-api-request-count-filter ok
    [+]poststarthook/openshift.io-startkubeinformers ok
    [+]poststarthook/openshift.io-openshift-apiserver-reachable ok
    [+]poststarthook/openshift.io-oauth-apiserver-reachable ok
    [+]poststarthook/start-kube-apiserver-admission-initializer ok
    [+]poststarthook/generic-apiserver-start-informers ok
    [+]poststarthook/priority-and-fairness-config-consumer ok
    [+]poststarthook/priority-and-fairness-filter ok
    [+]poststarthook/storage-object-count-tracker-hook ok
    [+]poststarthook/start-apiextensions-informers ok
    [+]poststarthook/start-apiextensions-controllers ok
    [+]poststarthook/crd-informer-synced ok
    [+]poststarthook/start-system-namespaces-controller ok
    [+]poststarthook/bootstrap-controller ok
    [+]poststarthook/rbac/bootstrap-roles ok
    [+]poststarthook/scheduling/bootstrap-system-priority-classes ok
    [+]poststarthook/priority-and-fairness-config-producer ok
    [+]poststarthook/start-cluster-authentication-info-controller ok
    [+]poststarthook/start-kube-apiserver-identity-lease-controller ok
    [+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
    [+]poststarthook/start-legacy-token-tracking-controller ok
    [+]poststarthook/aggregator-reload-proxy-client-cert ok
    [+]poststarthook/start-kube-aggregator-informers ok
    [+]poststarthook/apiservice-registration-controller ok
    [+]poststarthook/apiservice-status-available-controller ok
    [+]poststarthook/apiservice-wait-for-first-sync ok
    [+]poststarthook/kube-apiserver-autoregistration ok
    [+]autoregister-completion ok
    [+]poststarthook/apiservice-openapi-controller ok
    [+]poststarthook/apiservice-openapiv3-controller ok
    [+]poststarthook/apiservice-discovery-controller ok
    livez check failed

  metadata:
    creationTimestamp: "2025-11-17T09:33:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:33:01Z"
    name: kube-apiserver-XXXXXX2.1878c15eb6570be8
    namespace: openshift-kube-apiserver
    resourceVersion: "19154"
    uid: 9a4bdef2-c8f5-438a-b57c-7c350bb4ff58
  reason: ProbeError
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:32:52Z"
    name: kube-apiserver-XXXXXX2.1878c17743098fdd
    namespace: openshift-kube-apiserver
    resourceVersion: "19041"
    uid: 7546cae7-57b8-4e22-b060-db5525e4813c
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:32:54Z"
    name: kube-apiserver-XXXXXX2.1878c177ba471926
    namespace: openshift-kube-apiserver
    resourceVersion: "19043"
    uid: dd96e037-f39b-48d3-b10c-8bf43779d2ce
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:32:57Z"
    name: kube-apiserver-XXXXXX2.1878c1789174267c
    namespace: openshift-kube-apiserver
    resourceVersion: "19076"
    uid: 488dce22-bb2e-4d7f-bf5e-b4933ba97566
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 1m10s finished
  metadata:
    creationTimestamp: "2025-11-17T09:36:40Z"
    name: kube-apiserver-XXXXXX2.1878c1ac7c04810a
    namespace: openshift-kube-apiserver
    resourceVersion: "21743"
    uid: 344cd39c-e9d8-45f0-830a-9227b52228ab
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2025-11-17T09:36:40Z"
    name: kube-apiserver-XXXXXX2.1878c1ac7c433425
    namespace: openshift-kube-apiserver
    resourceVersion: "21744"
    uid: 187339a5-36df-40fa-819a-e142349ed54a
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:36:40Z"
    name: kube-apiserver-XXXXXX2.1878c1ac7c516c1a
    namespace: openshift-kube-apiserver
    resourceVersion: "21745"
    uid: 49426101-3b9b-4642-b62c-1b217e9189b7
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:36:42Z"
    name: kube-apiserver-XXXXXX2.1878c1acf38daff0
    namespace: openshift-kube-apiserver
    resourceVersion: "21755"
    uid: d1aeffb2-2d5e-4b7b-bb14-515bff945f64
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:36:46Z"
    name: kube-apiserver-XXXXXX2.1878c1addf39da23
    namespace: openshift-kube-apiserver
    resourceVersion: "21782"
    uid: 2247ad42-5c36-437b-bada-07eadf4e974a
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:42:34Z"
  message: Stopping container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:42:34Z"
    name: kube-apiserver-XXXXXX2.1878c1fed398bbdb
    namespace: openshift-kube-apiserver
    resourceVersion: "28602"
    uid: 7600a71d-955c-4c21-8c1f-9d0ed8e30da3
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:42:34Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 02f06b215f889945daa2c31a12130ff1
  kind: Event
  lastTimestamp: "2025-11-17T09:42:34Z"
  message: Stopping container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:42:34Z"
    name: kube-apiserver-XXXXXX2.1878c1fed398cdcd
    namespace: openshift-kube-apiserver
    resourceVersion: "28603"
    uid: b49192ec-8cbd-4051-89dd-c6e6df01f397
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: Received signal to terminate, becoming unready, but keeping serving
  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    name: kube-apiserver-XXXXXX2.1878c1fed4c2809a
    namespace: openshift-kube-apiserver
    resourceVersion: "28606"
    uid: c5e70db0-4a78-4804-ac6d-6c64e5a008dd
  reason: ShutdownInitiated
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pre-shutdown hooks have been finished
  metadata:
    creationTimestamp: "2025-11-17T09:42:34Z"
    name: kube-apiserver-XXXXXX2.1878c1fed5ce086b
    namespace: openshift-kube-apiserver
    resourceVersion: "28609"
    uid: c913d446-4eb9-4822-8ebd-0e4e638684d6
  reason: TerminationPreShutdownHooksFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: The minimal shutdown duration of 1m10s finished
  metadata:
    creationTimestamp: "2025-11-17T09:43:44Z"
    name: kube-apiserver-XXXXXX2.1878c20f2162cba2
    namespace: openshift-kube-apiserver
    resourceVersion: "29088"
    uid: 8d9ee1c2-1977-4588-b467-ef0fbf3de1e0
  reason: AfterShutdownDelayDuration
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All non long-running request(s) in-flight have drained
  metadata:
    creationTimestamp: "2025-11-17T09:43:44Z"
    name: kube-apiserver-XXXXXX2.1878c20f21a40b5d
    namespace: openshift-kube-apiserver
    resourceVersion: "29089"
    uid: 2bf60528-b1bd-428e-a562-ef55410ee319
  reason: InFlightRequestsDrained
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: HTTP Server has stopped listening
  metadata:
    creationTimestamp: "2025-11-17T09:43:44Z"
    name: kube-apiserver-XXXXXX2.1878c20f21add664
    namespace: openshift-kube-apiserver
    resourceVersion: "29090"
    uid: aead608b-c876-43b8-8377-fef53610d74f
  reason: HTTPServerStoppedListening
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: All pending requests processed
  metadata:
    creationTimestamp: "2025-11-17T09:43:46Z"
    name: kube-apiserver-XXXXXX2.1878c20f98f31291
    namespace: openshift-kube-apiserver
    resourceVersion: "29098"
    uid: 7f62e48a-c1c6-45de-b4b3-82d79f61fa6a
  reason: TerminationGracefulTerminationFinished
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:00Z"
    name: kube-apiserver-XXXXXX2.1878c212cff11ceb
    namespace: openshift-kube-apiserver
    resourceVersion: "29180"
    uid: d320c0db-f587-4ff4-b102-6186131007f6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:00Z"
  message: Created container setup
  metadata:
    creationTimestamp: "2025-11-17T09:44:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:00Z"
    name: kube-apiserver-XXXXXX2.1878c212dbae6bdf
    namespace: openshift-kube-apiserver
    resourceVersion: "29181"
    uid: 76a1f85d-bdd8-4313-93df-f7e67aa7ab62
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.initContainers{setup}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:00Z"
  message: Started container setup
  metadata:
    creationTimestamp: "2025-11-17T09:44:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:00Z"
    name: kube-apiserver-XXXXXX2.1878c212dcab2750
    namespace: openshift-kube-apiserver
    resourceVersion: "29182"
    uid: b792faae-46af-4bd8-bef5-78a008bba794
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:00Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685b764835a135da12c73f4fea43b72423b39897f2c65d726293760ab28a9df0"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:00Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:00Z"
    name: kube-apiserver-XXXXXX2.1878c212fdb8bbd5
    namespace: openshift-kube-apiserver
    resourceVersion: "29183"
    uid: 5c0a721f-0e07-4e5a-a8f6-fd6e868f5e0a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Created container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c21308ebec0d
    namespace: openshift-kube-apiserver
    resourceVersion: "29188"
    uid: 37d4eaaf-5eb1-4698-b484-081695f640c9
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Started container kube-apiserver
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2130a08f000
    namespace: openshift-kube-apiserver
    resourceVersion: "29189"
    uid: 3a2e7425-db7f-49a4-9dcd-640ccf097875
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2130a17a5cb
    namespace: openshift-kube-apiserver
    resourceVersion: "29190"
    uid: 17e967c4-bc36-443c-aabd-196a741b47cf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Created container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c21312bbb2c0
    namespace: openshift-kube-apiserver
    resourceVersion: "29191"
    uid: e926b32b-a99a-462b-93b3-31b74cdbec6d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-syncer}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Started container kube-apiserver-cert-syncer
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c21313c3dbb4
    namespace: openshift-kube-apiserver
    resourceVersion: "29192"
    uid: 8bb8b6ca-1d3e-4dee-aec1-61f1a946492f
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c21313d000fc
    namespace: openshift-kube-apiserver
    resourceVersion: "29193"
    uid: a282c0ed-6a23-4e0e-adc7-55e86fd7d1a9
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Created container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2131c90a341
    namespace: openshift-kube-apiserver
    resourceVersion: "29195"
    uid: e056eb59-b029-492b-b9cf-a691ba31b7d0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-cert-regeneration-controller}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Started container kube-apiserver-cert-regeneration-controller
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2131e21a79a
    namespace: openshift-kube-apiserver
    resourceVersion: "29196"
    uid: be6cf086-1a4d-47c9-9c53-bff7bc2107a9
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2131e2ebced
    namespace: openshift-kube-apiserver
    resourceVersion: "29197"
    uid: f89198a3-18db-4014-a156-f94236060cd7
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Created container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2132ac8f626
    namespace: openshift-kube-apiserver
    resourceVersion: "29199"
    uid: 549f6e9b-200d-4174-9e79-34873d30de8f
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-insecure-readyz}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Started container kube-apiserver-insecure-readyz
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2132c9fd03a
    namespace: openshift-kube-apiserver
    resourceVersion: "29200"
    uid: 10a4b3ca-1c9a-41bc-9322-3cdd90c5ba92
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2132cb62ae9
    namespace: openshift-kube-apiserver
    resourceVersion: "29201"
    uid: 0c2b64ec-6651-41ed-b9fd-b93fcb3d61d8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Created container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c2133603b594
    namespace: openshift-kube-apiserver
    resourceVersion: "29202"
    uid: 8da6c908-1517-4552-a723-dec497739df2
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:44:01Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-apiserver-check-endpoints}
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
    uid: 0d08e0c5dcd56ca8120809837842eccf
  kind: Event
  lastTimestamp: "2025-11-17T09:44:01Z"
  message: Started container kube-apiserver-check-endpoints
  metadata:
    creationTimestamp: "2025-11-17T09:44:01Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:44:01Z"
    name: kube-apiserver-XXXXXX2.1878c213373486bd
    namespace: openshift-kube-apiserver
    resourceVersion: "29203"
    uid: 65d1a54a-e312-4efe-9546-407bceb18e25
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  eventTime: null
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: kube-apiserver-XXXXXX2
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: null
  message: readyz=true
  metadata:
    creationTimestamp: "2025-11-17T09:44:04Z"
    name: kube-apiserver-XXXXXX2.1878c213befffd86
    namespace: openshift-kube-apiserver
    resourceVersion: "29216"
    uid: bd4c989d-3c27-449f-aa24-ebe53c52304e
  reason: KubeAPIReadyz
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: apiserver
    host: XXXXXX2
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:36:17Z"
  involvedObject:
    apiVersion: v1
    kind: Namespace
    name: openshift-kube-apiserver
    namespace: openshift-kube-apiserver
  kind: Event
  lastTimestamp: "2025-11-17T09:36:17Z"
  message: 'unable to get cluster infrastructure status, using HA cluster values for
    leader election: infrastructures.config.openshift.io "cluster" is forbidden: User
    "system:serviceaccount:openshift-kube-apiserver:localhost-recovery-client" cannot
    get resource "infrastructures" in API group "config.openshift.io" at the cluster
    scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:public-info-viewer"
    not found, clusterrole.rbac.authorization.k8s.io "system:build-strategy-jenkinspipeline"
    not found, clusterrole.rbac.authorization.k8s.io "basic-user" not found, clusterrole.rbac.authorization.k8s.io
    "cluster-status" not found, clusterrole.rbac.authorization.k8s.io "system:service-account-issuer-discovery"
    not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found,
    clusterrole.rbac.authorization.k8s.io "system:openshift:public-info-viewer" not
    found, clusterrole.rbac.authorization.k8s.io "helm-chartrepos-viewer" not found,
    clusterrole.rbac.authorization.k8s.io "console-extensions-reader" not found, clusterrole.rbac.authorization.k8s.io
    "system:webhook" not found, clusterrole.rbac.authorization.k8s.io "self-access-reviewer"
    not found, clusterrole.rbac.authorization.k8s.io "system:openshift:discovery"
    not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found,
    clusterrole.rbac.authorization.k8s.io "system:build-strategy-source" not found,
    clusterrole.rbac.authorization.k8s.io "system:scope-impersonation" not found,
    clusterrole.rbac.authorization.k8s.io "system:oauth-token-deleter" not found,
    clusterrole.rbac.authorization.k8s.io "system:openshift:scc:restricted-v2" not
    found, clusterrole.rbac.authorization.k8s.io "system:build-strategy-docker" not
    found, clusterrole.rbac.authorization.k8s.io "cluster-admin" not found]'
  metadata:
    creationTimestamp: "2025-11-17T09:36:17Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: cluster-kube-apiserver-operator
      operation: Update
      time: "2025-11-17T09:36:17Z"
    name: openshift-kube-apiserver.1878c1a7034087a8
    namespace: openshift-kube-apiserver
    resourceVersion: "21316"
    uid: 790d48f5-1d87-421c-8097-9d9c19fe68fc
  reason: ClusterInfrastructureStatus
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: cert-regeneration-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:58Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "30785"
    uid: 9f2fe8e6-23de-4a33-bd64-66049ff6896d
  kind: Event
  lastTimestamp: "2025-11-17T09:47:58Z"
  message: Add eth0 [10.130.0.37/23 fd02:0:0:3::25/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:47:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:47:58Z"
    name: revision-pruner-7-XXXXXX0.1878c24a5fa31a49
    namespace: openshift-kube-apiserver
    resourceVersion: "30811"
    uid: 12851f01-c377-489b-9564-145d686c9df3
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:58Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "30782"
    uid: 9f2fe8e6-23de-4a33-bd64-66049ff6896d
  kind: Event
  lastTimestamp: "2025-11-17T09:47:58Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:58Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:58Z"
    name: revision-pruner-7-XXXXXX0.1878c24a610e576b
    namespace: openshift-kube-apiserver
    resourceVersion: "30813"
    uid: d222a267-5d3a-4c0a-ab2b-4440fb50285c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "30782"
    uid: 9f2fe8e6-23de-4a33-bd64-66049ff6896d
  kind: Event
  lastTimestamp: "2025-11-17T09:47:59Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:59Z"
    name: revision-pruner-7-XXXXXX0.1878c24a7788116d
    namespace: openshift-kube-apiserver
    resourceVersion: "30815"
    uid: 84afe749-f3ff-4eba-8189-17410cd31013
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:59Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX0
    namespace: openshift-kube-apiserver
    resourceVersion: "30782"
    uid: 9f2fe8e6-23de-4a33-bd64-66049ff6896d
  kind: Event
  lastTimestamp: "2025-11-17T09:47:59Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:59Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:59Z"
    name: revision-pruner-7-XXXXXX0.1878c24a788d25e9
    namespace: openshift-kube-apiserver
    resourceVersion: "30816"
    uid: 9a0884e6-f97e-4af9-9efe-124b232fe98b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX0
  source:
    component: kubelet
    host: XXXXXX0
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:52Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "30744"
    uid: b3a392fe-1f77-4fb9-8fd6-d186d0b5533a
  kind: Event
  lastTimestamp: "2025-11-17T09:47:52Z"
  message: Add eth0 [10.128.0.80/23 fd02:0:0:1::50/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:47:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:47:52Z"
    name: revision-pruner-7-XXXXXX1.1878c248e4330510
    namespace: openshift-kube-apiserver
    resourceVersion: "30750"
    uid: 2e6926c5-f54c-46e8-be68-216f81321d31
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "30740"
    uid: b3a392fe-1f77-4fb9-8fd6-d186d0b5533a
  kind: Event
  lastTimestamp: "2025-11-17T09:47:52Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:52Z"
    name: revision-pruner-7-XXXXXX1.1878c248e5ae08a1
    namespace: openshift-kube-apiserver
    resourceVersion: "30752"
    uid: e41247f4-4683-4313-a252-a8e4a5d7afbf
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "30740"
    uid: b3a392fe-1f77-4fb9-8fd6-d186d0b5533a
  kind: Event
  lastTimestamp: "2025-11-17T09:47:52Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:52Z"
    name: revision-pruner-7-XXXXXX1.1878c248fe733b15
    namespace: openshift-kube-apiserver
    resourceVersion: "30756"
    uid: b026a9e5-b802-480f-b233-7360c7fe1c2d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:52Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX1
    namespace: openshift-kube-apiserver
    resourceVersion: "30740"
    uid: b3a392fe-1f77-4fb9-8fd6-d186d0b5533a
  kind: Event
  lastTimestamp: "2025-11-17T09:47:52Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:52Z"
    name: revision-pruner-7-XXXXXX1.1878c248ff718eca
    namespace: openshift-kube-apiserver
    resourceVersion: "30757"
    uid: f3b43a3d-5ac3-459e-a16f-15c81deb7e37
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX1
  source:
    component: kubelet
    host: XXXXXX1
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:55Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: revision-pruner-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "30762"
    uid: 445b757b-06c1-4ea4-8f6a-272ce6b23ae6
  kind: Event
  lastTimestamp: "2025-11-17T09:47:55Z"
  message: Add eth0 [10.129.0.83/23 fd02:0:0:2::53/64] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-11-17T09:47:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-11-17T09:47:55Z"
    name: revision-pruner-7-XXXXXX2.1878c24997b2727c
    namespace: openshift-kube-apiserver
    resourceVersion: "30773"
    uid: 308d25e5-6f91-4046-ab53-4d1da5711003
  reason: AddedInterface
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "30759"
    uid: 445b757b-06c1-4ea4-8f6a-272ce6b23ae6
  kind: Event
  lastTimestamp: "2025-11-17T09:47:55Z"
  message: Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4a3e7a9a5f1cbfd06efde645c7702d9452f55d4b46e5441c60b62ee1c701c093"
    already present on machine
  metadata:
    creationTimestamp: "2025-11-17T09:47:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:55Z"
    name: revision-pruner-7-XXXXXX2.1878c249995b0e93
    namespace: openshift-kube-apiserver
    resourceVersion: "30775"
    uid: 7df31402-c101-4530-9789-fdb8437d727e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "30759"
    uid: 445b757b-06c1-4ea4-8f6a-272ce6b23ae6
  kind: Event
  lastTimestamp: "2025-11-17T09:47:55Z"
  message: Created container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:55Z"
    name: revision-pruner-7-XXXXXX2.1878c249b35a340b
    namespace: openshift-kube-apiserver
    resourceVersion: "30776"
    uid: 058cc810-2dc2-40bf-ad67-913507513b3e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-11-17T09:47:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{pruner}
    kind: Pod
    name: revision-pruner-7-XXXXXX2
    namespace: openshift-kube-apiserver
    resourceVersion: "30759"
    uid: 445b757b-06c1-4ea4-8f6a-272ce6b23ae6
  kind: Event
  lastTimestamp: "2025-11-17T09:47:55Z"
  message: Started container pruner
  metadata:
    creationTimestamp: "2025-11-17T09:47:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-11-17T09:47:55Z"
    name: revision-pruner-7-XXXXXX2.1878c249b4966ff7
    namespace: openshift-kube-apiserver
    resourceVersion: "30777"
    uid: 3cde8ea2-ae87-40c6-8f33-79680076cbc4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: XXXXXX2
  source:
    component: kubelet
    host: XXXXXX2
  type: Normal
kind: EventList
metadata:
  resourceVersion: "32473"
