---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.129.0.29/23","fd02:0:0:2::1d/64"],"mac_address":"0a:58:0a:81:00:1d","gateway_ips":["10.129.0.1","fd02:0:0:2::1"],"routes":[{"dest":XXXXXXXXXXXXXXX,"nextHop":"10.129.0.1"},{"dest":XXXXXXXXXXXXXXX,"nextHop":"10.129.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.129.0.1"},{"dest":"fd02::/48","nextHop":"fd02:0:0:2::1"},{"dest":"fd03::/112","nextHop":"fd02:0:0:2::1"},{"dest":"fd98::/64","nextHop":"fd02:0:0:2::1"}]}}'
    k8s.v1.cni.cncf.io/network-status: |-
      [{
          "name": "ovn-kubernetes",
          "interface": "eth0",
          "ips": [
              "10.129.0.29",
              "fd02:0:0:2::1d"
          ],
          "mac": "0a:58:0a:81:00:1d",
          "default": true,
          "dns": {}
      }]
    openshift.io/scc: anyuid
  creationTimestamp: "2025-11-17T09:11:17Z"
  generateName: cluster-node-tuning-operator-85f658c4d5-
  labels:
    name: cluster-node-tuning-operator
    pod-template-hash: 85f658c4d5
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:target.workload.openshift.io/management: {}
        f:generateName: {}
        f:labels:
          .: {}
          f:name: {}
          f:pod-template-hash: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"e60877b1-9724-4479-adc7-c6000d2a5dde"}: {}
      f:spec:
        f:containers:
          k:{"name":"cluster-node-tuning-operator"}:
            .: {}
            f:args: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"CLUSTER_NODE_TUNED_IMAGE"}:
                .: {}
                f:name: {}
                f:value: {}
              k:{"name":"POD_NAME"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"RELEASE_VERSION"}:
                .: {}
                f:name: {}
                f:value: {}
              k:{"name":"RESYNC_PERIOD"}:
                .: {}
                f:name: {}
                f:value: {}
              k:{"name":"WATCH_NAMESPACE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":60000,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/apiserver.local.config/certificates"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/secrets"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/run/configmaps/trusted-ca/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:nodeSelector: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext:
          .: {}
          f:runAsNonRoot: {}
          f:runAsUser: {}
        f:serviceAccount: {}
        f:serviceAccountName: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"apiservice-cert"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:items: {}
              f:secretName: {}
          k:{"name":"node-tuning-operator-tls"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:secretName: {}
          k:{"name":"trusted-ca"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:items: {}
              f:name: {}
              f:optional: {}
            f:name: {}
    manager: kube-controller-manager
    operation: Update
    time: "2025-11-17T09:11:17Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
    manager: kube-scheduler
    operation: Update
    subresource: status
    time: "2025-11-17T09:11:17Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          f:k8s.ovn.org/pod-networks: {}
    manager: XXXXXX2
    operation: Update
    subresource: status
    time: "2025-11-17T09:20:00Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          f:k8s.v1.cni.cncf.io/network-status: {}
    manager: multus-daemon
    operation: Update
    subresource: status
    time: "2025-11-17T09:21:35Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.129.0.29"}:
            .: {}
            f:ip: {}
          k:{"ip":"fd02:0:0:2::1d"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2025-11-17T09:33:14Z"
  name: cluster-node-tuning-operator-85f658c4d5-5h6rh
  namespace: openshift-cluster-node-tuning-operator
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: cluster-node-tuning-operator-85f658c4d5
    uid: e60877b1-9724-4479-adc7-c6000d2a5dde
  resourceVersion: "19590"
  uid: 173c2a14-c8ab-4fb7-b6da-671f99ffc8ae
spec:
  containers:
  - args:
    - -v=0
    command:
    - cluster-node-tuning-operator
    env:
    - name: RELEASE_VERSION
      value: 4.14.59
    - name: WATCH_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    - name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: RESYNC_PERIOD
      value: "600"
    - name: CLUSTER_NODE_TUNED_IMAGE
      value: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a7b207552d68e89034828d63a08ccb5cccbedc4d28cba0c58bbcda63f726e448
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a7b207552d68e89034828d63a08ccb5cccbedc4d28cba0c58bbcda63f726e448
    imagePullPolicy: IfNotPresent
    name: cluster-node-tuning-operator
    ports:
    - containerPort: 60000
      name: metrics
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 20Mi
    securityContext:
      capabilities:
        drop:
        - MKNOD
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/secrets
      name: node-tuning-operator-tls
    - mountPath: /var/run/configmaps/trusted-ca/
      name: trusted-ca
    - mountPath: /apiserver.local.config/certificates
      name: apiservice-cert
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-9cmw5
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: XXXXXX2
  nodeSelector:
    node-role.kubernetes.io/XXXXXX: ""
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    runAsNonRoot: true
    runAsUser: 499
    seLinuxOptions:
      level: s0:c16,c0
  serviceAccount: cluster-node-tuning-operator
  serviceAccountName: cluster-node-tuning-operator
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/XXXXXX
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 120
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 120
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  volumes:
  - name: node-tuning-operator-tls
    secret:
      defaultMode: 420
      secretName: node-tuning-operator-tls
  - name: apiservice-cert
    secret:
      defaultMode: 420
      items:
      - key: tls.crt
        path: apiserver.crt
      - key: tls.key
        path: apiserver.key
      secretName: performance-addon-operator-webhook-cert
  - configMap:
      defaultMode: 420
      items:
      - key: ca-bundle.crt
        path: tls-ca-bundle.pem
      name: trusted-ca
      optional: true
    name: trusted-ca
  - name: kube-api-access-9cmw5
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
      - configMap:
          items:
          - key: service-ca.crt
            path: service-ca.crt
          name: openshift-service-ca.crt
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2025-11-17T09:19:25Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2025-11-17T09:33:14Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2025-11-17T09:33:14Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2025-11-17T09:19:25Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://2b32c8aaeaacc084036f66f80675c12e4e7f7f6356517ec642637ebcbcd8a328
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a7b207552d68e89034828d63a08ccb5cccbedc4d28cba0c58bbcda63f726e448
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a7b207552d68e89034828d63a08ccb5cccbedc4d28cba0c58bbcda63f726e448
    lastState:
      terminated:
        containerID: cri-o://ea468bcf738730fcd70f8a4d2cbab6f04da16f7599a429a3f2349544e2a64379
        exitCode: 1
        finishedAt: "2025-11-17T09:33:00Z"
        message: |
          .io","controllerKind":"PerformanceProfile"}
          I1117 09:29:49.588439       1 controller.go:1410] started events processor/controller
          I1117 09:29:49.601961       1 server.go:113] starting metrics server
          I1117 09:29:49.619771       1 controller.go:657] created profile XXXXXX1 [openshift-control-plane]
          I1117 09:29:49.637438       1 controller.go:729] updated profile XXXXXX2 [openshift-control-plane]
          I1117 09:29:49.647071       1 controller.go:729] updated profile XXXXXX1 [openshift-control-plane]
          {"level":"info","ts":"2025-11-17T09:29:49Z","msg":"Starting XXXXXXs","controller":"performanceprofile","controllerGroup":"performance.openshift.io","controllerKind":"PerformanceProfile","XXXXXX count":1}
          E1117 09:32:07.539155       1 leaderelection.go:327] error retrieving resource lock openshift-cluster-node-tuning-operator/node-tuning-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io node-tuning-operator-lock)
          W1117 09:32:52.071048       1 reflector.go:533] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:233: failed to list *v1.RuntimeClass: Get "https://172.30.0.1:443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=18528": dial tcp 172.30.0.1:443: connect: connection refused
          E1117 09:32:52.071094       1 reflector.go:148] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:233: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://172.30.0.1:443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=18528": dial tcp 172.30.0.1:443: connect: connection refused
          E1117 09:32:54.541511       1 leaderelection.go:364] Failed to update lock: client rate limiter Wait returned an error: context deadline exceeded
          I1117 09:32:54.541545       1 leaderelection.go:280] failed to renew lease openshift-cluster-node-tuning-operator/node-tuning-operator-lock: timed out waiting for the condition
          F1117 09:33:00.392852       1 main.go:193] manager exited with non-zero code: leader election lost
        reason: Error
        startedAt: "2025-11-17T09:26:54Z"
    name: cluster-node-tuning-operator
    ready: true
    restartCount: 2
    started: true
    state:
      running:
        startedAt: "2025-11-17T09:33:13Z"
  hostIP: XXXXXXXXXXX
  phase: Running
  podIP: 10.129.0.29
  podIPs:
  - ip: 10.129.0.29
  - ip: fd02:0:0:2::1d
  qosClass: Burstable
  startTime: "2025-11-17T09:19:25Z"
